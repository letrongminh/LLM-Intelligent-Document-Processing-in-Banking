{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRYSu48huSUW",
    "outputId": "64e4984b-4b62-4709-847a-a021d4730a8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (24.0)\n",
      "Collecting pip\n",
      "  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.0\n",
      "    Uninstalling pip-24.0:\n",
      "      Successfully uninstalled pip-24.0\n",
      "Successfully installed pip-24.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "poetry 1.2.0 requires requests-toolbelt<0.10.0,>=0.9.1, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "datasets 2.16.1 requires dill<0.3.8,>=0.3.0, but you have dill 0.3.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip -q install langchain langchain-community openai tiktoken chromadb python-dotenv pypdf sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AnZQpL_IZZZ"
   },
   "source": [
    "# Create a Vector Database with ChromaDB\n",
    "\n",
    "Data -> Embedding Model -> Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqwsGJDhvAQ5"
   },
   "source": [
    "## Setting up LangChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw (text pdf) -> embeddding -> vector -> database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dNA4TsHpu6OM"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"OpenAI API key not found. Please set the OPENAI_API_KEY environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XHVE9uFb3Ajj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khoa/py39/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Optional, Union\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UcQKUId3X2M"
   },
   "source": [
    "## Load multiple and process documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PRSeXXc_3Ypj",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " impossible to decode XFormObject /Fm0\n",
      " impossible to decode XFormObject /Fm1\n",
      " impossible to decode XFormObject /Fm2\n",
      " impossible to decode XFormObject /Fm3\n",
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/doc_4771.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'<!doc'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/doc_5242.pdf: Stream has ended unexpectedly\n",
      "Error loading file ../data/verra/verra_news/pdf/83-cap_1.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n",
      "invalid pdf header: b'\\n\\n \\n '\n",
      "EOF marker not found\n",
      "EOF marker not found\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/doc_3898.pdf: Stream has ended unexpectedly\n",
      "Error loading file ../data/verra/verra_news/pdf/777420AR0201200mbargo0until0May0290.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b' <!DO'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/CI_Linking-Flight-and-Forests-Technical-Annex-Apr-2016.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b' <!DO'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/CI_Linking-Flight-and-Forests-Briefing-Paper-Apr-2016.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/doc_4501.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/doc_4475.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 15 0 (offset 0)\n",
      "Ignoring wrong pointing object 17 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n",
      "Ignoring wrong pointing object 40 0 (offset 0)\n",
      "Ignoring wrong pointing object 67 0 (offset 0)\n",
      "Ignoring wrong pointing object 84 0 (offset 0)\n",
      "Ignoring wrong pointing object 86 0 (offset 0)\n",
      "Ignoring wrong pointing object 130 0 (offset 0)\n",
      "Ignoring wrong pointing object 145 0 (offset 0)\n",
      "Ignoring wrong pointing object 147 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 151 0 (offset 0)\n",
      "Ignoring wrong pointing object 153 0 (offset 0)\n",
      "Ignoring wrong pointing object 155 0 (offset 0)\n",
      "Ignoring wrong pointing object 157 0 (offset 0)\n",
      "Ignoring wrong pointing object 159 0 (offset 0)\n",
      "Ignoring wrong pointing object 161 0 (offset 0)\n",
      "Ignoring wrong pointing object 216 0 (offset 0)\n",
      "Ignoring wrong pointing object 248 0 (offset 0)\n",
      "invalid pdf header: b'\\r\\n<!D'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/DECRETO%20926%20DEL%2001%20DE%20JUNIO%20DE%202017.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/doc_5388.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<html'\n",
      "EOF marker not found\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/cma3_auv_12a_PA_6.2.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!doc'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/estrada-etal2013-statistically20-century.temperature.changes.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<!DOC'\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/doc_5715.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<html'\n",
      "EOF marker not found\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_news/pdf/paris_agreement_english_.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid pdf header: b'<html'\n",
      "EOF marker not found\n",
      "EOF marker not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading file ../data/verra/verra_views/pdf/pub_07_financial_flows.pdf: Stream has ended unexpectedly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EOF marker seems truncated\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 30 0 (offset 0)\n",
      "Ignoring wrong pointing object 36 0 (offset 0)\n",
      "Ignoring wrong pointing object 38 0 (offset 0)\n",
      "Ignoring wrong pointing object 47 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n",
      "Ignoring wrong pointing object 33 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 7 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n",
      "Ignoring wrong pointing object 34 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "\n",
    "DATA_PATH = \"verra/\"\n",
    "\n",
    "# Function to load both PDF and TXT files based on file extension with error handling\n",
    "def load_file(file_path):\n",
    "    try:\n",
    "        if file_path.endswith('.txt'):\n",
    "            return TextLoader(file_path).load()\n",
    "        elif file_path.endswith('.pdf'):\n",
    "            return PyPDFLoader(file_path).load()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "    return []\n",
    "\n",
    "# Recursive function to traverse directories and load files\n",
    "def load_documents_from_directory(base_path):\n",
    "    all_documents = []\n",
    "    for root, _, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            documents = load_file(file_path)\n",
    "            all_documents.extend(documents)\n",
    "    return all_documents\n",
    "\n",
    "documents = load_documents_from_directory(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "3__nT0D4Fkmg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length text : 11839\n"
     ]
    }
   ],
   "source": [
    "def split_text(\n",
    "    documents,\n",
    "    separators=[\"\\n\\n\\n\", \"\\n\\n\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=separators,\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "texts = split_text(documents)\n",
    "print(f\"Length text : {len(texts)}\")\n",
    "# Length text : 44873"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsYsIy8F4cdm"
   },
   "source": [
    "## create the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q_eTIZwf4Dk2",
    "outputId": "1cd293c4-716c-402d-d41b-045b6a264041"
   },
   "outputs": [],
   "source": [
    "def load_embedding_model(\n",
    "    model_name: str = \"Snowflake/snowflake-arctic-embed-m-v1.5\", device: str = \"cpu\"\n",
    ") -> HuggingFaceBgeEmbeddings:\n",
    "    model_kwargs = {\"device\": device}\n",
    "    encode_kwargs = {\n",
    "        \"normalize_embeddings\": True\n",
    "    }  # set True to compute cosine similarity\n",
    "    embedding_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "    )\n",
    "    return embedding_model\n",
    "\n",
    "\n",
    "def generate_embeddings(docs, embedding_model):\n",
    "    db = FAISS.from_documents(documents=docs, embedding=embedding_model)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/Users/khoa/Downloads/batch_0.pkl\", \"rb\") as r:\n",
    "    documents = pickle.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 42min 56s, sys: 33min 17s, total: 2h 16min 14s\n",
      "Wall time: 19min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_model = load_embedding_model()\n",
    "vectorstore = generate_embeddings(documents, embedding_model=embedding_model)\n",
    "vectorstore.save_local(\"document_idx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7682f99b7670>, search_kwargs={'k': 10})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Neijiang  Xingming  Energy  Co.,  Ltd  has  commissioned  Det  Norske  Veritas  Certification  AS \n",
    "(DNV)  to  perform  a  validation  of  the  “Chuanwei  Group  24  MW  Waste  Gas  Based  Captive \n",
    "Power  Plant”  project  in  China  (hereafter  called  “the  project”). \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reranker_model(\n",
    "    reranker_model_name: str = \"BAAI/bge-reranker-large\", device: str = \"cuda\"\n",
    ") -> CrossEncoder:\n",
    "    reranker_model = CrossEncoder(\n",
    "        model_name=reranker_model_name, max_length=512, device=device\n",
    "    )\n",
    "    return reranker_model\n",
    "    \n",
    "def rerank_docs(reranker_model, query, retrieved_docs):\n",
    "    query_and_docs = [(query, r.page_content) for r in retrieved_docs]\n",
    "    scores = reranker_model.predict(query_and_docs)\n",
    "    return sorted(list(zip(retrieved_docs, scores)), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reranker_model = load_reranker_model()\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "retrieved_documents = retriever.get_relevant_documents(query)\n",
    "reranked_docs = rerank_docs(reranker_model, query, retrieved_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "uRfD_Te-47lb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': '../data/verra/projects/VCS/12/registration/Chuanwei CDM Validation Report.pdf', 'page': 5}, page_content='D ET  N ORSKE  V ERITAS  \\n \\nV ALIDATION R EPORT  \\n \\nCDM Validation2007-0849, rev.2\\n 6  \\n2  INTRODUCTION \\nNeijiang Xingming Energy Co., Ltd has commissioned Det Norske Veritas Certification AS \\n(DNV) to perform a validation of the “Chuanwei Grou p 24 MW Waste Gas Based Captive \\nPower Plant” project in China (hereafter called “th e project”). This report summaries the \\nfindings of the validation of the project, performe d on the basis of UNFCCC criteria for CDM \\nprojects, as well as criteria given to provide for consistent project operations, monitoring and \\nreporting.  \\n2.1 Objective \\nThe purpose of a validation is to have an independe nt third party assess the project design. In \\nparticular, the project’s baseline, monitoring plan , and the project’s compliance with relevant \\nUNFCCC and host Party criteria are validated in ord er to confirm that the project design, as \\ndocumented, is sound and reasonable and meets the i dentified criteria. Validation is a \\nrequirement for all CDM projects and is seen as nec essary to provide assurance to \\nstakeholders of the quality of the project and its intended generation of certified emission \\nreductions (CERs). \\n3.5  Scope \\nThe validation scope is defined as an independent a nd objective review of the project design \\ndocument (PDD). The PDD is reviewed against the cri teria stated in Article 12 of the Kyoto \\nProtocol, the CDM modalities and procedures as agre ed in the Marrakech Accords and the \\nrelevant decisions by the CDM Executive Board, incl uding the approved baseline and \\nmonitoring methodology ACM0004. The validation team  has, based on the recommendations \\nin the Validation and Verification Manual /12/ empl oyed a risk-based approach, focusing on \\nthe identification of significant risks for project  implementation and the generation of CERs. \\nThe validation is not meant to provide any consulti ng towards the project participants. \\nHowever, stated requests for clarifications and/or corrective actions may have provided input \\nfor improvement of the project design. '),\n",
       "  0.99992716),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/Chuanwei CDM Validation Report.pdf', 'page': 4}, page_content='D ET  N ORSKE  V ERITAS  \\n \\nV ALIDATION R EPORT  \\n \\nCDM Validation2007-0849, rev.2\\n 5  \\n1  EXECUTIVE SUMMARY – V ALIDATION OPINION \\nDet Norske Veritas Certification AS (DNV) has perfo rmed a validation of the “Chuanwei \\nGroup 24 MW Waste Gas Based Captive Power Plant” pr oject in China. The validation was \\nperformed on the basis of UNFCCC criteria for the C lean Development Mechanism and host \\ncountry criteria, as well as criteria given to prov ide for consistent project operations, \\nmonitoring and reporting.  \\nThe review of the project design documentation and the subsequent follow-up interviews have \\nprovided DNV with sufficient evidence to determine the fulfilment of stated criteria.  \\nThe host country is China and the Annex I Party is the Netherlands. Both Parties fulfil the \\nparticipation criteria for CDM and have approved th e project and authorized the project \\nparticipants. The DNA from China has also confirmed  that the project assists the country in \\nachieving sustainable development.  \\nThe project correctly applies ACM0004 “Consolidated  baseline methodology for waste gas \\nand/or heat for power generation”, version 02 of 3 March 2006.   \\nThe electricity generated by the utilization of the  waste gas from a blast furnace will displace \\nelectricity generated by consuming coal and fuel oi l in Central China Grid. The project \\nthereby results in reductions of CO \\n2  emissions that are real, measurable and give long- term \\nbenefits to the mitigation of climate change. It is  demonstrated that the project is not a likely \\nbaseline scenario. Emission reductions attributable  to the project are hence additional to any \\nthat would occur in the absence of the project acti vity.   \\nThe total emission reductions from the project are estimated to be on the average 180 693 \\ntCO 2 e per year over the first 7-year crediting period. The emission reduction forecast has \\nbeen checked, and it is deemed likely that the stat ed amount is achieved given that the \\nunderlying assumptions do not change.  \\nAdequate training and monitoring procedures have be en implemented.   \\nIn summary, it is DNV’s opinion that the “ Chuanwei Group 24 MW Waste Gas Based Captive \\nPower Plant in China ” , as described in the PDD of 5 August 2008, version  6, meets all \\nrelevant UNFCCC requirements for the CDM and all re levant host country criteria and \\ncorrectly applies the baseline and monitoring metho dology ACM0004 version 2. DNV thus \\nrequests the registration of the project as a CDM p roject activity. '),\n",
       "  0.9997285),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/Chuanwei CDM Validation Report.pdf', 'page': 1}, page_content='D ET  N ORSKE  V ERITAS  \\n \\nV ALIDATION R EPORT  \\n \\nCDM Validation2007-0849, rev.2\\n 2  \\nD ET N ORSKE V ERITAS  \\nDNV  C ERTIFICATION AS \\n \\nVeritasveien 1, \\n1322 HØVIK, Norway \\nTel:  +47 67 57 99 00 \\nFax:  +47 67 57 99 11 \\nhttp://www.dnv.com \\nOrg. No: NO 945 748 931 MVA \\n \\nDate of first issue:  Project No.:  \\n2006-11-27 44410002 (48) \\nApproved by:  Organisational unit:  \\nMichael Lehmann DNV Certification, International Climate \\nChange Services  \\nClient:  Client ref.:  \\nEnergy Systems International BV Mr. Zhang Yimeng \\n \\nProject Name:  Chuanwei Group 24 MW Waste Gas Based Captive Power  Plant \\nCountry:  China \\nMethodology: ACM0004  \\nVersion: 02 \\nGHG reducing Measure/Technology: power generation from waste gas  \\nER estimate:  180 693 tCO 2 e  \\nSize \\nLarge Scale \\nSmall Scale \\nValidation Phases: \\n Desk Review \\n Follow up interviews \\n Resolution of outstanding issues \\nValidation Status \\n Corrective Actions Requested \\n Clarifications Requested \\nFull Approval and submission for registration \\nRejected \\nIn summary, it is DNV’s opinion that the “Chuanwei Group 24 MW Waste Gas Based \\nCaptive Power Plant” project in China, as described  in the PDD of 5 August 2008, version 6, \\nmeets all relevant UNFCCC requirements for the CDM and all relevant host country criteria \\nand correctly applies the baseline and monitoring m ethodology ACM0004. DNV thus \\nrequests the registration of the project as a CDM p roject activity. \\n \\nReport No.:  Date of this revision:  Rev. No.   Key words:  \\n2007-0849 2008-08-20 02  \\nReport title:   \\nChuanwei Group 24 MW Waste Gas Based \\nCaptive Power Plant in China  \\n \\nClimate Change \\nKyoto Protocol \\nValidation \\nClean Development Mechanism \\nWork carried out by:    \\nMing Yue, Wilson Tang, Tim Kuo, Michael \\nLehmann \\n  No distribution without permission from \\nthe Client or responsible organisational unit  \\nWork verified by:    \\n  Limited distribution \\n   \\nHendrik W. Brinks, Einar Telnes \\n  Unrestricted distribution \\n '),\n",
       "  0.99890506),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/VER_Verification Report-Chuanwei WG 24MW_Approved _1_.pdf', 'page': 23}, page_content='DET NORSKE VERITAS \\nReport No: 2009-0278 , rev. 01 \\nVCS VERIFICATION / CERTIFICATION REPORT \\nPage 19 \\nReference to part of this report which may lead to misinterpretation is not permissible.  \\n5 CERTIFICATION STATEMENT \\nDet Norske Veritas Certification AS has perf ormed a verification of  emission reductions \\nreported for the “Chuanwei Group 24 MW Waste Gas based Captive Power Plant” managed by \\nNeijiang Xingming Energy Co., Ltd. for the period 01 January 2007 to  09 September 2008. The \\nproject is registered as CDM project ac tivity (UNFCCC Registration Ref. No. 1470) with the \\nCDM crediting period of the project starting on 10 September 2008. The emission reductions \\nfrom 01 January 2007 to 09 September 2008 and t hus prior to the CDM crediting period are \\nclaimed as Voluntary Carbon Units (VCU) under the Voluntary Carbon Standard (VCS).  \\nNeijiang Xingming Energy Co., Ltd. is responsible for the collection of dat a in accordance with \\nthe validated monitoring plan and the reporting of GHG emission reductions from the project. \\nIt is DNV’s responsibility to express an independent verification statement on the reported GHG \\nemission reductions from the project. \\nIn DNV’s opinion the GHG emission reductions reported for the project in the monitoring report \\nof 23 March 2009 are fairly stated and the project design meets all VCU Verification Criteria. \\nThe GHG emission reductions were  calculated correctly on th e basis of the baseline and \\nmonitoring methodology, ACM0004 version 2 and the monitoring plan provided in the PDD. The \\nemission reductions are claimed as Voluntary Carbon Units (VCU) under the Voluntary Carbon \\nStandard (VCS). \\nDet Norske Veritas Certification AS is able to certify that the emission reductions from the \\n‘Chuanwei Group 24 MW Waste Gas based Cap tive Power Plant’, managed by Neijiang \\nXingming Energy Co., Ltd. during the period 01 January 2007 to 09 Se ptember 2008 amount to \\n237 205  tonnes of CO2 equivalent. \\nDNV does not assume any responsibility towards the issuance and utilization of the VCUs \\nhereby verified and certified. Re quest for issuance of VCUs s hall be made by the project \\nproponent to an approved VCS Program Registry based on the requirements set out under the \\nmost recent version of the VCS Program Guidelines clause on VCS Registration. \\nThe verification of reported emi ssion reductions is based on the information made available to \\nus and the engagement conditions detailed in this report. DNV cannot guarantee the accuracy or \\ncorrectness of this information. Hence, DNV cannot  be held liable by any  party for decisions \\nmade or not made based on this report. \\n \\nBeijing, 27 March 2009, Oslo, 27 March 2009,  \\n  \\nTao Li Hendrik W. Brinks \\nGHG Auditor Technical Director for CDM  \\nClimate Change Services Climate Change Services \\n \\n'),\n",
       "  0.99822456),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/VER_Verification Report-Chuanwei WG 24MW_Approved _1_.pdf', 'page': 1}, page_content='DET NORSKE VERITAS \\n \\nVCS VERIFICATION / CERTIFICATION REPORT \\nHead Office: Veritasvn. 1, N-1322 HØVIK, Norway \\nVER_Verification Report-Chuanwei WG 24MW_Approved.doc \\n \\n Det Norske Veritas \\nCERTIFICATION AS \\n \\nVeritasveien 1, \\n1322 HØVIK, Norway \\nTel:  +47 67 57 99 00 \\nFax:  +47 67 57 99 11 \\nhttp://www.dnv.com \\nOrg. No: NO 945 748 931 MVA \\nDate of first issue: Pro ject No.:\\n2009-03-23 63608011 \\nApproved by: Or ganisational unit:\\nHendrik W. Brinks Climate Change Services \\nClient: Client ref.:\\nClimate Bridge Ltd. Li Ling \\nSummary: \\nDet Norske Veritas Certification AS (DNV) has performed a verification of emission reductions reported from the \\n‘Chuanwei Group 24 MW Waste Gas based Captive Power Plant’ (CGWGCPP), managed by Neijiang Xingming Energy \\nCo., Ltd. for the period 01 January 2007 to 09 September 2008 . The project activity is registered as CDM project activity \\nunder the UNFCCC with the Registration Ref. No. being 1470 and with the CDM crediting period of the project starting \\non 10 September 2008. The emission reductions from 01 January 2007 to 09 September 2008 and thus prior to the CDM \\ncrediting period are claimed as Voluntary Carbon Units (VCU) under the Voluntary Carbon Standard (VCS 2007.1). \\nIn our opinion the GHG emissions reductions reported for the project in the monitoring report dated 23 March 2009 are \\nfairly stated. \\nThe GHG emission reductions were calculated correctly on the basis of the CDM baseline and monitoring methodology \\nACM0004 Version 2. \\nDet Norske Veritas Certification AS is able to certify that the emission reductions from the ‘Chuanwei Group 24 MW \\nWaste Gas based Captive Power Plant’, managed by Neijiang Xingming Energy Co., Ltd., during the period 01 January\\n2007 to 09 September 2008 amount to 237 205  tonnes of CO2 equivalent. \\nDNV does not assume any responsibility towards the issuance and utilization of VCUs hereby verified and certified. \\nRequest for issuance of VCUs shall be made by the project proponent to an approved VCS Program Registry based on the \\nrequirements set out under the most recent version of the VCS Program Guidelines clause on VCS Registration.  \\nThe verification of reported emission reductions is based on the information made available to us and the engagement \\nconditions detailed in this report. DNV can not guarantee the accuracy or correctness of this information. Hence, DNV\\ncannot be held liable by any party for decisions made or not made based on this report. \\n \\nReport No.: Sub ject Group:\\n2009-0278 Environment  Indexing terms \\nReport title: Ke y words Service Area\\nVerification \\nMarket Sector \\n“Chuanwei Group 24 MW Waste Gas based \\nCaptive Power Plant” \\n Climate Change \\nKyoto Protocol \\nValidation \\nClean Development \\nMechanism \\nProcess Industry \\nWork carried out by: \\nTao Li, Peng Huang, Cuiping Deng  \\nWork verified by: \\nGuo Kang  \\nDate of this revision: Rev. No.: Number of pages:\\n2009-03-27 01 21  \\n No distribution without permission from the \\nclient or responsible organisational unit \\n \\n free distribution within DNV after 3 years \\n \\n Strictly confidential \\n \\n Unrestricted distribution \\n \\n© 2002 Det Norske Veritas AS \\nAll rights reserved. This publication or parts thereof may not be reproduced or transmitted in any form or by any means, including \\nphotocopying or recording, without the prior written consent of Det Norske Veritas AS. \\n '),\n",
       "  0.9956974),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/VER_Verification Report-Chuanwei WG 24MW_Approved _1_.pdf', 'page': 8}, page_content='DET NORSKE VERITAS \\nReport No: 2009-0278 , rev. 01 \\nVCS VERIFICATION / CERTIFICATION REPORT \\nPage 4 \\nReference to part of this report which may lead to misinterpretation is not permissible.  \\ngrid emission coefficient of 0.97505 tCO 2e/MWh and deduct the project emission according to \\nthe registered PDD. \\nTitle of the project activity:  Chuanwei Group 24 MW Waste Gas based Captive Power \\nPlant \\nLocation of the project activity:  Lianjie Town, Weiyuan County, Neijiang City of Sichuan \\n Province, P.R.China. \\nVerification period:  01 Janua ry 2007 to 09 September 2008  \\nProject starting date:  06 July 200 6 (project commissioning date /19/) \\n \\n1.4 Level of assurance \\nDuring the verification, DNV has focused on providing a reasonable level of assurance that; \\n- the emission reduction calculation methodology used is appropriate and correctly applied, \\nand  \\n- the emission reductions have been accurately monitored for 1# and 7# power generators. \\n2 METHODOLOGY  \\nThe verification of the emission reductions has asse ssed all factors and issues that constitute the \\nbasis for emission reductions from the projec t according to the applicable CDM methodology \\nACM0004 – “Consolidated methodology for waste gas and/or heat for power generation” \\n(version 2) including \\n• The review of the calculation of the carbon emission factor for the CCPG \\n• The net electricity supplied by the project activity to CCPG multiplied by the grid \\nemission factor \\n \\nVerification Team: \\nType of involvement \\nRole/Qualification Last Name First Name Country \\nDesk review \\nSite visit  \\nReporting \\nSupervision of work Technical review \\nExpert input \\nCDM verifier / \\ntechnical team \\nleader \\nDeng Cuiping China    √   \\nGHG auditor / \\nProject manager \\nLi Tao China √ √ √    \\nGHG auditor  Huang Peng China √√  √     \\nTechnical \\nreviewer \\nGuo Kang China     √  \\n \\n '),\n",
       "  0.9932197),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/VER_Verification Report-Chuanwei WG 24MW_Approved _1_.pdf', 'page': 24}, page_content='DET NORSKE VERITAS \\nReport No: 2009-0278 , rev. 01 \\nVCS VERIFICATION / CERTIFICATION REPORT \\nPage 20 \\nReference to part of this report which may lead to misinterpretation is not permissible.  \\n6 REFERENCES \\n \\n/1/ Monitoring Report of Chuanwei Group 24 MW  Waste Gas based Captive Power Plant, \\nversion 1 dated 13 November 2008, version 2 dated 10 January 2009, version 3 dated \\n13 February 2009, version 4 dated 20 March and version 5.1 dated 23 March 2009. \\n/2/ PDD for Chuanwei Group 24 MW Waste Gas based Captive Power Plant’ Version 6 of \\n05 August 2008. \\n/3/ Power Purchase Agreement between Chuanwei Group Ltd and CCPG, 08 July 2006 \\nPower Purchase Agreement between Neijiang Xingming Energy Co., Ltd. and Weiyuan \\nSteel company 10 September 2005 \\n/4/ Generator Test and Joint Inspecti on Report by Chuanwei Group Ltd, 06 July 2006. \\n/5/ Validation Report by DNV, version 2, report number: 2007-0849 dated 20 August 2008.\\n/6/ Emission Reduction calculation spreadsheet dated 13 February 2009 \\n/7/ Business License of the project owner, available from 30 March 2005 \\n/8/ Sales receipts for electricity of Weiyuan Steel company and NG purchase receipts of \\nNeijiang Xingming Energy Co., Ltd from January 2007 to September 2008 \\n/9/ Calibration report for all el ectricity and gas meters valid from 2006 to 2008.(Annex 2) \\n/10/ Power station running recording from December 2006 to September 2008 \\n/11/ Project feasibility study report, April 2004 and approval letter by the Sichuan Province \\nEconomic commission, October 2005. \\n/12/ Environmental impact assessment in November 2005 and approval letter by the \\nEnvironmental Protection Bureau of Sichuan Province on December 2005. \\n/13/ Running report of include the number of electricity generation, electricity consumption, \\nNG and COG consumption from the DCS system from December 2006 to September \\n2008 \\n/14/ International Emission Trading Associ ation (IETA) & the World Bank’s Prototype \\nCarbon Fund (PCF), Validation and Verification Manual. \\nhttp://www.ieta.org/ieta/www/pages/index.php?IdSitePage=200 \\n/15/ ACM0004 Consolidated methodology for wast e gas and/or heat for power generation \\nVersion 2, dated 03 March 2006 to 05 July 2007.  \\nACM0002 – Approved Consolidated baseli ne and monitoring methodology Date 19 \\nMay 2006 \\n/16/ CDM Executive Board: Tool for the demonstration and assessment of additionality , \\nversion 03 of 16 February 2007 \\n/17/ Voluntary Carbon Standard 2007 (VCS 2007.1), 18 November 2008. '),\n",
       "  0.93892473),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/VER_Verification Report-Chuanwei WG 24MW_Approved _1_.pdf', 'page': 7}, page_content='DET NORSKE VERITAS \\nReport No: 2009-0278 , rev. 01 \\nVCS VERIFICATION / CERTIFICATION REPORT \\nPage 3 \\nReference to part of this report which may lead to misinterpretation is not permissible.  \\n1.3 VCS Project Description \\n1.3.1 Project Category \\nAccording to Annex A of the Kyoto Protocol, the project is applicable under the sectoral scope 1 \\n- Energy Industries (renewable/ non-renewable sources). \\n1.3.2 Geographic Location \\nThe project is located at the Lianjie Town, Weiyuan County, Ne ijiang City of Sichuan Province, \\nP.R.China. \\n1.3.3 Project Background \\nThe project is a waste gas based captive power  plant which will combust blast furnace gas \\n(hereafter referred to as BFG). The natural gas (hereafter referred to as NG) and Coke-Oven Gas \\n(hereafter referred to as COG) will be used as a uxiliary fuel gas. The installed capacity of the \\nproject is 24 MW consisting of 2 sets of  12 MW condensing generators. The details of the \\ngenerators with respect to their numbers, type a nd model of the machines have been verified to \\nbe as per details provided in the registered CDM PDD /2/ \\nThe two condensing generators, located in the power plant of Chuanwei Group, are named as 1# \\ngenerator and 7# generator, separately. During the site visit, besides those two generators, there \\nhave 5 other small generators in the power pl ant, which are named as from 2# generator to 6# \\ngenerator. However, as per PDD, these 5 genera tors are not included in the project activity. The \\ninstall capacity of each generator for 2# to 6# is 3 MW each. During the site visit, each generator \\ninclude 1# to 7# generator has th eir individual meter to monitor the electricity generation and \\nconsumption, so the data 1# and 7# can be ve rified based on the running record and \\nreport/10//13/..The quantity of auxiliary gas include NG and COG for 1# and 7# were monitored \\nwith other 5 generators, for conservative purpos e, the emission caused by total consumption of \\nauxiliary gas for 7 generators were considered  as the project emission when calculated the \\nemission reduction. \\nThe project activity is registered as CD M project activity unde r the UNFCCC with the \\nRegistration Ref. No. being 1470 and with the CDM crediting period of the project starting on 10 \\nSeptember 2008. \\nThe CDM baseline and monitoring methodol ogies used is ACM0004 – “Consolidated \\nmethodology for waste gas and/or heat for power generation” (version 2) \\nThe electricity generated is s upplied to Weiyuan Steel Company which belongs to Chuanwei \\nGroup and displacing part of electr icity supplied by fossil fuel-fired  power plants of the Central \\nChina Power Grid (which is dominated by co al-fired power plants ) under Power Purchase \\nAgreements (PPAs) signed by Weiyuan Steel Company and the Power plant /3/.  \\nThe 7# generator was tested and approved connect to the Chuanwei Group and send electricity to \\nWeiyuan Steel company at 06 July 2006 /19/, 7# ge nerator is the last generator which approved \\nconnect to the Chuanwei Group, so the date of 06 July 2006 was considered as project starting \\ndate. \\nThe project participant claimed for emission reductions generate d by the proposed project from \\n01 January 2007 to 09 September 2008. The projects  emission reductions are determined by \\nmultiplying the net amount of electricity generated by the project by an estimated ex-ante fixed '),\n",
       "  0.9223952),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/VER_Verification Report-Chuanwei WG 24MW_Approved _1_.pdf', 'page': 0}, page_content=' \\n  \\nVCS VERIFICATION / \\nCERTIFICATION REPORT  \\n \\nDET NORSKE VERITAS \\nVOLUNTARY CARBON STANDARD \\n \\n \\n \\n \\n“CHUANWEI GROUP 24 MW \\nWASTE GAS BASED CAPTIVE \\nPOWER PLANT \\n \\nVERIFICATION PERIOD: \\n01 JANUARY 2007 TO 09 SEPTEMBER 2008 \\n \\nREPORT NO. 2009-0278 \\nREVISION NO. 01 \\n'),\n",
       "  0.87139493),\n",
       " (Document(metadata={'source': '../data/verra/projects/VCS/12/registration/VER_Verification Report-Chuanwei WG 24MW_Approved _1_.pdf', 'page': 11}, page_content=\"DET NORSKE VERITAS \\nReport No: 2009-0278 , rev. 01 \\nVCS VERIFICATION / CERTIFICATION REPORT \\nPage 7 \\nReference to part of this report which may lead to misinterpretation is not permissible.  \\n3 VERIFICATION FINDINGS \\n3.1 Remaining issues, including any material discrepancy, from previous \\nvalidation \\nThe validation report does not identify any remaining issues to be checked during verification. \\n3.2 Project Implementation \\nDNV has checked the name plate and the running r ecord and verified the capacity of 1# and 7# \\ngenerators to be 24 MW in total. The commissi oning dates of the genera tors were 06 July 2006 \\n/19/ \\nThe project activity involves implementation and operation of a 24 MW Waste Gas based \\nCaptive Power Plant that comprises 2 sets of 12 MW generators; the project is to utilize the \\nwaste gas (BFG) of Chuanwei Gr oup which would be flared in th e absence of the project to \\ngenerate electricity, displacing part of internal use electricity supplied by fossil fuel-fired power \\nplants of the CCPG (Central China Power Grid).  \\nThe net electricity generation and gas consumpti on data considered for the project period of 01 \\nJanuary 2007 to 09 September 2008 has been verified by reviewi ng the ‘Power Station Running \\nRecording /10/ and relevant receipts /8/. The electricity meters and gas meters calibration reports \\n/9/ of the project have been verified and found to be in order. \\nIn the registered PDD (B.7.1): \\nSix meters installed to monito ring the electricity import and export. Include meter 501, 502 and \\n503 for 1# generator, 581, 582 and 583 for 7# generator. \\n501, 581 monitoring the electricity output from  the generators, 502, 582 monitoring the \\nelectricity consumption, these 4 meters instal l at the power plant, 503, 583 monitoring the net \\nelectricity supply installed at substation. \\nBut during the site visit, DNV is able to conf irm that except 1# and 7# generators, the project \\nowner have other 5 generators named 2# to 6# generator, 503 and 583 in stalled at the power \\nplant and not monitoring this project's data. \\n501, 581 monitoring the electricity output from  the generators, 502, 582 monitoring the \\nelectricity consumption, these 4 meters install at the power plant as per the registered PDD \\n651, 652, 654, 655 installed at substation monitoring the total net electricity supply from 1# to 7# \\ngenerator instead. The invoices fo r total net electricity were pub lished based on these 4 meters' \\naggregated data. So the total electricity for all generators can be cross checked by invoice /8/. \\nAs per the ACM0004 version 2, electricity genera tion and electricity consumption need to be \\nmonitored. These data were monitored by 501, 502, 581 and 582, the net electricity is calculated \\nfrom the measuring data, so the implementation in line with the methodology. \\nThrough on site visit, DNV is able to confirm th at each generator meter for 1# to 7# has their \\nindividual electricity meter to monitoring the electricity export and se lf consumption, these \\nmeters were installed at the power plant and co ntinuously recorded by DCS, all meters for 1# to \\n7# and 651, 652, 654, 655 were calibrated according to  the national and industrial regulation /9/ \\nand registered PDD /2/. \"),\n",
       "  0.8120394)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-h1y_eAHmD-",
    "outputId": "4a6097fb-e30e-4fa2-ff4d-b972ce7f6154"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FAISS.load_local() missing 1 required positional argument: 'embeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m index_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaiss_index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Reload the FAISS index\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: FAISS.load_local() missing 1 required positional argument: 'embeddings'"
     ]
    }
   ],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal.\n",
    "# Path to the saved FAISS index\n",
    "index_path = \"faiss_index\"\n",
    "\n",
    "# Reload the FAISS index\n",
    "vectordb = FAISS.load_local(index_path, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class FAISS in module langchain_community.vectorstores.faiss:\n",
      "\n",
      "class FAISS(langchain_core.vectorstores.base.VectorStore)\n",
      " |  FAISS(embedding_function: 'Union[Callable[[str], List[float]], Embeddings]', index: 'Any', docstore: 'Docstore', index_to_docstore_id: 'Dict[int, str]', relevance_score_fn: 'Optional[Callable[[float], float]]' = None, normalize_L2: 'bool' = False, distance_strategy: 'DistanceStrategy' = <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>)\n",
      " |  \n",
      " |  FAISS vector store integration.\n",
      " |  \n",
      " |  See [The FAISS Library](https://arxiv.org/pdf/2401.08281) paper.\n",
      " |  \n",
      " |  Setup:\n",
      " |      Install ``langchain_community`` and ``faiss-cpu`` python packages.\n",
      " |  \n",
      " |      .. code-block:: bash\n",
      " |  \n",
      " |          pip install -qU langchain_community faiss-cpu\n",
      " |  \n",
      " |  Key init args — indexing params:\n",
      " |      embedding_function: Embeddings\n",
      " |          Embedding function to use.\n",
      " |  \n",
      " |  Key init args — client params:\n",
      " |      index: Any\n",
      " |          FAISS index to use.\n",
      " |      docstore: Docstore\n",
      " |          Docstore to use.\n",
      " |      index_to_docstore_id: Dict[int, str]\n",
      " |          Mapping of index to docstore id.\n",
      " |  \n",
      " |  Instantiate:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          import faiss\n",
      " |          from langchain_community.vectorstores import FAISS\n",
      " |          from langchain_community.docstore.in_memory import InMemoryDocstore\n",
      " |          from langchain_openai import OpenAIEmbeddings\n",
      " |  \n",
      " |          index = faiss.IndexFlatL2(len(OpenAIEmbeddings().embed_query(\"hello world\")))\n",
      " |  \n",
      " |          vector_store = FAISS(\n",
      " |              embedding_function=OpenAIEmbeddings(),\n",
      " |              index=index,\n",
      " |              docstore= InMemoryDocstore(),\n",
      " |              index_to_docstore_id={}\n",
      " |          )\n",
      " |  \n",
      " |  Add Documents:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          from langchain_core.documents import Document\n",
      " |  \n",
      " |          document_1 = Document(page_content=\"foo\", metadata={\"baz\": \"bar\"})\n",
      " |          document_2 = Document(page_content=\"thud\", metadata={\"bar\": \"baz\"})\n",
      " |          document_3 = Document(page_content=\"i will be deleted :(\")\n",
      " |  \n",
      " |          documents = [document_1, document_2, document_3]\n",
      " |          ids = [\"1\", \"2\", \"3\"]\n",
      " |          vector_store.add_documents(documents=documents, ids=ids)\n",
      " |  \n",
      " |  Delete Documents:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          vector_store.delete(ids=[\"3\"])\n",
      " |  \n",
      " |  Search:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          results = vector_store.similarity_search(query=\"thud\",k=1)\n",
      " |          for doc in results:\n",
      " |              print(f\"* {doc.page_content} [{doc.metadata}]\")\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          * thud [{'bar': 'baz'}]\n",
      " |  \n",
      " |  Search with filter:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          results = vector_store.similarity_search(query=\"thud\",k=1,filter={\"bar\": \"baz\"})\n",
      " |          for doc in results:\n",
      " |              print(f\"* {doc.page_content} [{doc.metadata}]\")\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          * thud [{'bar': 'baz'}]\n",
      " |  \n",
      " |  Search with score:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          results = vector_store.similarity_search_with_score(query=\"qux\",k=1)\n",
      " |          for doc, score in results:\n",
      " |              print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          * [SIM=0.335304] foo [{'baz': 'bar'}]\n",
      " |  \n",
      " |  Async:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          # add documents\n",
      " |          # await vector_store.aadd_documents(documents=documents, ids=ids)\n",
      " |  \n",
      " |          # delete documents\n",
      " |          # await vector_store.adelete(ids=[\"3\"])\n",
      " |  \n",
      " |          # search\n",
      " |          # results = vector_store.asimilarity_search(query=\"thud\",k=1)\n",
      " |  \n",
      " |          # search with score\n",
      " |          results = await vector_store.asimilarity_search_with_score(query=\"qux\",k=1)\n",
      " |          for doc,score in results:\n",
      " |              print(f\"* [SIM={score:3f}] {doc.page_content} [{doc.metadata}]\")\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          * [SIM=0.335304] foo [{'baz': 'bar'}]\n",
      " |  \n",
      " |  Use as Retriever:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          retriever = vector_store.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={\"k\": 1, \"fetch_k\": 2, \"lambda_mult\": 0.5},\n",
      " |          )\n",
      " |          retriever.invoke(\"thud\")\n",
      " |  \n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |          [Document(metadata={'bar': 'baz'}, page_content='thud')]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      FAISS\n",
      " |      langchain_core.vectorstores.base.VectorStore\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, embedding_function: 'Union[Callable[[str], List[float]], Embeddings]', index: 'Any', docstore: 'Docstore', index_to_docstore_id: 'Dict[int, str]', relevance_score_fn: 'Optional[Callable[[float], float]]' = None, normalize_L2: 'bool' = False, distance_strategy: 'DistanceStrategy' = <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>)\n",
      " |      Initialize with necessary components.\n",
      " |  \n",
      " |  async aadd_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more texts through the embeddings and add to the vectorstore\n",
      " |          asynchronously.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts: Iterable of strings to add to the vectorstore.\n",
      " |          metadatas: Optional list of metadatas associated with the texts.\n",
      " |          ids: Optional list of unique IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of ids from adding the texts into the vectorstore.\n",
      " |  \n",
      " |  add_embeddings(self, text_embeddings: 'Iterable[Tuple[str, List[float]]]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Add the given texts and embeddings to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          text_embeddings: Iterable pairs of string and embedding to\n",
      " |              add to the vectorstore.\n",
      " |          metadatas: Optional list of metadatas associated with the texts.\n",
      " |          ids: Optional list of unique IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of ids from adding the texts into the vectorstore.\n",
      " |  \n",
      " |  add_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more texts through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts: Iterable of strings to add to the vectorstore.\n",
      " |          metadatas: Optional list of metadatas associated with the texts.\n",
      " |          ids: Optional list of unique IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of ids from adding the texts into the vectorstore.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance asynchronously.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch before filtering (if needed) to\n",
      " |                   pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance asynchronously.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch before filtering to\n",
      " |                   pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search_with_score_by_vector(self, embedding: 'List[float]', *, k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None) -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs and their similarity scores selected using the maximal marginal\n",
      " |          relevance asynchronously.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch before filtering to\n",
      " |                   pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents and similarity scores selected by maximal marginal\n",
      " |              relevance and score for each.\n",
      " |  \n",
      " |  async asimilarity_search(self, query: 'str', k: 'int' = 4, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query asynchronously.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          filter: (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |          fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      " |                    Defaults to 20.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents most similar to the query.\n",
      " |  \n",
      " |  async asimilarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to embedding vector asynchronously.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata.\n",
      " |              Defaults to None. If a callable, it must take as input the\n",
      " |              metadata dict of Document and return a bool.\n",
      " |      \n",
      " |          fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      " |                    Defaults to 20.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents most similar to the embedding.\n",
      " |  \n",
      " |  async asimilarity_search_with_score(self, query: 'str', k: 'int' = 4, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs most similar to query asynchronously.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata.\n",
      " |              Defaults to None. If a callable, it must take as input the\n",
      " |              metadata dict of Document and return a bool.\n",
      " |      \n",
      " |          fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      " |                    Defaults to 20.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of documents most similar to the query text with\n",
      " |          L2 distance in float. Lower score represents more similarity.\n",
      " |  \n",
      " |  async asimilarity_search_with_score_by_vector(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs most similar to query asynchronously.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding vector to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, Any]]): Filter by metadata.\n",
      " |              Defaults to None. If a callable, it must take as input the\n",
      " |              metadata dict of Document and return a bool.\n",
      " |      \n",
      " |          fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      " |                    Defaults to 20.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Can include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of documents most similar to the query text and L2 distance\n",
      " |          in float for each. Lower score represents more similarity.\n",
      " |  \n",
      " |  delete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'Optional[bool]'\n",
      " |      Delete by ID. These are the IDs in the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to delete.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Optional[bool]: True if deletion is successful,\n",
      " |          False otherwise, None if not implemented.\n",
      " |  \n",
      " |  max_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch before filtering (if needed) to\n",
      " |                   pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  max_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch before filtering to\n",
      " |                   pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  max_marginal_relevance_search_with_score_by_vector(self, embedding: 'List[float]', *, k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None) -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs and their similarity scores selected using the maximal marginal\n",
      " |          relevance.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch before filtering to\n",
      " |                   pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents and similarity scores selected by maximal marginal\n",
      " |              relevance and score for each.\n",
      " |  \n",
      " |  merge_from(self, target: 'FAISS') -> 'None'\n",
      " |      Merge another FAISS object with the current one.\n",
      " |      \n",
      " |      Add the target FAISS to the current one.\n",
      " |      \n",
      " |      Args:\n",
      " |          target: FAISS object you wish to merge into the current one\n",
      " |      \n",
      " |      Returns:\n",
      " |          None.\n",
      " |  \n",
      " |  save_local(self, folder_path: 'str', index_name: 'str' = 'index') -> 'None'\n",
      " |      Save FAISS index, docstore, and index_to_docstore_id to disk.\n",
      " |      \n",
      " |      Args:\n",
      " |          folder_path: folder path to save index, docstore,\n",
      " |              and index_to_docstore_id to.\n",
      " |          index_name: for saving with a specific index file name\n",
      " |  \n",
      " |  serialize_to_bytes(self) -> 'bytes'\n",
      " |      Serialize FAISS index, docstore, and index_to_docstore_id to bytes.\n",
      " |  \n",
      " |  similarity_search(self, query: 'str', k: 'int' = 4, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          filter: (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |          fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      " |                    Defaults to 20.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents most similar to the query.\n",
      " |  \n",
      " |  similarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, Any]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to embedding vector.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata.\n",
      " |              Defaults to None. If a callable, it must take as input the\n",
      " |              metadata dict of Document and return a bool.\n",
      " |      \n",
      " |          fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      " |                    Defaults to 20.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents most similar to the embedding.\n",
      " |  \n",
      " |  similarity_search_with_score(self, query: 'str', k: 'int' = 4, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs most similar to query.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata.\n",
      " |              Defaults to None. If a callable, it must take as input the\n",
      " |              metadata dict of Document and return a bool.\n",
      " |      \n",
      " |          fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      " |                    Defaults to 20.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of documents most similar to the query text with\n",
      " |          L2 distance in float. Lower score represents more similarity.\n",
      " |  \n",
      " |  similarity_search_with_score_by_vector(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Union[Callable, Dict[str, Any]]]' = None, fetch_k: 'int' = 20, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs most similar to query.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding vector to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Union[Callable, Dict[str, Any]]]): Filter by metadata.\n",
      " |              Defaults to None. If a callable, it must take as input the\n",
      " |              metadata dict of Document and return a bool.\n",
      " |          fetch_k: (Optional[int]) Number of Documents to fetch before filtering.\n",
      " |                    Defaults to 20.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Can include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of documents most similar to the query text and L2 distance\n",
      " |          in float for each. Lower score represents more similarity.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  async afrom_embeddings(text_embeddings: 'Iterable[Tuple[str, List[float]]]', embedding: 'Embeddings', metadatas: 'Optional[Iterable[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'FAISS' from abc.ABCMeta\n",
      " |      Construct FAISS wrapper from raw documents asynchronously.\n",
      " |  \n",
      " |  async afrom_texts(texts: 'list[str]', embedding: 'Embeddings', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'FAISS' from abc.ABCMeta\n",
      " |      Construct FAISS wrapper from raw documents asynchronously.\n",
      " |      \n",
      " |      This is a user friendly interface that:\n",
      " |          1. Embeds documents.\n",
      " |          2. Creates an in memory docstore\n",
      " |          3. Initializes the FAISS database\n",
      " |      \n",
      " |      This is intended to be a quick way to get started.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from langchain_community.vectorstores import FAISS\n",
      " |              from langchain_community.embeddings import OpenAIEmbeddings\n",
      " |      \n",
      " |              embeddings = OpenAIEmbeddings()\n",
      " |              faiss = await FAISS.afrom_texts(texts, embeddings)\n",
      " |  \n",
      " |  deserialize_from_bytes(serialized: 'bytes', embeddings: 'Embeddings', *, allow_dangerous_deserialization: 'bool' = False, **kwargs: 'Any') -> 'FAISS' from abc.ABCMeta\n",
      " |      Deserialize FAISS index, docstore, and index_to_docstore_id from bytes.\n",
      " |  \n",
      " |  from_embeddings(text_embeddings: 'Iterable[Tuple[str, List[float]]]', embedding: 'Embeddings', metadatas: 'Optional[Iterable[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'FAISS' from abc.ABCMeta\n",
      " |      Construct FAISS wrapper from raw documents.\n",
      " |      \n",
      " |      This is a user friendly interface that:\n",
      " |          1. Embeds documents.\n",
      " |          2. Creates an in memory docstore\n",
      " |          3. Initializes the FAISS database\n",
      " |      \n",
      " |      This is intended to be a quick way to get started.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from langchain_community.vectorstores import FAISS\n",
      " |              from langchain_community.embeddings import OpenAIEmbeddings\n",
      " |      \n",
      " |              embeddings = OpenAIEmbeddings()\n",
      " |              text_embeddings = embeddings.embed_documents(texts)\n",
      " |              text_embedding_pairs = zip(texts, text_embeddings)\n",
      " |              faiss = FAISS.from_embeddings(text_embedding_pairs, embeddings)\n",
      " |  \n",
      " |  from_texts(texts: 'List[str]', embedding: 'Embeddings', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'FAISS' from abc.ABCMeta\n",
      " |      Construct FAISS wrapper from raw documents.\n",
      " |      \n",
      " |      This is a user friendly interface that:\n",
      " |          1. Embeds documents.\n",
      " |          2. Creates an in memory docstore\n",
      " |          3. Initializes the FAISS database\n",
      " |      \n",
      " |      This is intended to be a quick way to get started.\n",
      " |      \n",
      " |      Example:\n",
      " |          .. code-block:: python\n",
      " |      \n",
      " |              from langchain_community.vectorstores import FAISS\n",
      " |              from langchain_community.embeddings import OpenAIEmbeddings\n",
      " |      \n",
      " |              embeddings = OpenAIEmbeddings()\n",
      " |              faiss = FAISS.from_texts(texts, embeddings)\n",
      " |  \n",
      " |  load_local(folder_path: 'str', embeddings: 'Embeddings', index_name: 'str' = 'index', *, allow_dangerous_deserialization: 'bool' = False, **kwargs: 'Any') -> 'FAISS' from abc.ABCMeta\n",
      " |      Load FAISS index, docstore, and index_to_docstore_id from disk.\n",
      " |      \n",
      " |      Args:\n",
      " |          folder_path: folder path to load index, docstore,\n",
      " |              and index_to_docstore_id from.\n",
      " |          embeddings: Embeddings to use when generating queries\n",
      " |          index_name: for saving with a specific index file name\n",
      " |          allow_dangerous_deserialization: whether to allow deserialization\n",
      " |              of the data which involves loading a pickle file.\n",
      " |              Pickle files can be modified by malicious actors to deliver a\n",
      " |              malicious payload that results in execution of\n",
      " |              arbitrary code on your machine.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  embeddings\n",
      " |      Access the query embedding object if available.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.vectorstores.base.VectorStore:\n",
      " |  \n",
      " |  async aadd_documents(self, documents: 'list[Document]', **kwargs: 'Any') -> 'list[str]'\n",
      " |      Async run more documents through the embeddings and add to\n",
      " |      the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents: Documents to add to the vectorstore.\n",
      " |          kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of IDs of the added texts.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the number of IDs does not match the number of documents.\n",
      " |  \n",
      " |  add_documents(self, documents: 'list[Document]', **kwargs: 'Any') -> 'list[str]'\n",
      " |      Add or update documents in the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents: Documents to add to the vectorstore.\n",
      " |          kwargs: Additional keyword arguments.\n",
      " |              if kwargs contains ids and documents contain ids,\n",
      " |              the ids in the kwargs will receive precedence.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of IDs of the added texts.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the number of ids does not match the number of documents.\n",
      " |  \n",
      " |  async adelete(self, ids: 'Optional[list[str]]' = None, **kwargs: 'Any') -> 'Optional[bool]'\n",
      " |      Async delete by vector ID or other criteria.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to delete. If None, delete all. Default is None.\n",
      " |          **kwargs: Other keyword arguments that subclasses might use.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Optional[bool]: True if deletion is successful,\n",
      " |          False otherwise, None if not implemented.\n",
      " |  \n",
      " |  async aget_by_ids(self, ids: 'Sequence[str]', /) -> 'list[Document]'\n",
      " |      Async get documents by their IDs.\n",
      " |      \n",
      " |      The returned documents are expected to have the ID field set to the ID of the\n",
      " |      document in the vector store.\n",
      " |      \n",
      " |      Fewer documents may be returned than requested if some IDs are not found or\n",
      " |      if there are duplicated IDs.\n",
      " |      \n",
      " |      Users should not assume that the order of the returned documents matches\n",
      " |      the order of the input IDs. Instead, users should rely on the ID field of the\n",
      " |      returned documents.\n",
      " |      \n",
      " |      This method should **NOT** raise exceptions if no documents are found for\n",
      " |      some IDs.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to retrieve.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents.\n",
      " |      \n",
      " |      .. versionadded:: 0.2.11\n",
      " |  \n",
      " |  as_retriever(self, **kwargs: 'Any') -> 'VectorStoreRetriever'\n",
      " |      Return VectorStoreRetriever initialized from this VectorStore.\n",
      " |      \n",
      " |      Args:\n",
      " |          **kwargs: Keyword arguments to pass to the search function.\n",
      " |              Can include:\n",
      " |              search_type (Optional[str]): Defines the type of search that\n",
      " |                  the Retriever should perform.\n",
      " |                  Can be \"similarity\" (default), \"mmr\", or\n",
      " |                  \"similarity_score_threshold\".\n",
      " |              search_kwargs (Optional[Dict]): Keyword arguments to pass to the\n",
      " |                  search function. Can include things like:\n",
      " |                      k: Amount of documents to return (Default: 4)\n",
      " |                      score_threshold: Minimum relevance threshold\n",
      " |                          for similarity_score_threshold\n",
      " |                      fetch_k: Amount of documents to pass to MMR algorithm\n",
      " |                          (Default: 20)\n",
      " |                      lambda_mult: Diversity of results returned by MMR;\n",
      " |                          1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
      " |                      filter: Filter by document metadata\n",
      " |      \n",
      " |      Returns:\n",
      " |          VectorStoreRetriever: Retriever class for VectorStore.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # Retrieve more documents with higher diversity\n",
      " |          # Useful if your dataset has many similar documents\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
      " |          )\n",
      " |      \n",
      " |          # Fetch more documents for the MMR algorithm to consider\n",
      " |          # But only return the top 5\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={'k': 5, 'fetch_k': 50}\n",
      " |          )\n",
      " |      \n",
      " |          # Only retrieve documents that have a relevance score\n",
      " |          # Above a certain threshold\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"similarity_score_threshold\",\n",
      " |              search_kwargs={'score_threshold': 0.8}\n",
      " |          )\n",
      " |      \n",
      " |          # Only get the single most similar document from the dataset\n",
      " |          docsearch.as_retriever(search_kwargs={'k': 1})\n",
      " |      \n",
      " |          # Use a filter to only retrieve documents from a specific paper\n",
      " |          docsearch.as_retriever(\n",
      " |              search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}}\n",
      " |          )\n",
      " |  \n",
      " |  async asearch(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'list[Document]'\n",
      " |      Async return docs most similar to query using a specified search type.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Input text.\n",
      " |          search_type: Type of search to perform. Can be \"similarity\",\n",
      " |              \"mmr\", or \"similarity_score_threshold\".\n",
      " |          **kwargs: Arguments to pass to the search method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents most similar to the query.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If search_type is not one of \"similarity\",\n",
      " |              \"mmr\", or \"similarity_score_threshold\".\n",
      " |  \n",
      " |  async asimilarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'list[tuple[Document, float]]'\n",
      " |      Async return docs and relevance scores in the range [0, 1].\n",
      " |      \n",
      " |      0 is dissimilar, 1 is most similar.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Input text.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Tuples of (doc, similarity_score)\n",
      " |  \n",
      " |  get_by_ids(self, ids: 'Sequence[str]', /) -> 'list[Document]'\n",
      " |      Get documents by their IDs.\n",
      " |      \n",
      " |      The returned documents are expected to have the ID field set to the ID of the\n",
      " |      document in the vector store.\n",
      " |      \n",
      " |      Fewer documents may be returned than requested if some IDs are not found or\n",
      " |      if there are duplicated IDs.\n",
      " |      \n",
      " |      Users should not assume that the order of the returned documents matches\n",
      " |      the order of the input IDs. Instead, users should rely on the ID field of the\n",
      " |      returned documents.\n",
      " |      \n",
      " |      This method should **NOT** raise exceptions if no documents are found for\n",
      " |      some IDs.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to retrieve.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents.\n",
      " |      \n",
      " |      .. versionadded:: 0.2.11\n",
      " |  \n",
      " |  search(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'list[Document]'\n",
      " |      Return docs most similar to query using a specified search type.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Input text\n",
      " |          search_type: Type of search to perform. Can be \"similarity\",\n",
      " |              \"mmr\", or \"similarity_score_threshold\".\n",
      " |          **kwargs: Arguments to pass to the search method.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents most similar to the query.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If search_type is not one of \"similarity\",\n",
      " |              \"mmr\", or \"similarity_score_threshold\".\n",
      " |  \n",
      " |  similarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'list[tuple[Document, float]]'\n",
      " |      Return docs and relevance scores in the range [0, 1].\n",
      " |      \n",
      " |      0 is dissimilar, 1 is most similar.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Input text.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Tuples of (doc, similarity_score).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.vectorstores.base.VectorStore:\n",
      " |  \n",
      " |  async afrom_documents(documents: 'list[Document]', embedding: 'Embeddings', **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
      " |      Async return VectorStore initialized from documents and embeddings.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents: List of Documents to add to the vectorstore.\n",
      " |          embedding: Embedding function to use.\n",
      " |          kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          VectorStore: VectorStore initialized from documents and embeddings.\n",
      " |  \n",
      " |  from_documents(documents: 'list[Document]', embedding: 'Embeddings', **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
      " |      Return VectorStore initialized from documents and embeddings.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents: List of Documents to add to the vectorstore.\n",
      " |          embedding: Embedding function to use.\n",
      " |          kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          VectorStore: VectorStore initialized from documents and embeddings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.vectorstores.base.VectorStore:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(FAISS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import tempfile\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader\n",
    "\n",
    "\n",
    "def load_file_from_s3(key, bucket_name, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Download the file\n",
    "            file_obj = s3.get_object(Bucket=bucket_name, Key=key)\n",
    "            file_content = file_obj['Body'].read()\n",
    "            #return file_content\n",
    "            # Print the content length and a preview to check if data is being retrieved\n",
    "            content_length = len(file_content)\n",
    "            print(f\"File {key} downloaded with size: {content_length} bytes\")\n",
    "            #print(f\"File content preview (first 100 bytes): {file_content[:100]}\")\n",
    "\n",
    "            # Check for empty content\n",
    "            if content_length == 0:\n",
    "                print(f\"WARNING: No content found in file: s3://{bucket_name}/{key}\")\n",
    "                return []\n",
    "\n",
    "            # Handle .txt files as plain text\n",
    "            if key.endswith('.txt'):\n",
    "                try:\n",
    "                    text_content = file_content.decode('utf-8')\n",
    "                    print(f\"Text content loaded successfully for file: {key}\")\n",
    "                    return text_content\n",
    "                    #return TextLoader(text_content).load()\n",
    "                except UnicodeDecodeError:\n",
    "                    # Log and retry decoding with errors ignored\n",
    "                    text_content = file_content.decode('utf-8', errors='ignore')\n",
    "                    print(f\"WARNING: Non-UTF-8 encoding detected in file {bucket_name}/{key}, decoding with errors ignored.\")\n",
    "                    return TextLoader(text_content).load()\n",
    "\n",
    "            # Handle PDF files by saving to a temporary file for PyPDFLoader\n",
    "            elif key.endswith('.pdf'):\n",
    "                with tempfile.NamedTemporaryFile(suffix=\".pdf\", delete=False) as temp_file:\n",
    "                    temp_file.write(file_content)\n",
    "                    temp_file_path = temp_file.name\n",
    "\n",
    "                print(f\"Loaded binary file into temporary file: {temp_file_path}\")\n",
    "                loaded_data = PyPDFLoader(temp_file_path).load()\n",
    "\n",
    "                # Clean up the temporary file\n",
    "                os.remove(temp_file_path)\n",
    "                return loaded_data\n",
    "\n",
    "        except boto3.exceptions.S3UploadFailedError:\n",
    "            print(f\"ERROR: Failed to access file {bucket_name}/{key}: Network issue or permissions error.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Attempt {attempt + 1} - Error loading file {bucket_name}/{key}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying ({attempt + 1}/{max_retries})...\")\n",
    "            else:\n",
    "                print(f\"ERROR: Failed to load file after {max_retries} attempts: s3://{bucket_name}/{key}\")\n",
    "                return []\n",
    "\n",
    "    # Return empty if all attempts fail\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "key = \"verra/program_notices/txt/Verra Extends Validation Deadline for Plastic Projects.txt\"\n",
    "bucket_name = 'ccex-climate-proj'\n",
    "#a = load_file_from_s3(key, bucket_name, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import S3FileLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'J0GDZ4158N099D1P',\n",
       "  'HostId': 'VoZPqxBocKCdIGkOMAyMHvFZRV5NK4mPtRUUB9QdglPbpM9tsoGD1VatUrEtqKioUmD8mcjFQlY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'VoZPqxBocKCdIGkOMAyMHvFZRV5NK4mPtRUUB9QdglPbpM9tsoGD1VatUrEtqKioUmD8mcjFQlY=',\n",
       "   'x-amz-request-id': 'J0GDZ4158N099D1P',\n",
       "   'date': 'Mon, 04 Nov 2024 13:04:07 GMT',\n",
       "   'last-modified': 'Mon, 04 Nov 2024 07:16:30 GMT',\n",
       "   'etag': '\"46c046c9b56928f41c7674d76051cb4d\"',\n",
       "   'x-amz-server-side-encryption': 'AES256',\n",
       "   'accept-ranges': 'bytes',\n",
       "   'content-type': 'binary/octet-stream',\n",
       "   'content-length': '1022',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'AcceptRanges': 'bytes',\n",
       " 'LastModified': datetime.datetime(2024, 11, 4, 7, 16, 30, tzinfo=tzutc()),\n",
       " 'ContentLength': 1022,\n",
       " 'ETag': '\"46c046c9b56928f41c7674d76051cb4d\"',\n",
       " 'ContentType': 'binary/octet-stream',\n",
       " 'ServerSideEncryption': 'AES256',\n",
       " 'Metadata': {},\n",
       " 'Body': <botocore.response.StreamingBody at 0x10a5f2e80>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.get_object(Bucket=bucket_name, Key=key)#['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 's3://ccex-climate-proj/verra/methodology/pdf/Improved-Grazing-Management-Methodology-v2-4.pdf'}, page_content=\"VCS Methodology for\\n\\nAgricultural Land Management Improved Grassland Management\\n\\nMark Dangerfield Charlie Wilson James Schultz Alex Nimz\\n\\nNovember 2010\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 1\\n\\nAgricultural Land Management – Improved Grassland Management\\n\\nVersion 2.4 November 2010\\n\\nScope\\n\\nThis methodology is for estimating and monitoring the greenhouse gas emission reductions resulting from improved grassland management projects.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 2\\n\\nTable of Contents\\n\\nScope .................................................................................................................................... 2 Table of Contents ................................................................................................................. 3 PART 1 - SOURCES, DEFINITIONS AND APPLICABILITY ............................................................ 6\\n\\n1. Sources ...................................................................................................................... 6 2. Definitions ..................................................................................................................... 7 3. Symbols and Notations .................................................................................................. 7 3.1 Physical quantities ................................................................................................... 8 3.2 Scenario qualifiers ................................................................................................... 8\\n\\n4. Applicability ................................................................................................................... 9\\n\\nPART 2 – STEP-BY-STEP METHODOLOGY DESCRIPTION ....................................................... 10\\n\\nSTEP 0 – Eligibility ............................................................................................................ 12 STEP 1 - Project Boundaries and Scope ............................................................................ 13\\n\\nStep 1.1 Geographical Boundaries ............................................................................... 13 Step 1.2 Temporal Boundaries ..................................................................................... 13 Step 1.3 Carbon Pools.................................................................................................. 14 Step 1.4 Greenhouse Gases ......................................................................................... 14\\n\\nSTEP 2 – Baseline Selection and Additionality .................................................................. 16\\n\\nStep 2.1 Potential baseline scenarios ........................................................................... 16 Step 2.2 Selecting the baseline scenario ...................................................................... 16 Step 2.3 Additionality .................................................................................................. 16\\n\\nSTEP 3 – Ex-ante Grassland Management Plans and Stratification ................................... 17\\n\\nStep 3.1 Grassland Management Plan ........................................................................ 17 Step 3.2 Improved Grassland Management Plan ......................................................... 17 Step 3.3 Select carbon pools and greenhouse gas emission sources ............................ 18 Step 3.4 Stratification .................................................................................................. 20\\n\\nSTEP 4 – Ex-ante Net Greenhouse Gas Emissions in the Baseline Scenario ...................... 22\\n\\nStep 4.1 Determine soil organic carbon stock change in the baseline scenario ............ 22 Step 4.2 Determine carbon stock change in above-ground woody biomass in the baseline scenario ......................................................................................................... 25 Step 4.3 Determine methane production from enteric emissions in the baseline scenario ....................................................................................................................... 29 Step 4.4 Determine greenhouse gas emissions from fossil fuel combustion in the baseline scenario ......................................................................................................... 31 Step 4.5 Determine emissions from fertilizer use in the baseline scenario ................... 32 Step 4.6 Net GHG emissions in the baseline scenario .................................................. 33\\n\\nSTEP 5 – Ex-ante Net Greenhouse Gas Emissions in the Project Scenario ........................ 35\\n\\nStep 5.1 Determine soil organic carbon stock change in the project scenario .............. 35 Step 5.2 Determine carbon stock change in above-ground woody biomass in the project scenario ........................................................................................................... 37\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 3\\n\\nStep 5.3 Estimate methane production from enteric emissions in the project scenario40 Step 5.4 Determine greenhouse gas emissions from fossil fuel combustion in the project scenario ........................................................................................................... 42 Step 5.5 Estimate emissions from fertilizer use in the project scenario ........................ 42 Step 5.6 Estimate net Greenhouse gas emissions in the ex-ante project scenario ........ 44\\n\\nSTEP 6 – Ex-post Grassland Management Plans and stratification ................................... 45\\n\\nStep 6.1 Ex-post Grassland Management Plan ............................................................. 45 Step 6.2 Ex-post Improved Grassland Management Plan ............................................. 46 Step 6.3 Update carbon pools and greenhouse gas emission sources .......................... 46\\n\\nSTEP 7 – Ex post Net Greenhouse Gas Emissions in the baseline scenario ....................... 49\\n\\nStep 7.1 Determine SOC stock change in the baseline scenario ................................... 49 Step 7.2 Determine carbon stock change in above-ground woody biomass in the baseline scenario ......................................................................................................... 49 Step 7.3 Determine methane production from enteric emissions in the ex-post baseline scenario ....................................................................................................................... 53 Step 7.4 Determine emissions from fossil fuel combustion in the ex-post baseline scenario ....................................................................................................................... 55 Step 7.5 Determine emissions from fertilizer use in the ex-post baseline scenario ...... 56 Step 7.6 Net greenhouse gas emissions in the ex-post baseline scenario ..................... 57\\n\\nSTEP 8 – Ex-post Net Greenhouse Gas Emissions in the Project Scenario ......................... 59\\n\\nStep 8.1 Estimate SOC stock change in the ex-post project scenario from SOC modelling .................................................................................................................................... 59 Step 8.2 Validate SOC stock change estimate in the ex-post project scenario .............. 59 Step 8.3 Determine carbon stock change in above-ground woody biomass in the ex- post project scenario ................................................................................................... 62 Step 8.4 Determine emissions from enteric methane production in the ex-post project scenario ....................................................................................................................... 64 Step 8.5 Determine emissions from fossil fuel combustion in the ex-post project scenario ....................................................................................................................... 67 Step 8.6 Determine emissions from fertilizer use in the ex-post project scenario ........ 68 Step 8.7 Net GHG emissions in the ex-post project scenario ........................................ 70\\n\\nSTEP 9 – Project Leakage ................................................................................................. 71\\n\\nStep 9.1 Activity shifting leakage ................................................................................. 71 Step 9.2 Market leakage .............................................................................................. 72\\n\\nSTEP 10 – Net Project Greenhouse Gas Emission Reductions........................................... 74 STEP 11 – Project Voluntary Carbon Units ....................................................................... 75\\n\\nStep 11.1 Adjustment for uncertainty .......................................................................... 75 Step 11.2 Calculation of voluntary carbon units ........................................................... 76\\n\\nSTEP 12 – Project Monitoring .......................................................................................... 77\\n\\nStep 12.1 Scope of monitoring and the monitoring plan .............................................. 77 Step 12.2 Monitoring of project implementation......................................................... 77 Step 12.3 Data inputs to SOC model calibration........................................................... 78\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 4\\n\\nStep 12.4 Disturbance ................................................................................................. 79 Step 12.5 National livestock production ...................................................................... 79 Step 12.6 General requirements for monitoring .......................................................... 80 Step 12.7 Conservative approach and uncertainty ....................................................... 80\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 5\\n\\nPART 1 - SOURCES, DEFINITIONS AND APPLICABILITY\\n\\n1. Sources\\n\\nVCS Program Guidelines 2007.11 VCS Tool for AFOLU Methodological Issues2 Tool for AFOLU Non-Permanence Risk Analysis and Buffer Determination3\\n\\nTool for Calculation of the Number of Sample Plots for Measurements within A/R\\n\\nCDM Project Activities4\\n\\nTool for Demonstration and Assessment of Additionality5 Tool for testing significance of GHG emissions in A/R CDM project activities6\\n\\n1 http://www.v-c-s.org/docs/Voluntary%20Carbon%20Standard%20Program%20Guidelines%202007_1.pdf 2 http://www.v-c-s.org/docs/Tool%20for%20AFOLU%20Methodological%20Issues.pdf 3http://www.v-c-s.org/docs/Tool%20for%20AFOLU%20Non- permanence%20Risk%20Analysis%20and%20Buffer%20Determination.pdf 4 http://cdm.unfccc.int/methodologies/ARmethodologies/approved_ar.html 5 http://cdm.unfccc.int/methodologies/PAmethodologies/tools/am-tool-01-v5.2.pdf 6 http://cdm.unfccc.int/methodologies/ARmethodologies/approved_ar.html\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 6\\n\\n2. Definitions\\n\\nThis methodology uses all VCS approved definitions from the VCS Program Guidelines 2007.17 and the VCS Tool for AFOLU Methodological Issues8.\\n\\nThe definitions in Table 1 are specific to this methodology.\\n\\nTable 1. ALM-IGM Methodology: definitions\\n\\nTerm\\n\\nExplanation\\n\\nGrassland management Activities on lands falling under the VCS definition for Grassland\\n\\nGMP\\n\\nThe Grassland Management Plan that is a description of the activities on grasslands that result in livestock production in the baseline scenario and includes:\\n\\nlivestock type, livestock stocking rate and grazing days per land parcel;\\n\\ngrassland management for forage production including any biomass burning and/or vegetation clearing, and/or pasture improvement;\\n\\nfertilizer use as mass of synthetic fertilizer and/or mass of organic fertilizer to enhance forage production; and\\n\\nfossil fuel consumed (as represented by fuel purchased by fuel type).\\n\\nIGMP\\n\\nThe Improved Grassland Management Plan that is a description of the activities on grasslands that result in livestock production in the project scenario and includes:\\n\\nlivestock type, livestock stocking rate and grazing days per land parcel;\\n\\ngrassland management for forage production including any biomass burning and/or vegetation clearing, and/or pasture improvement;\\n\\nfertilizer use as mass of synthetic fertilizer and/or mass of organic fertilizer to enhance forage production; and\\n\\nfossil fuel consumed (as represented by fuel purchased by fuel type).\\n\\nLand parcel\\n\\nUnit of land management under the GMP and IGMP, usually a paddock or field\\n\\nLivestock\\n\\nAny animals used in a production system and managed as asset\\n\\nSOC\\n\\nSoil organic carbon\\n\\n7 http://www.v-c-s.org/docs/Voluntary%20Carbon%20Standard%20Program%20Guidelines%202007_1.pdf 8 http://www.v-c-s.org/docs/Tool%20for%20AFOLU%20Methodological%20Issues.pdf\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 7\\n\\n3. Symbols and Notations\\n\\n3.1 Physical quantities\\n\\nIn this section we present the symbols that are used throughout the methodology to represent physical quantities used in the accounting equations.\\n\\n3.1.1 Flows of greenhouse gas(es)\\n\\nThe symbol GHG is the common identifier used throughout this methodology to represent flows of greenhouse gas(es) to/from the atmosphere.\\n\\nFor these flows, the absolute value represents the intensity of the flow, in tCO2e year-1, or the total amounts exchanged with the atmosphere, in tCO2e.\\n\\n3.1.2 Carbon stocks\\n\\nThe symbol C is the common identifier used throughout this methodology to represent carbon stocks. The values presented are either carbon stocks (in tC), or carbon stocks per unit area (in tC•ha-1) as indicated in the step-by-step methodology described under Part 2.\\n\\n3.1.3 Carbon stock changes\\n\\nThe symbol ∆C is the common identifier used throughout this methodology to represent changes in carbon stocks. The values presented could be either total changes in carbon stocks (in tC), annual changes in carbon stocks (in tC•year-1), or annual changes in carbon stocks per unit area (in tC•ha-1•year-1), as indicated in the step-by-step methodology described under Part 2.\\n\\n3.2 Scenario qualifiers\\n\\nIn this section we present the symbols that are used throughout the methodology as scenario qualifiers, for the physical quantities used in the accounting equations.\\n\\nPhysical quantities referring to the baseline scenario feature the suffix |BSL;\\n\\nPhysical quantities referring to the project scenario feature the suffix, |PRS; and\\n\\nPhysical quantities derived from baseline and project scenario accounting feature\\n\\nthe suffix |IGM\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 8\\n\\n4. Applicability\\n\\nProject activities must fall within the AFOLU project category “ALM Improved Grassland Management” as defined in the most recent version of the VCS AFOLU Guidance document9.\\n\\nWhere perennial woody species are introduced as part of grassland management, carbon sequestration in perennial woody biomass may be included as part of emission reduction credits. However, projects proponents must demonstrate that they do not harm local ecosystems as outlined in the general AFOLU guidance (see section “B. Community and/or environmental impacts of projects”).\\n\\nSpecific conditions under which this methodology is applicable are:\\n\\nthe boundaries of the project area must be clearly defined;\\n\\nthe baseline scenario must be grassland management;\\n\\na soil organic carbon model applicable to the project area and that satisfies the\\n\\nspecific conditions of this methodology must be available;\\n\\nimproved grassland management activities included in the IGMP must:\\n\\no o decrease the time bare soil is exposed; and/or o\\n\\ndecrease the proportion of bare soil in the landscape; and/or\\n\\nincrease the proportion of perennial species above the baseline scenario;\\n\\nNo improved grassland management activities can result in a land designation\\n\\nchange;\\n\\nthe project area must remain a grass-dominated system throughout the crediting period;\\n\\nimproved grassland management activities must not result in an increase in woody perennials that would reach the threshold for the national definition of forest; and\\n\\nno clearing of vegetation shall occur after the project start date except where the grassland management activities that have been proven to enhance long-term grassland productivity are included in the IGMP.\\n\\n9 http://www.v-c-s.org/docs/Guidance%20for%20AFOLU%20Projects.pdf\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 9\\n\\nPART 2 – STEP-BY-STEP METHODOLOGY DESCRIPTION\\n\\nUnder the VCS standard project proponents shall present conservative estimations of the Agricultural Land Management (ALM) project activity.\\n\\nThe Improved Grassland Management (IGM) methodology presented here is designed as a detailed step-by-step procedure enabling conservative estimation of net GHG emissions resulting from ALM projects which would not be implemented in the absence of carbon finance.\\n\\nThe methodology is organised into nine steps:\\n\\nSTEP 0 – Eligibility, sets the criteria for eligibility of projects under the proposed IGM\\n\\nmethodology;\\n\\nSTEP 1 – Project Boundaries and Scope, provides guidelines for defining the\\n\\ngeographical and temporal boundaries of the project and lists the GHG emissions sources and carbon pools to be included in the project accounts;\\n\\nSTEP 2 – Baseline Selection, Additionality and Baseline Modelling, provides guidelines to select the most conservative baseline scenario and to determine the additionality of the proposed project activities against the baseline selected;\\n\\nSTEP 3 – Ex ante Grassland Management Plans and Stratification, develops ex-ante\\n\\nGrassland Management Plan (GMP) for the baseline scenario and the ex-ante Improved Grassland Management Plan (IGMP) for the project scenario;\\n\\nSTEP 4 – Ex ante Greenhouse Gas Emissions in the Baseline Scenario, provides the\\n\\ndetailed, step-by-step procedure to develop conservative estimates of net greenhouse gas emissions resulting from changes in carbon stocks and GHG emission in the baseline scenario;\\n\\nSTEP 5 – Ex ante Net Greenhouse Gas Emissions in the Project Scenario, provides the\\n\\ndetailed, step-by-step procedure to develop conservative estimates of net greenhouse gas emissions resulting from changes in carbon stocks and GHG emission in the ex-ante project scenario;\\n\\nSTEP 6 – Ex post Grassland Management Plans and Stratification, develops ex-post\\n\\nGrassland Management Plan (GMP) for the baseline scenario and the ex-post Improved Grassland Management Plan (IGMP) for the project scenario;\\n\\nSTEP 7 – Ex post Net Greenhouse Gas Emissions in the Baseline Scenario, provides the detailed, step-by-step procedure to develop conservative estimates of net greenhouse gas emissions resulting from changes in carbon stocks and GHG emission in the ex-post baseline scenario;\\n\\nSTEP 8 – Ex post Net Greenhouse Gas Emissions in the Project scenario, provides the\\n\\ndetailed, step-by-step procedure to develop conservative estimates of net greenhouse gas emissions resulting from changes in carbon stocks and GHG emission in the ex-post project scenario;\\n\\nSTEP 9 – Project Leakage, describes the methodology approach to account for leakage mechanisms arising from the implementation of project activities;\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 10\\n\\nSTEP 10 – Net Project Greenhouse Gas Emission Reductions, provides the\\n\\nmethodological approach to determine the amount of net greenhouse gas emissions at the end of each year on the basis of the estimates of greenhouse gas emissions;\\n\\nSTEP 11 – Project Voluntary Carbon Units, provides the methodological approach to\\n\\ndetermine, on the basis of the amount of net greenhouse gas emissions estimated at Step 6 and deductions to account for risk and uncertainty, the amount of carbon units that should be credited to the project each year over the crediting period; and\\n\\nSTEP 12 – Project Monitoring, provides guidelines for the implementation of a\\n\\nmonitoring plan and identifies monitored parameters to assess carbon stock change and disturbance in the project scenario.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 11\\n\\nSTEP 0 – Eligibility In order to be eligible for crediting under the VCS, ALM project proponents must demonstrate that the project area was not cleared of native ecosystems, such as forests, grasslands, scrublands or wetlands, to create VCUs.\\n\\nDocumented evidence shall be provided in the VCS-PD that no ALM project area was cleared of native ecosystems within the ten years prior to the proposed VCS project start.\\n\\nThe burden of proof rests with the project proponent.\\n\\nLegal right to manage land in a manner aligned to Improved Grazing Management must pre- exist the implementation of the project; subsequently:\\n\\nthe project proponent must provide documentary evidence of the legal right to implement the IGM project activity consistent with land tenure and/or ownership rights; and\\n\\nthe project proponent must demonstrate that project activity is consistent with those permissible under any existing environmental legislation that covers the project area.\\n\\nThis methodology requires the use of a published soil carbon dynamics model, therefore:\\n\\nthe selected soil organic carbon model must be able to generate output based on both the baseline and project scenario land management activities;\\n\\nsoil type classification must be available at a level of precision for classification and area determination required as input to soil carbon models applicable to the project area;\\n\\nthe time of first clearing of native vegetation for land management must be known for the project area;\\n\\nhistorical land management practices for a minimum of 10 years prior to the proposed project start date must be known for the project area or historical soil carbon data for the project area sufficient to calibrate the chosen soil organic carbon model must be available; and\\n\\na digital, spatially explicit map of the project area identifying all strata must be\\n\\navailable or generated.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 12\\n\\nSTEP 1 - Project Boundaries and Scope\\n\\nStep 1.1 Geographical Boundaries\\n\\nProject proponents shall clearly define the spatial boundaries of a project so as to facilitate accurate measuring, monitoring, accounting, and verifying of the project’s emissions reductions and removals.\\n\\nThe ALM project activity may contain more than one discrete area of land.\\n\\nWhen describing physical project boundaries, the following information shall be provided per discrete area:\\n\\nname of the project area (including compartment number, allotment number,\\n\\nlocal name);\\n\\nmap(s) of the area (preferably in digital format);\\n\\ngeographic coordinates of each polygon vertex (preferably obtained from a GPS\\n\\nor from a geo-referenced digital map);\\n\\ntotal land area; and\\n\\ndetails of grassland rights holder and user rights.\\n\\nThe geographic boundaries of an ALM project are fixed and thus do not change over the project lifetime.\\n\\nFollowing the VCS definition of market leakage the geographic boundaries for leakage from market effects are those of the country in which the project area occurs.\\n\\nStep 1.2 Temporal Boundaries\\n\\nThe following temporal boundaries shall be defined:\\n\\nStep 1.2.1 Start date and end date of the “crediting period”\\n\\nThe crediting period is the period of time for which the net GHG emissions reductions or removals will be verified, which under the VCS is equivalent to the project lifetime. The project must have an operating plan covering this period.\\n\\nThe duration of the project activity/crediting period shall be reported in the VCS Project Document (VCS-PD).\\n\\nStep 1.2.2 Duration of the monitoring periods\\n\\nIssuance of Voluntary Carbon Units (VCUs) is subject to monitoring and verification. The minimum duration of a monitoring period is one year and the maximum duration is 10 years.\\n\\nProject proponents are free to decide the periodicity of verifications, however, under the VCS guidelines, if verification does not occur within 5 years, 50% of the buffer account credits are cancelled.\\n\\nBaseline projections shall be annual and be available for each proposed future verification date.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 13\\n\\nStep 1.3 Carbon Pools\\n\\nThe carbon pools included or excluded from the project boundary are shown in Table 2.\\n\\nTable 2: Carbon pools\\n\\nCarbon pools\\n\\nIncluded/Optional/ Excluded\\n\\nJustification / Explanation of choice\\n\\nAbove-ground woody biomass\\n\\nIncluded\\n\\nCarbon in perennial woody biomass.\\n\\nAbove-ground non- woody Biomass\\n\\nExcluded\\n\\nExcluded from ALM projects\\n\\nBelow-ground\\n\\nIncluded\\n\\nIncluded as part of above-ground woody biomass10\\n\\nDead-wood\\n\\nExcluded\\n\\nExcluded from ALM projects\\n\\nHarvested wood products\\n\\nExcluded\\n\\nExcluded from ALM projects\\n\\nLitter\\n\\nExcluded\\n\\nInsignificant and exclusion is conservative\\n\\nSoil organic carbon\\n\\nIncluded\\n\\nSoil carbon is the primary pool of concern for ALM.\\n\\nStep 1.4 Greenhouse Gases\\n\\nThe emissions sources included in or excluded from the project boundary are shown in Table 3.\\n\\nAny one of these sources shall be neglected, i.e., accounted as zero, if the application of the most recent version of the “Tool for testing significance of GHG emissions in A/R CDM project activities” leads to the conclusion that the emission source is insignificant11. In addition, the sum of decreases in carbon pools and increases in emissions that may be neglected shall be less than 5% of the total project GHG benefits (VCS, 2007.1).\\n\\n10 Above-ground woody biomass calculations incorporate below ground biomass calculations, the below- ground biomass pool is not measured separately. 11 http://cdm.unfccc.int/methodologies/ARmethodologies/approved_ar.html\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 14\\n\\nTable 3: Emission sources other than resulting from changes in stocks in carbon pools\\n\\nGas\\n\\nSources\\n\\nIncluded/\\n\\nJustification/explanation of choice\\n\\nExcluded\\n\\nCarbon dioxide (CO2)\\n\\nCombustion of fossil fuels (in vehicles, machinery and equipment)\\n\\nIncluded\\n\\nConservative as emissions will be greater in the baseline scenario than in the project scenario.\\n\\nRemoval of herbaceous vegetation\\n\\nExcluded\\n\\nBased on CDM EB decision reflected in paragraph 11 of the report of the 23rd session of the board: cdm.unfccc.int/Panels/ar/023/ar_023 _rep.pdf\\n\\nMethane (CH4) Combustion of fossil\\n\\nIncluded\\n\\nIncluded as CO2 equivalent emission\\n\\nfuels (in vehicles, machinery and equipment)\\n\\nBurning of Biomass\\n\\nIncluded\\n\\nIncluded as CO2 equivalent emission\\n\\nEnteric emissions\\n\\nIncluded\\n\\nIncluded as CO2 equivalent emission\\n\\nNitrous oxide (N2O)\\n\\nCombustion of fossil fuels (in vehicles, machinery and equipment)\\n\\nIncluded\\n\\nPotential emissions are negligible\\n\\nNitrogen based fertilizer\\n\\nIncluded\\n\\nIncluded as CO2 equivalent emission\\n\\nBurning of Biomass\\n\\nExcluded\\n\\nPotential emissions are negligible\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 15\\n\\nSTEP 2 – Baseline Selection and Additionality\\n\\nStep 2.1 Potential baseline scenarios\\n\\nThe project proponent shall select or establish criteria and procedures for identifying and assessing potential baseline scenarios in accordance with rule 6.3 VCS (2007.1) in the VCS Tool for Methodological Issues (paragraph 13)12 .\\n\\nProject proponents must identify realistic and credible land-use scenarios that could occur on the land within the proposed project boundary in the absence of the ALM project activity. The scenarios must be credible and feasible for the project proponent or similar project developers taking into account relevant national and/or sectoral policies and circumstances.\\n\\nThe identification of realistic and credible land use scenarios shall use a combination of land-use records, field surveys, information from stakeholder consultation, historical land use practices, and information from other sources as appropriate.\\n\\nBaseline scenarios must be general and can be a single or a combination of land management strategies, including but not exclusively, grazing management, fertilizer use, and irrigation practices. It is not necessary to consider all possible combinations of specific strategies as baseline scenarios but each of the realistic and credible strategies must be assessed through application of the VCS “Tool for Demonstration and Assessment of Additionality”13\\n\\nStep 2.2 Selecting the baseline scenario\\n\\nThe project proponent shall use the current VCS “Tool for Demonstration and Assessment of Additionality”14 in AFOLU Project Activities to assess which of the baseline alternatives and management strategies shall be excluded from further consideration.\\n\\nThe project proponent shall arrive at a baseline scenario of grassland management.\\n\\nThe baseline scenario shall be described in the VCS-PD in the form of a baseline Grassland Management Plan (GMP) which defines the baseline management strategies and input data for estimates of greenhouse gas emissions in the baseline scenario. Proponents shall develop the GMP in Step 3.\\n\\nStep 2.3 Additionality\\n\\nThe project proponent shall test the additionality of the project using the current VCS Tool for Demonstration and Assessment of Additionality in AFOLU Project Activities.\\n\\n12 http://www.v-c-s.org/docs/Tool%20for%20AFOLU%20Methodological%20Issues.pdf 13 http://cdm.unfccc.int/methodologies/PAmethodologies/tools/am-tool-01-v5.2.pdf 14 http://cdm.unfccc.int/methodologies/PAmethodologies/tools/am-tool-01-v5.2.pdf\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 16\\n\\nSTEP 3 – Ex-ante Grassland Management Plans and Stratification This step develops ex-ante, the Grassland Management Plan (GMP) for the baseline scenario and the Improved Grassland Management Plan (IGMP) for the project scenario.\\n\\nStep 3.1 Grassland Management Plan\\n\\nThe GMP shall define the baseline management strategies and input data for ex ante estimates of greenhouse gas emissions in the baseline scenario.\\n\\nThe GMP shall include details on an annualised basis of\\n\\nlivestock management including stocking rate, livestock type, and grazing days per land parcel;\\n\\ngrassland management including any biomass burning and/or vegetation clearing,\\n\\nand/or pasture improvement;\\n\\nfertilizer use as mass of synthetic fertilizer and/or mass of organic fertilizer; and\\n\\nfossil fuel consumed (as represented by fuel purchased by fuel type).\\n\\nProject proponents must provide credible evidence for the management strategies and input values in the GMP for the baseline scenario in the VCS-PD. These shall be obtained from either:\\n\\ndocumented land management history for the project area, where such records include livestock type, livestock production and grazing management practices, or\\n\\na common practice analysis of grassland management for similar properties in the\\n\\ndistrict.\\n\\nStep 3.2 Improved Grassland Management Plan\\n\\nThe IGMP shall define the project management strategies and input data for ex-ante estimates of greenhouse gas emissions in the project scenario.\\n\\nProponents shall select project strategies that are expected to increase carbon stock in measured pools and/or reduce emissions and/or avoid emissions when compared to the baseline scenario.\\n\\nGrassland management strategies in the project area that\\n\\ndecrease the proportion of bare soil, and/or decrease the time soil is exposed, and/or shift the vegetation composition toward deep rooted perennial species, and/or\\n\\nreduce energy and fertilizer inputs\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 17\\n\\nare likely to increase carbon stocks and/or reduce greenhouse gas emissions compared to the baseline scenario.\\n\\nThe improved grassland management strategies selected must be achievable within the bio- physical constraints of the project area, must be included as a parameter in the selected SOC model, and be within the land management capability of the project proponents.\\n\\nThe improved grassland management strategies must conform to the eligibility and applicability conditions of this methodology described at Step 0.\\n\\nThe IGMP outlines the strategies that make up the project scenario and must be described in the VCS-PD.\\n\\nStep 3.3 Select carbon pools and greenhouse gas emission sources\\n\\nThis step selects carbon pools and greenhouse gas emission sources that are required or are material in the baseline scenario and project scenario defined by the grassland management strategies in the GMP and the IGMP.\\n\\nStep 3.3.1 Carbon stock additions from above-ground woody biomass\\n\\nIn the baseline scenario, project proponents shall use the approved A/R CDM Guidance on Conditions under which the Change in Carbon Stocks in Existing Live Woody Vegetation Need not be Accounted15, to determine whether the change in carbon stocks in existing live woody vegetation (i.e. in trees and shrubs) are to be accounted in the baseline scenario greenhouse gas accounts.\\n\\nEquations are given in Step 4.2.1\\n\\nIn the project scenario, project proponents may conservatively exclude above-ground woody biomass carbon stock additions from the ex-ante project scenario greenhouse accounts.\\n\\nWhere project proponents choose to account above-ground woody biomass carbon stock additions, equations are given in Step 5.2.1\\n\\nStep 3.3.2 Above-ground woody biomass carbon stock losses\\n\\nIn the baseline scenario, where biomass clearing and/or burning is included in the management strategies described in the GMP, project proponents may choose to conservatively exclude carbon stock losses in above-ground woody biomass from the ex- ante baseline scenario greenhouse gas accounts.\\n\\nWhere project proponents choose to account above-ground woody biomass carbon stock losses, equations are given in Step 4.2.2\\n\\n15 REF!\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 18\\n\\nIn the baseline scenario, if fire is included in the management strategies described in the GMP, the area burned shall be defined as a stratum, and all biomass in the stratum shall be considered to be burned. In the project scenario, where biomass clearing and/or burning is an included management strategy in the IGMP, above-ground woody biomass carbon stock losses must be included in ex-ante project scenario greenhouse gas accounts.\\n\\nEquations for above-ground woody biomass carbon stock losses in the project scenario are given in Step 5.2.2\\n\\nStep 3.3.3 Enteric emissions from methane production\\n\\nIn the baseline scenario, project proponents may choose to conservatively exclude enteric emissions from the ex-ante baseline scenario greenhouse gas accounts.\\n\\nWhere project proponents choose to account enteric emissions, equations are given in Step 4.3\\n\\nIn the project scenario, it is necessary to compare baseline scenario GMP and the project scenario IGMP, and if there is:\\n\\n(a) no change in livestock numbers and livestock composition or type; or\\n\\n(b) a decrease in livestock numbers and no substitution to more emissions\\n\\nintensive livestock type(s) in the IGMP; or\\n\\n(c) a substitution to less emissions intensive livestock type(s) and no increase in\\n\\nlivestock numbers in the IGMP;\\n\\nproject proponents may choose to exclude enteric emissions from the ex-ante project scenario greenhouse gas accounts.\\n\\nEnteric emissions must be accounted in the ex-ante project scenario greenhouse gas accounts in all other situations using equations given in Step 5.3\\n\\nStep 3.3.4 Emissions from fossil fuel combustion\\n\\nIn the baseline scenario, project proponents may choose to conservatively exclude emissions from fossil fuel combustion from the ex-ante baseline scenario greenhouse gas accounts.\\n\\nWhere project proponents choose to account emissions from fossil fuel combustion, equations are given in Step 4.4\\n\\nIn the project scenario, it is necessary to compare baseline scenario GMP and the project scenario IGMP, and if there is:\\n\\n(a) no change in fuel consumed and fuel type; or\\n\\n(b) a decrease in fuel consumed and no substitution to more emissions intensive\\n\\nfuel type(s) in the IGMP; or\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 19\\n\\n(c) a substitution to less emissions intensive fuel type(s) and no increase in fuel\\n\\nconsumed in the IGMP;\\n\\nproject proponents may choose to exclude emissions from fossil fuel combustion in the ex- ante project scenario greenhouse gas accounts. Emissions from fossil fuel combustion must be accounted in the ex-ante project scenario greenhouse gas accounts in all other situations using equations given in Step 5.4\\n\\nStep 3.3.5 Emissions from fertilizer use\\n\\nIn the baseline scenario, where fertilizer use is included in the management strategies described in the GMP, project proponents may choose to conservatively exclude emissions from fertilizer use the ex-ante baseline scenario greenhouse gas accounts.\\n\\nWhere project proponents choose to account fertilizer use, equations are given in Step 4.5\\n\\nIn the project scenario, where fertilizer use in an included management strategy in the IGMP, emissions from fertilizer use must be included in ex-ante project scenario greenhouse gas accounts using equations given in Step 5.5\\n\\nStep 3.4 Stratification\\n\\nStratification of the project area must be carried out in order to determine the areas under each land management strategy to improve the accuracy and precision of carbon stock estimates.\\n\\nProject proponents shall stratify the project area in the baseline scenario and the project scenario.\\n\\nStrata shall be developed on the basis of key parameters used to estimate changes in carbon stocks.\\n\\nAt a minimum, strata must include soil type, vegetation type (and/or pasture species) and management strategies.\\n\\nBased on the availability of data regarding the nature of soils and composition of the vegetation in the project area, stratification shall be developed on the basis of either:\\n\\na) existing soils mapping for the project area; and\\n\\nb) existing vegetation mapping or stratification and/or a paddock map with paddock\\n\\nmanagement histories for the project area; or\\n\\nc) estimates developed from sampling the project area using soil and vegetation\\n\\nsurvey tools appropriate for the region.\\n\\nIt is acceptable to group similar land management strategies into one strata provided justification for any grouping is given in the VCS-PD.\\n\\nWhere the selected SOC model allows for additional input parameters, proponents may choose to further stratify the project by these parameters to improve accuracy (See Step 3.1.1).\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 20\\n\\nProject proponents will submit as part of the VCS-PD a detailed description of the stratification adopted and the data sources used to develop stratification of the project area.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 21\\n\\nSTEP 4 – Ex-ante Net Greenhouse Gas Emissions in the Baseline Scenario\\n\\nThis step estimates ex-ante, GHGNET,t|BSL, the greenhouse gas emissions in year t in the baseline scenario.\\n\\nThe following table lists the baseline emissions modelled by this methodology:\\n\\nIncluded in modelling Soil carbon, above ground woody biomass, biomass burning, enteric emissions, fossil fuel use, fertilizer use\\n\\nConservatively excluded from modelling Above ground non-woody biomass\\n\\nStep 4.1 Determine soil organic carbon stock change in the baseline scenario\\n\\nThe output of this step is ex ante projection of SOC stock change in the baseline scenario.\\n\\nA modelling approach shall be used to determine the SOC stock change in the baseline scenario.\\n\\nStep 4.1.1 Select the SOC model\\n\\nChanges in SOC stocks in the baseline shall be estimated using a published soil carbon dynamics model applicable to the project site.\\n\\nProponents shall use a SOC model\\n\\nthat has been accepted in peer-reviewed scientific publications such as the RothC16 or the CENTURY17 model,\\n\\nthat has been field tested on soils within the geographic region that includes the project area(s),\\n\\nwhere the output resolution of the model can predict differences in SOC at the scale\\n\\nof project activity and stratification,\\n\\nthat includes land management practice as an input parameter,\\n\\nis designed to account for time since clearing from natural vegetation,\\n\\n16 Ref 17 Ref\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 22\\n\\ncan generate forward and backward projections of SOC stocks in the modelled\\n\\nscenario\\n\\nwhere mean and variance in SOC density in t ha-1 at time t are outputs of the\\n\\nmodel18.\\n\\nIt is not acceptable to use a broad scale model that is not able to predict change at the scale of management activity, such as those designed for regional or national scale carbon accounts.\\n\\nProponents must follow the parameter inputs and settings defined by the baseline scenario, input these parameters into the model, and use the model to estimate the SOC projection over the project lifetime given the management practices in the baseline scenario.\\n\\nStep 4.1.2 Align soil type classification to the SOC model\\n\\nSOC models assume a certain level of soil classification as an input parameter.\\n\\nProject proponents must select a level of soil classification for the project area that matches the required sensitivity of the chosen SOC model. Selection can be made amongst soil classification categories that exist in soil mapping for the project area or use soil classification systems that would be applied to the project area for standard soil surveys.\\n\\nStep 4.1.3 Determine the spatial co-ordinates for SOC modelling\\n\\nTo generate spatial output from the selected SOC model it is necessary to determine a grid of spatial co-ordinates (virtual sample points) that will provide spatial representation of strata across the project area.\\n\\nProject proponents shall select and describe in the VCS-PD the scale, resolution and arrangement of spatial co-ordinates across the project area that shall be used to generate model output.\\n\\nIn all land parcels defined by the baseline stratification that cover greater than 5% of the project area, and are therefore above de minimis, the sampling grid of spatial co-ordinates must generate at least 3 sample points. The grid must also generate a minimum of three sample points in each land parcel across sufficient strata to cover 95% of the project area.\\n\\nStep 4.1.4 Run the SOC model for the baseline scenario\\n\\n18 It is acceptable to convert model output to soil carbon density (t ha-1) where the output of the model is in alternate units through the estimation of soil bulk density in the project area. Bulk density measurements must follow standard practice; and the methods and sampling design must be described in the VCS-PD.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 23\\n\\nFor each spatial co-ordinate on the sampling grid, project proponents shall collate the data for each input parameter in the SOC model from soil maps, meteorological stations, land management records and land management projections for the chosen baseline scenario.\\n\\nData sources must be described in the VCS-PD.\\n\\nProponents shall run the selected SOC model for the baseline scenario at each of the selected spatial co-ordinates.\\n\\nModel runs of the baseline scenario must project forward to cover the project crediting period and also be applied retrospectively for 10 years prior to the project start date.\\n\\nBack projections are necessary to comply with the VCS requirement that “soil C stock estimates shall be determined relative to the computed maximum C stocks that occurred in the designated land area within the previous 10 years.” 19\\n\\nThe output of the modelling will be a matrix of values for the SOC stock at each spatial co- ordinate for each year of the baseline scenario and for each of the ten years prior to the start date. Whilst ex-ante values for project start date, the end of the crediting period and the maximum carbon stock in the previous 10 years are required, annual carbon stocks must still be modelled for use in ex-post estimations at Step 5 and Step 6.\\n\\nStep 4.1.5 Spatial interpolation of SOC stock\\n\\nAt this step, a spatial interpolation algorithm, f(X,Y..), shall be applied to the spatial matrix of SOC stock estimates to generate a SOC stock profile for the baseline scenario across the project area at the project start date, the end of the crediting period, and for each of the ten years prior to the project start date.\\n\\nProponents shall use standard geostatistical interpolation methods to create the SOC stock profiles.\\n\\nProject proponents must compute SOC stock profiles using proprietary geostatistical software applications where such applications have the ability to define the interpolation method, include the project boundaries as defined at Step 1.1, and to sum the SOC stock across the profile for the project area. Summation across the profile shall estimate the SOC stock across the total project area in t C.\\n\\nThe following parameters are then assigned to the output of spatial interpolation:\\n\\nCS_MAX|BSL\\n\\nmaximum computed carbon stock in SOC in the 10 years prior to project start date in the baseline scenario, t C20;\\n\\nCS_START|BSL\\n\\ncarbon stock in SOC at the project start date in the baseline scenario, t C; and\\n\\nCS_END|BSL\\n\\ncarbon stock in SOC at the end of the project crediting period in the baseline scenario, t C.\\n\\n19 Step 4, paragraph 13, Tool for AFOLU Methodological Issues 20 For example, if SOC stocks on the project area were 10,000 t C in 2002, then declined to 9,000 t C by 2007 after intensive grazing, CS_MAX|BSL for a project established in 2008 would be 10,000 t C.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 24\\n\\nStep 4.1.6 Calculate the SOC stock change in the baseline scenario\\n\\nThis step estimates Cs|BSL, the ex ante SOC stock loss in the baseline scenario.\\n\\nThe carbon stock change in the baseline scenario shall be estimated as:\\n\\nC\\n\\nS\\n\\n|\\n\\nBSL\\n\\nC (\\n\\nS\\n\\n_\\n\\nMAX\\n\\n|\\n\\nBSL\\n\\nC\\n\\nS\\n\\n_\\n\\nEND |\\n\\nBSL\\n\\n)\\n\\nC (\\n\\nS\\n\\n_\\n\\nMAX\\n\\n|\\n\\nBSL\\n\\nC\\n\\nS\\n\\n_\\n\\nSTART\\n\\nBSL\\n\\n)\\n\\n(1)\\n\\nWhere:\\n\\n∆CS |BSL\\n\\ncarbon stock change in soil organic carbon in the baseline scenario, t C;\\n\\nCS_MAX |BSL\\n\\nmaximum computed carbon stock in soil organic carbon in the 10 years prior to project start date in the baseline scenario, t C; and\\n\\nCS_END|BSL\\n\\ncarbon stock in soil organic carbon at the end of the project crediting period in the baseline scenario, t C.\\n\\nA simplifying and conservative assumption is made that SOC stock change in the baseline scenario is linear. Consequently, the total carbon stock change is divided by the project crediting period to annualise the carbon stock change in SOC in the baseline scenario:\\n\\nC\\n\\n|, tS\\n\\nBSL\\n\\nC\\n\\n| S IGM\\n\\nBSL\\n\\nCP\\n\\n44 12\\n\\n(2)\\n\\nWhere:\\n\\nCs,t |BSL\\n\\ncarbon stock change in soil organic carbon in year t in the baseline scenario, t CO2-e;\\n\\n∆CS|BSL\\n\\ncarbon stock change in soil organic carbon in the baseline scenario, t C; and\\n\\nIGMCP\\n\\ncrediting period for improved grassland management project, years.\\n\\nStep 4.2 Determine carbon stock change in above-ground woody biomass in the baseline scenario\\n\\nThis step calculates ∆CAWB,t|BSL , the carbon stock change in above-ground woody biomass within the project boundary in year t in the baseline scenario.\\n\\nStep 4.2.1 Above-ground woody biomass carbon stock additions in the baseline scenario\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 25\\n\\nThis step calculates ∆CAWB_AD,t|BSL above-ground woody biomass carbon stock additions in year t in the baseline scenario.\\n\\nIf at Step 3.3.1 above-ground woody biomass carbon stock additions need not be accounted in the ex-post baseline scenario, then:\\n\\n∆CAWB_AD,t|BSL = 0\\n\\nOtherwise, proponents shall use the approved A/R Methodological Tool Estimation of carbon stocks and change in carbon stocks of trees and shrubs in A/R CDM project, to determine the following parameters21:\\n\\n∆CTREE_BSL,t\\n\\nchange in carbon stock in tree biomass within the project boundary in the baseline scenario in year t; t CO2-e\\n\\n∆CSHRUB_BSL,t change in carbon stock in shrub biomass within the project boundary\\n\\nin the baseline scenario in year t; t CO2-e\\n\\nProponents shall estimate above-ground woody biomass carbon stock additions in year t in the baseline scenario as:\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tAD\\n\\nBSL\\n\\nC\\n\\nTREE\\n\\n_\\n\\nBSL\\n\\n, t\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nBSL\\n\\n, t\\n\\n(3)\\n\\nWhere:\\n\\n∆CAWB_AD,t|BSL above-ground woody biomass carbon stock additions in year t in the\\n\\nbaseline scenario; t CO2-e\\n\\n∆CTREE_BSL,t\\n\\nchange in carbon stock in tree biomass within the project boundary in the baseline scenario in year t; t CO2-e; and\\n\\n∆CSHRUB_BSL,t change in carbon stock in shrub biomass within the project boundary\\n\\nin the baseline scenario in year t; t CO2-e.\\n\\nStep 4.2.2 Above-ground woody biomass carbon stock losses in the baseline scenario\\n\\nThis step calculates ∆CAWB_LS,t|BSL, the change in above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the baseline scenario.\\n\\nIf at Step 6.3.2, above-ground woody biomass carbon stock additions need not be accounted in the ex-post baseline scenario, then:\\n\\n∆CAWB_LS,t|BSL = 0\\n\\n21 ∆CTREE_BSL,t and ∆CSHRUB_BSL,t are parameters in the A/R Methodological Tool and do not use the same nomenclature scenario qualifiers as this methodology.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 26\\n\\nIf fire is used, the area burned shall be defined as a stratum, and all biomass in the stratum is considered to be burned. Burning from unplanned disturbance is dealt with separately under the project scenario (Step 11.4).\\n\\nFor all strata with managed biomass clearing and/or burning in year t in the baseline scenario, project proponents must use the approved A/R Methodological Tool Estimation of carbon stocks and change in carbon stocks of trees and shrubs in A/R CDM project activities to determine the following parameters:\\n\\nCTREE_BSL,i,t\\n\\ncarbon stock in tree biomass in statum i in the baseline scenario in year t; t C; and\\n\\nCSHRUB_BSL,i,t\\n\\ncarbon stock in shrub biomass in stratum i in the baseline scenario in year t; t C.\\n\\nProponents shall then estimate the above-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i in year t in the baseline scenario as:\\n\\nC\\n\\nAWB\\n\\n|,, ti\\n\\nBSL\\n\\nC\\n\\nTREE\\n\\n_\\n\\nBSL\\n\\n,, ti\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nBSL\\n\\n,, ti\\n\\n(4)\\n\\nWhere:\\n\\nCAWB,i,t|BSL\\n\\nabove-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i year t in the baseline scenario; t CO2-e\\n\\nCTREE_BSLi,,t\\n\\ncarbon stock in tree biomass within the project boundary in stratum i in the baseline scenario in year t; t CO2-e; and\\n\\nCSHRUB_BSLi,,t\\n\\ncarbon stock in shrub biomass within the project boundary in stratum i in the baseline scenario in year t; t CO2-e.\\n\\nTherefore, ∆CAWB_LS,t|BSL, the change in above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the baseline scenario is calculated as:\\n\\nC\\n\\nAWB\\n\\n_\\n\\ntLS |,\\n\\nBSL\\n\\nC\\n\\nAWB\\n\\nti |,,\\n\\nBSL\\n\\n(5)\\n\\ni\\n\\nWhere:\\n\\n∆CAWB_LS,t|BSL change\\n\\nin above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the baseline scenario; t CO2-e;\\n\\nCAWB i,t|BSL\\n\\nabove-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i year t in the baseline scenario; t CO2-e; and\\n\\ni\\n\\n1,2,3… clearing and/or burning strata.\\n\\nWhere fire is used, it is necessary to also estimate the instantaneous non-CO2 greenhouse gas emissions due to biomass burning of tree and shrub biomass within those strata (Box 1).\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 27\\n\\nBox 1. Non-CO2 greenhouse gas emissions due to biomass burning This box calculates the non-CO2 greenhouse gas emissions due to biomass burning. These emissions are treated as an instantaneous greenhouse gas emission and not a carbon stock change.\\n\\nProponents shall estimate non-CO2 emissions from tree biomass due to managed fire in stratum i in year t in the baseline scenario as:\\n\\nGHG\\n\\nTREE\\n\\nti |,,\\n\\nBSL\\n\\nC\\n\\nTREE\\n\\n_\\n\\nBSL\\n\\nti ,,\\n\\nCOMF\\n\\nTREE\\n\\n,\\n\\ni\\n\\nER\\n\\nCH\\n\\n4\\n\\n16 44\\n\\nGWP\\n\\nCH\\n\\n4\\n\\n(6)\\n\\nWhere:\\n\\nGHGTREE,i,t|BSL non-CO2 greenhouse gas emissions from tree biomass due to\\n\\nCTREE_BSLi,,t\\n\\nmanaged fire in stratum i in year t in the baseline scenario; t CO2-e; carbon stock in tree biomass within the project boundary in stratum i in the baseline scenario in year t; t CO2-e;\\n\\nCOMFTREE,i\\n\\nERCH4\\n\\n16/44\\n\\nGWPCH4\\n\\ncombustion factor for tree biomass in stratum i, dimensionless; emissions factor for CH4, t CH4 t-1 C burnt; ratio of molecular weights of CH4 and CO2; mol mol-1; and global warming potential for CH4; t CO2-e t-1 CH4.\\n\\nProponents shall then estimate non-CO2 emissions from shrub biomass due to managed fire in stratum i in year t in the baseline scenario as:\\n\\nGHG\\n\\nSHRUB\\n\\nti |,,\\n\\nBSL\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nBSL\\n\\nti ,,\\n\\nCOMF\\n\\nSHRUB\\n\\n,\\n\\ni\\n\\nER\\n\\nCH\\n\\n4\\n\\n16 44\\n\\nGWP\\n\\nCH\\n\\n4\\n\\n(7)\\n\\nWhere:\\n\\nGHGSHRUB,i,t|BSL non-CO2 greenhouse gas emissions from shrub biomass due to\\n\\nCSHRUB_BSLi,,t\\n\\nmanaged fire in stratum i in year t in the baseline scenario; t CO2-e; carbon stock in shrub biomass within the project boundary in stratum i in the baseline scenario in year t; t CO2-e;\\n\\nCOMFSHRUB,i combustion factor for shrub biomass in stratum i, dimensionless;\\n\\nERCH4\\n\\n16/44\\n\\nGWPCH4\\n\\nemissions factor for CH4, t CH4 t-1 C burnt; ratio of molecular weights of CH4 and CO2; mol mol-1; and global warming potential for CH4; t CO2-e t-1 CH4.\\n\\nTherefore, non-CO2 greenhouse gas emissions due to managed fire in year t in the baseline scenario are calculated as:\\n\\nGHG\\n\\nAWB\\n\\n|, t\\n\\nBSL\\n\\nGHG\\n\\nTREE\\n\\n|,, ti\\n\\nBSL\\n\\nGHG\\n\\nSHRUB\\n\\n|,, ti\\n\\nBSL\\n\\n(8)\\n\\ni\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 28\\n\\nGHGAWB,t|BSL non-CO2 greenhouse gas emissions from above-ground woody biomass due to managed fire in year t in the baseline scenario; t CO2- e;\\n\\nGHGTREE,i,t|BSL non-CO2 greenhouse gas emissions from tree biomass due to\\n\\nmanaged fire in stratum i in year t in the baseline scenario; t CO2-e;\\n\\nGHGSHRUB,i,t|BSL non-CO2 greenhouse gas emissions from shrub biomass due to managed fire in stratum i in year t in the baseline scenario; t CO2-e; and\\n\\ni\\n\\n1,2,3… clearing and/or burning strata.\\n\\nStep 4.2.3 Above-ground woody biomass carbon stock in the baseline scenario\\n\\nTherefore, ∆CAWB,t|BSL , the carbon stock change in above-ground woody biomass within the project boundary in year t in the baseline scenario is calculated as follows:\\n\\nC\\n\\nAWB\\n\\n|, t\\n\\nBSL\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tLS\\n\\nBSL\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tAD\\n\\nBSL\\n\\n(9)\\n\\nWhere:\\n\\n∆CAWB,t|BSL\\n\\nthe carbon stock change in above-ground woody biomass within the project boundary in year t in the baseline scenario; t CO2-e;\\n\\n∆CAWB_AD,t|BSL above-ground woody biomass carbon stock additions in year t in the\\n\\nbaseline scenario; t CO2-e; and\\n\\n∆CAWB_LS,t|BSL change\\n\\nin above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the baseline scenario; t CO2-e.\\n\\nStep 4.3 Determine methane production from enteric emissions in the baseline scenario\\n\\nThis step calculates GHGENTERIC,t|BSL fermentation in year t in the baseline scenario.\\n\\n, the greenhouse gas emissions from enteric\\n\\nIf at Step 3.3.3 methane production from enteric emissions\\n\\nIn need not be accounted in the ex-ante baseline scenario, then\\n\\nGHGENTERIC,t|BSL.= 0\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 29\\n\\nOtherwise, Proponents shall then estimate methane production from enteric emissions in year t in the ex-ante baseline scenario as:\\n\\nEF l\\n\\nGE\\n\\nMCF l\\n\\nl 65.55\\n\\n(10)\\n\\nWhere:\\n\\nEFl\\n\\nGEl\\n\\nemissions factor for livestock type l, kg CH4 head-1 day-1; gross energy intake livestock type l, MJ head-1 day-1;\\n\\nMCFl\\n\\nmethane conversion factor for livestock type l, fraction of gross energy in feed converted to methane;\\n\\n55.65\\n\\nenergy content of methane, MJ/kg CH4; and\\n\\nl\\n\\nspecies/category/type of livestock.\\n\\nE\\n\\nENTERIC\\n\\n|, t\\n\\nBSL\\n\\nEF l\\n\\nN\\n\\n|, tl\\n\\nBSL\\n\\nGP |, tl\\n\\nBSL\\n\\n(11)\\n\\nl\\n\\nWhere:\\n\\nEENTERIC,t|BSL\\n\\nEFl\\n\\nmethane emissions from enteric fermentation in year t in the baseline scenario, kg CH4 yr-1; emissions factor for livestock type l, kg CH4 head-1 day-1;\\n\\nNl,t|BSL\\n\\nnumber of livestock of type l in year t in the baseline scenario, head yr-1;\\n\\nGPl,t|BSL\\n\\ngrazing days for livestock type l in year t in the baseline scenario, days; and\\n\\nl\\n\\nspecies/category/type of livestock.\\n\\nThe conversion of methane production to carbon dioxide equivalents shall be calculated as:\\n\\nGHG\\n\\nENTERIC\\n\\n|, t\\n\\nBSL\\n\\nE\\n\\nENTERIC\\n\\n|, t\\n\\nBSL\\n\\n23\\n\\n10\\n\\n3\\n\\n(12)\\n\\nWhere:\\n\\nGHGENTERIC,t|BSL\\n\\ngreenhouse gas emissions from enteric fermentation in year t in the baseline scenario; t CO2-e yr-1;\\n\\nEENTERIC,t|BSL\\n\\nmethane emissions from enteric fermentation in year t in the baseline scenario, kg CH4 yr-1; and\\n\\n23\\n\\nglobal warming potential integrated over 100 years for CH4, t CO2-e t-1 CH4.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 30\\n\\nStep 4.4 Determine greenhouse gas emissions from fossil fuel combustion in the baseline scenario\\n\\nThis step calculates GHGFF,t|BSL, the greenhouse gas emissions from fossil fuel combustion in year t in the baseline scenario. If at Step 3.3.4 emissions from fossil fuel combustion need not be accounted in the ex-ante baseline scenario, then:\\n\\nGHGFF,t|BSL. = 0\\n\\nOtherwise, greenhouse gas emissions from fossil fuel combustion in the baseline scenario shall be calculated as follows:\\n\\nGHG\\n\\ntFF ,\\n\\nBSL\\n\\n3\\n\\nf\\n\\n\\n\\nEC\\n\\ntf |,\\n\\nBSL\\n\\nEF\\n\\nfg ,\\n\\nGWP g\\n\\n10\\n\\n3\\n\\n(13)\\n\\ng\\n\\n1\\n\\nf\\n\\n1\\n\\nWhere:\\n\\nGHGFF,t|BSL\\n\\ngreenhouse gas emissions from fossil fuel combustion in year t in the baseline scenario, tCO2-e yr-1;\\n\\nECf,t|BSL\\n\\nEFg,f\\n\\nenergy consumed for fuel type f in year t in the baseline scenario, TJ; emissions factor for greenhouse gas g for fuel type f; kg TJ-1;\\n\\nGWP100,g\\n\\nglobal warming potential greenhouse gas g, t CO2-e t-1;\\n\\nintegrated over 100 years for\\n\\ng\\n\\nunique identifier for each greenhouse gas; and\\n\\nf\\n\\nfuel type.\\n\\nThe energy consumed for each fuel type in the baseline scenario shall be calculated as follows:\\n\\nEC\\n\\n|, tf\\n\\nBSL\\n\\nFC\\n\\n|, tf\\n\\nBSL\\n\\nNCV\\n\\nf\\n\\nD\\n\\nf\\n\\n(14)\\n\\nWhere:\\n\\nECf,t|BSL\\n\\nenergy consumed for fuel type f in year t in the baseline scenario, TJ;\\n\\nFCf,t|BSL\\n\\nNCVf\\n\\nDf\\n\\nfuel consumed (as represented by fuel purchased) for fuel type f in year t in the baseline scenario, kL; net calorific value for fuel type f, TJ Gg-1; and density of fuel type f, Gg kL-1.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 31\\n\\nStep 4.5 Determine emissions from fertilizer use in the baseline scenario\\n\\nThis step calculates GHGFERT,t|BSL , the direct N2O emissions that result from the application of nitrogen in the baseline scenario. If at Step 3.3.5 emissions from fertilizer use need not be accounted in the ex-ante baseline scenario, then:\\n\\nGHGFERT,t|BSL. = 0\\n\\nIf flooding irrigation or any flood has occurred on the project area within a period of 3 months from date of fertilization, then GHGFERT,t|BSL in year t is conservatively estimated as:\\n\\nGHG\\n\\nFERT\\n\\nt |, BSL\\n\\n0\\n\\nFor all other years, the direct nitrous oxide emissions from nitrogen fertilization in year t shall be calculated as:\\n\\nGHG\\n\\nFERT\\n\\n|, t\\n\\nBSL\\n\\n(\\n\\nF\\n\\nSN\\n\\n,\\n\\nt\\n\\nF\\n\\n, tON\\n\\n)\\n\\nEF 1\\n\\n44 28\\n\\nGWP\\n\\nON 2\\n\\n(15)\\n\\nWhere:\\n\\nGHGFERT,t|BSL\\n\\ndirect N2O emission as a result of nitrogen application within the project boundary in year t, t CO2-e;\\n\\nFSN,t\\n\\nMass of synthetic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nFON,t\\n\\nEF1\\n\\n44/28\\n\\nmass of organic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N; emission factor for emissions from N inputs, t N2O t-1 N input; ratio of molecular weights of N2O and N, t N2O t-1 N; and\\n\\nONGWP\\n\\n2\\n\\nglobal warming potential integrated over 100 years for N2O, t CO2-e t-1 N2O.\\n\\nF\\n\\nSN\\n\\n,\\n\\nt\\n\\nM\\n\\nSF\\n\\n,\\n\\ntk ,\\n\\nNC\\n\\nSF\\n\\n,\\n\\nk\\n\\n1(\\n\\nFrac\\n\\nGASF\\n\\n)\\n\\n(16)\\n\\nk\\n\\nWhere:\\n\\nFSN,t\\n\\nmass of synthetic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 32\\n\\nMSF,k,t|BSL\\n\\nmass of synthetic fertilizer type k applied in year t in the baseline scenario, t;\\n\\nNCSF,k\\n\\nnitrogen content of synthetic fertilizer type k applied, g N 100g-1 fertilizer;\\n\\nFracGASF\\n\\nFraction that volatilises as NH3 and NOX for synthetic fertilizers, dimensionless; and\\n\\nk\\n\\nsynthetic fertilizer type.\\n\\nF\\n\\ntON ,\\n\\nM\\n\\ntjOF , ,\\n\\nNC\\n\\njOF ,\\n\\n1(\\n\\nFrac\\n\\nGASM\\n\\n)\\n\\n(17)\\n\\nj\\n\\nWhere:\\n\\nFON,t\\n\\nmass of organic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nMOF,j,t|BSL\\n\\nNCOF,j\\n\\nmass of organic fertilizer type j applied in year t in the baseline scenario, t; nitrogen content of organic fertilizer type j applied, g N 100g-1 fertilizer; and\\n\\nFracGASM\\n\\nFraction that volatilises as NH3 and NOX for organic fertilizers, dimensionless; and\\n\\nj\\n\\norganic fertilizer type.\\n\\nStep 4.6 Net GHG emissions in the baseline scenario\\n\\nThis step calculates GHGNET,t|BSL, the net GHG emissions in year t in the baseline scenario.\\n\\nProponents shall calculate the net greenhouse gas emissions in year t in the ex-ante baseline scenario as:\\n\\nGHG\\n\\nNET\\n\\n|, t\\n\\nBSL\\n\\nC\\n\\n|, tS\\n\\nBSL\\n\\nC\\n\\nAWB\\n\\n|, t\\n\\nBSL\\n\\nGHG\\n\\nAWB\\n\\n|, t\\n\\nBSL\\n\\nGHG\\n\\nENTERIC\\n\\n|, t\\n\\nBSL\\n\\nGHG\\n\\n|, tFF\\n\\nBSL\\n\\nGHG\\n\\nFERT\\n\\n|, t\\n\\nBSL\\n\\n(18)\\n\\nWhere:\\n\\nGHGNET,t|BSL\\n\\nnet greenhouse gas emissions in year t in the baseline scenario; t CO2-e;\\n\\nCs,t |BSL\\n\\ncarbon stock change in soil organic carbon in year t in the baseline scenario, t CO2-e;\\n\\n∆CAWB,t|BSL\\n\\nthe carbon stock change in above-ground woody biomass within the project boundary in year t in the baseline scenario; t CO2-e\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 33\\n\\nGHGAWB,t|BSL\\n\\nGHGENTERIC,t|BSL\\n\\nGHGFF,t|BSL\\n\\nGHGFERT,t|BSL\\n\\nIGM Methodology\\n\\nnon-CO2 greenhouse gas emissions from above-ground woody biomass due to managed fire in year t in the baseline scenario; t CO2-e;\\n\\ngreenhouse gas emissions from enteric fermentation in year t in the baseline scenario; t CO2-e;\\n\\ngreenhouse gas emissions from fossil fuel combustion in year t in the baseline scenario, tCO2-e; and\\n\\ndirect N2O emission as a result of nitrogen application within the project boundary in year t, t CO2-e.\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 34\\n\\nSTEP 5 – Ex-ante Net Greenhouse Gas Emissions in the Project Scenario\\n\\nThis step estimates GHGNET,t|PRS, ex-ante net greenhouse gas emissions in year t in the project scenario, in tCO2-e.\\n\\nStep 5.1 Determine soil organic carbon stock change in the project scenario\\n\\nThe output of this step is ex ante estimation of SOC stock change in the project scenario.\\n\\nA modelling approach shall be used to determine the SOC stock change in the project scenario. The same SOC model chosen for the baseline scenario (Step 3.1.1) shall be used to model the project scenario.\\n\\nStep 5.1.1 Apply project stratification under the chosen SOC model\\n\\nProject proponents will submit as part of the VCS-PD a detailed description of the stratification adopted and the data sources used to develop project scenario stratification for the project area.\\n\\nStep 5.1.2 Align soil type classification to the SOC model\\n\\nProject proponents must use the same soil classification in the project scenario as that chosen for the baseline scenario.\\n\\nStep 5.1.3 Determine the spatial co-ordinates for SOC modelling\\n\\nTo generate spatial output from the selected SOC model it is necessary to determine a grid of spatial co-ordinates (virtual sample points) that will provide spatial representation of strata across the project area.\\n\\nProject proponents shall select and describe in the VCS-PD the scale, resolution and arrangement of spatial co-ordinates across the project area that shall be used to generate model output for the project scenario.\\n\\nIn all land parcels defined by the project stratification that cover greater than 5% of the project area, the sampling grid of spatial co-ordinates must generate at least 3 sample points. The grid must also generate a minimum of three sample points in each land parcel across sufficient strata to cover 95% of the project area.\\n\\nStep 5.1.4 Run the SOC model for the project scenario\\n\\nFor each spatial co-ordinate on the sampling grid, proponents shall collate data for each input parameter land management records and the Project Grassland Management Plan.\\n\\nin the SOC model from soil maps, meteorological stations,\\n\\nData sources must be described in the VCS-PD.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 35\\n\\nProponents shall run the selected SOC model for the project scenario at each of the selected spatial co-ordinates.\\n\\nModel runs of the project scenario must project forward to cover the project crediting period.\\n\\nThe output of the modelling will be a matrix of values for the SOC stock at each spatial co- ordinate for each year of the project scenario.\\n\\nStep 5.1.5 Spatial interpolation of SOC stock in the project scenario\\n\\nAt this step, a spatial interpolation algorithm, f(X,Y..), shall be applied to the spatial matrix of SOC stock estimates to generate a SOC stock profile for the project scenario across the project area at the end of the crediting period.\\n\\nAt this step, spatial interpolation algorithms shall be applied to the spatial matrix of SOC stock estimates to generate a SOC stock profile for the end of the crediting period.\\n\\nProponents shall use the same geostatistical interpolation methods used to create the baseline scenario SOC stock profiles. Summation across the profile shall estimate the SOC stock across the total project area in t C.\\n\\nThe following parameter is then assigned to the output of spatial interpolation:\\n\\nCS_END|PRS\\n\\ncarbon stock in SOC at the end of the crediting period in the project scenario, t C\\n\\nStep 5.1.6 Determine the SOC stock change in the project scenario\\n\\nThis step calculates Cs|PRS the carbon stock change in SOC in the project scenario.\\n\\nThe carbon stock change in the project scenario shall be determined as:\\n\\nC\\n\\nS\\n\\n|\\n\\nPRS\\n\\nC (\\n\\nS\\n\\n_\\n\\nEND |\\n\\nPRS\\n\\nC\\n\\nS\\n\\n_\\n\\nMAX\\n\\n|\\n\\nBSL\\n\\n)\\n\\n(19)\\n\\nWhere:\\n\\nCS|PRS\\n\\ncarbon stock change in the soil organic carbon pool in the project scenario; t C;\\n\\nCS_END|PRS\\n\\ncarbon stock in soil organic carbon at the end of the project crediting period in the project scenario, t C; and\\n\\nCS_MAX|BSL\\n\\nmaximum computed carbon stock in soil organic carbon in the 10 years prior to project start date in the baseline scenario, t C.\\n\\nThe total carbon stock change is then divided by the project crediting period to remove fluctuations and annualise the carbon stock change in soil organic carbon:\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 36\\n\\nC\\n\\ntS |,\\n\\nPRS\\n\\nC\\n\\n| S IGM\\n\\nBSL\\n\\nCP\\n\\n44 12\\n\\n(20)\\n\\nWhere:\\n\\nCs,t |PRS\\n\\ncarbon stock change in soil organic carbon in year t in the baseline scenario, t CO2-e;\\n\\nCS|PRS\\n\\ncarbon stock change in soil organic carbon in the project scenario; t C ha-1; and\\n\\nIGMCP\\n\\ncrediting period for improved grassland management project, years.\\n\\nStep 5.2 Determine carbon stock change in above-ground woody biomass in the project scenario\\n\\nThis step calculates ∆CAWB,t|PRS, the carbon stock change in above-ground woody biomass within the project boundary in year t in the project scenario.\\n\\nStep 5.2.1 Above-ground woody biomass carbon stock additions in the project scenario\\n\\nThis step calculates ∆CAWB_AD,t|PRS above-ground woody biomass carbon stock additions in year t in the project scenario.\\n\\nIf at Step 3.3.1 above-ground woody biomass carbon stock additions need not be accounted in the ex-post project scenario, then:\\n\\n∆CAWB_AD,t|PRS = 0\\n\\nOtherwise, proponents shall use the approved A/R Methodological Tool Estimation of carbon stocks and change in carbon stocks of trees and shrubs in A/R CDM project, to determine the following parameters22:\\n\\n∆CTREE_PROJ,t change in carbon stock in tree biomass within the project boundary in\\n\\nthe project scenario in year t; t CO2-e\\n\\n∆CSHRUB_PROJ,t change in carbon stock in shrub biomass within the project boundary\\n\\nin the project scenario in year t; t CO2-e\\n\\n22 ∆CTREE_PROJ,t and ∆CSHRUB_PROJ,t are parameters in the A/R Methodological Tool and do not use the same nomenclature scenario qualifiers as this methodology.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 37\\n\\nProponents shall estimate above-ground woody biomass carbon stock additions in year t in the project scenario as:\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tAD\\n\\nPRS\\n\\nC\\n\\nTREE\\n\\n_\\n\\nPROJ\\n\\n, t\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nPROJ\\n\\n, t\\n\\n(21)\\n\\nWhere:\\n\\n∆CAWB_AD,t|PRS above-ground woody biomass carbon stock additions in year t in the\\n\\nproject scenario; t CO2-e\\n\\n∆CTREE_PRS,t\\n\\nchange in carbon stock in tree biomass within the project boundary in the project scenario in year t; t CO2-e; and\\n\\n∆CSHRUB_PRS,t change in carbon stock in shrub biomass within the project boundary\\n\\nin the project scenario in year t; t CO2-e.\\n\\nStep 5.2.2 Above-ground woody biomass carbon stock losses in the ex-ante project scenario\\n\\nThis step calculates ∆CAWB_LS,t|PRS, the change in above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the project scenario. If fire is used, the area burned shall be defined as a stratum, and all biomass in the stratum is considered to be burned.\\n\\nBurning from unplanned disturbance is dealt with separately under the ex-post project scenario (Step 8.3.2).\\n\\nProject proponents must use the approved A/R Methodological Tool Estimation of carbon stocks and change in carbon stocks of trees and shrubs in A/R CDM project activities to determine the following parameters:\\n\\nCTREE_PROJ,i,t\\n\\ncarbon stock in tree biomass in statum i in the project scenario in year t; t C; and\\n\\nCSHRUB_PROJ,i,t carbon stock in shrub biomass in stratum i in the project scenario in\\n\\nyear t; t C.\\n\\nProponents shall then estimate the above-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i in year t in the project scenario as:\\n\\nC\\n\\nAWB\\n\\n|,, ti\\n\\nPRS\\n\\nC\\n\\nTREE\\n\\n_\\n\\nPROJ\\n\\n,, ti\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nPROJ\\n\\n,, ti\\n\\n(22)\\n\\nWhere:\\n\\nCAWB,i,t|PRS\\n\\nabove-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i year t in the project scenario; t CO2-e\\n\\nCTREE_PRSi,,t\\n\\ncarbon stock in tree biomass within the project boundary in stratum i in the project scenario in year t; t CO2-e; and\\n\\nCSHRUB_PRSi,,t\\n\\ncarbon stock in shrub biomass within the project boundary in stratum i in the project scenario in year t; t CO2-e.\\n\\nTherefore, ∆CAWB_LS,t|PRS, the change in above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the project scenario is calculated as:\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 38\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tLS\\n\\nPRS\\n\\nC\\n\\nAWB\\n\\n|,, ti\\n\\nPRS\\n\\n(23)\\n\\ni\\n\\nWhere:\\n\\n∆CAWB_LS,t|PRS change\\n\\nin above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the project scenario; t CO2-e;\\n\\nCAWB i,t|PRS\\n\\nabove-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i year t in the project scenario; t CO2-e; and\\n\\ni\\n\\n1,2,3… clearing and/or burning strata.\\n\\nWhere fire is used, it is necessary to also estimate the instantaneous non-CO2 greenhouse gas emissions due to biomass burning of tree and shrub biomass within those strata (Box 2).\\n\\nBox 2. Non-CO2 greenhouse gas emissions due to biomass burning This box calculates the non-CO2 greenhouse gas emissions due to biomass burning. These emissions are treated as an instantaneous greenhouse gas emission and not a carbon stock change.\\n\\nProponents shall estimate non-CO2 emissions from tree biomass due to managed fire in stratum i in year t in the project scenario as:\\n\\nGHG\\n\\nTREE\\n\\nti |,,\\n\\nPRS\\n\\nC\\n\\nTREE\\n\\n_\\n\\nPROJ\\n\\nti ,,\\n\\nCOMF\\n\\nTREE\\n\\n,\\n\\ni\\n\\nER\\n\\nCH\\n\\n4\\n\\n16 44\\n\\nGWP\\n\\nCH\\n\\n4\\n\\n(24)\\n\\nWhere:\\n\\nGHGTREE,i,t|PRS non-CO2 greenhouse gas emissions from tree biomass due to\\n\\nCTREE_PROJi,,t\\n\\nmanaged fire in stratum i in year t in the project scenario; t CO2-e; carbon stock in tree biomass within the project boundary in stratum i in the project scenario in year t; t CO2-e;\\n\\nCOMFTREE,i\\n\\nERCH4\\n\\n16/44\\n\\nGWPCH4\\n\\ncombustion factor for tree biomass in stratum i, dimensionless; emissions factor for CH4, t CH4 t-1 C burnt; ratio of molecular weights of CH4 and CO2; mol mol-1; and global warming potential for CH4; t CO2-e t-1 CH4.\\n\\nProponents shall then estimate non-CO2 emissions from shrub biomass due to managed fire in stratum i in year t in the project scenario as:\\n\\nGHG\\n\\nSHRUB\\n\\nti |,,\\n\\nPRS\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nPROJ\\n\\nti ,,\\n\\nCOMF\\n\\nSHRUB\\n\\n,\\n\\ni\\n\\nER\\n\\nCH\\n\\n4\\n\\n16 44\\n\\nGWP\\n\\nCH\\n\\n4\\n\\n(25)\\n\\nWhere:\\n\\nGHGSHRUB,i,t|PRS non-CO2 greenhouse gas emissions from shrub biomass due to\\n\\nmanaged fire in stratum i in year t in the project scenario; t CO2-e;\\n\\nCSHRUB_PROJi,,t carbon stock in shrub biomass within the project boundary in stratum\\n\\ni in the project scenario in year t; t CO2-e;\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 39\\n\\nCOMFSHRUB,i combustion factor for shrub biomass in stratum i, dimensionless;\\n\\nERCH4\\n\\n16/44\\n\\nGWPCH4\\n\\nemissions factor for CH4, t CH4 t-1 C burnt; ratio of molecular weights of CH4 and CO2; mol mol-1; and global warming potential for CH4; t CO2-e t-1 CH4.\\n\\nTherefore, non-CO2 greenhouse gas emissions due to managed fire in year t in the project scenario are calculated as:\\n\\nGHG\\n\\nAWB\\n\\n|, t\\n\\nPRS\\n\\nGHG\\n\\nTREE\\n\\n|,, ti\\n\\nPRS\\n\\nGHG\\n\\nSHRUB\\n\\n|,, ti\\n\\nPRS\\n\\n(26)\\n\\ni\\n\\nGHGAWB,t|PRS non-CO2 greenhouse gas emissions from above-ground woody biomass due to managed fire in year t in the project scenario; t CO2-e; GHGTREE,i,t|PRS non-CO2 greenhouse gas emissions from tree biomass due to\\n\\nmanaged fire in stratum i in year t in the project scenario; t CO2-e;\\n\\nGHGSHRUB,i,t|PRS non-CO2 greenhouse gas emissions from shrub biomass due to managed fire in stratum i in year t in the project scenario; t CO2-e; and\\n\\ni\\n\\n1,2,3… clearing and/or burning strata.\\n\\nStep 5.2.3 Above-ground woody biomass carbon stock in the project scenario\\n\\nTherefore, ∆CAWB,t|PRS , the carbon stock change in above-ground woody biomass within the project boundary in year t in the project scenario is calculated as follows:\\n\\nC\\n\\nAWB\\n\\n|, t\\n\\nPRS\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tAD\\n\\nPRS\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tLS\\n\\nPRS\\n\\n(27)\\n\\nWhere:\\n\\n∆CAWB,t|PRS\\n\\nthe carbon stock change in above-ground woody biomass within the project boundary in year t in the project scenario; t CO2-e;\\n\\n∆CAWB_AD,t|PRS above-ground woody biomass carbon stock additions in year t in the\\n\\nproject scenario; t CO2-e; and\\n\\n∆CAWB_LS,t|PRS change\\n\\nin above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the project scenario; t CO2-e.\\n\\nStep 5.3 Estimate methane production from enteric emissions in the project scenario\\n\\nIf selected at Step 3.3.3, greenhouse gas emission from enteric methane production in year t shall be calculated as:\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 40\\n\\nEF l\\n\\nGE\\n\\nMCF l\\n\\nl 65.55\\n\\n(28)\\n\\nWhere:\\n\\nEFl\\n\\nGEl\\n\\nemissions factor for livestock type l, kg CH4 head-1 day-1; gross energy intake livestock type l, MJ head-1 day-1;\\n\\nMCFl\\n\\nmethane conversion factor for livestock type l, fraction of gross energy in feed converted to methane;\\n\\n55.65\\n\\nenergy content of methane, MJ/kg CH4; and\\n\\nl\\n\\nspecies/category/type of livestock.\\n\\nE\\n\\nENTERIC\\n\\n|, t\\n\\nPRS\\n\\nEF l\\n\\nN\\n\\n|, tl\\n\\nPRS\\n\\nGD |, tl\\n\\nPRS\\n\\n(29)\\n\\nl\\n\\nWhere:\\n\\nEENTERIC,t|PRS\\n\\nEFl\\n\\nmethane emissions from enteric fermentation in year t in the project scenario, kg CH4 yr-1; emissions factor for livestock type l, kg CH4 head-1 day-1;\\n\\nNl,t|PRS\\n\\nnumber of livestock of type l in year t in the project scenario, head yr-1;\\n\\nGDl,t|PRS\\n\\ngrazing days for livestock type l in year t in the project scenario, days; and\\n\\nl\\n\\nspecies/category/type of livestock.\\n\\nThe conversion of methane production to carbon dioxide equivalents shall be calculated as:\\n\\nGHG\\n\\nENTERIC\\n\\n|, t\\n\\nPRS\\n\\nE\\n\\nENTERIC\\n\\n|, t\\n\\nPRS\\n\\n23\\n\\n10\\n\\n3\\n\\n(30)\\n\\nWhere:\\n\\nGHGENTERIC,t|PRS\\n\\ngreenhouse gas emissions from enteric fermentation in year t in the project scenario; t CO2-e yr-1;\\n\\nEENTERIC,t|PRS\\n\\nmethane emissions from enteric fermentation in year t in the project scenario, kg CH4 yr-1; and\\n\\n23\\n\\nglobal warming potential integrated over 100 years for CH4, t CO2-e t-1 CH4.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 41\\n\\nStep 5.4 Determine greenhouse gas emissions from fossil fuel combustion in the project scenario\\n\\nIf selected at Step 3.3.4, greenhouse gas emission from fossil fuel combustion in year t shall be calculated as:\\n\\n3\\n\\nf\\n\\n\\n\\nGHG\\n\\ntFF ,\\n\\nPRS\\n\\nEC\\n\\ntf |,\\n\\nPRS\\n\\nEF\\n\\nfg ,\\n\\nGWP g\\n\\n10\\n\\n3\\n\\n(31)\\n\\ng\\n\\n1\\n\\nf\\n\\n1\\n\\nWhere:\\n\\nGHGFF,t|PRS\\n\\ngreenhouse gas emissions from fossil fuel combustion in year t in the project scenario, tCO2-e yr-1;\\n\\nECf,t|PRS\\n\\nEFg,f\\n\\nenergy consumed for fuel type f in year t in the project scenario, TJ; emissions factor for greenhouse gas g for fuel type f; kg TJ-1;\\n\\nGWP100,g\\n\\nglobal warming potential greenhouse gas g, t CO2-e t-1;\\n\\nintegrated over 100 years for\\n\\ng\\n\\nunique identifier for each greenhouse gas; and\\n\\nf\\n\\nfuel type.\\n\\nThe energy consumed for each fuel type in the baseline scenario shall be calculated as follows:\\n\\nEC\\n\\n|, tf\\n\\nPRS\\n\\nFC\\n\\n|, tf\\n\\nPRS\\n\\nNCV\\n\\nf\\n\\nD\\n\\nf\\n\\n(32)\\n\\nWhere:\\n\\nECf,t|PRS\\n\\nenergy consumed for fuel type f in year t in the project scenario, TJ;\\n\\nFCf,t|PRS\\n\\nNCVf\\n\\nDf\\n\\nfuel consumed (as represented by fuel purchased) for fuel type f in year t in the project scenario, kL; net calorific value for fuel type f, TJ Gg-1; and density of fuel type f, Gg kL-1.\\n\\nStep 5.5 Estimate emissions from fertilizer use in the project scenario\\n\\nIn the project scenario direct nitrous oxide emissions from nitrogen fertilization is measured even when flood irrigation or flooding has occurred on the project area within a period of 3 months from date of fertilization, as this is conservative. The direct nitrous oxide emissions from nitrogen fertilization in year t shall be estimated as follows:\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 42\\n\\nGHG\\n\\nFERT\\n\\n|, t\\n\\nPRS\\n\\nWhere:\\n\\nGHGFERT,t|PRS\\n\\nFSN,t\\n\\nFON,t\\n\\nEF1\\n\\n44/28\\n\\nONGWP\\n\\n2\\n\\nF\\n\\nSN\\n\\n,\\n\\nt\\n\\nM\\n\\nk\\n\\nWhere:\\n\\nFSN,t|PRS\\n\\nMSF,k,t|PRS\\n\\nNCSF,k\\n\\nFracGASF\\n\\nk\\n\\nF\\n\\ntON ,\\n\\nM\\n\\nj\\n\\nWhere:\\n\\nFON,t|PRS\\n\\nMOF,j,t|PRS\\n\\nIGM Methodology\\n\\n(\\n\\nSF\\n\\n,\\n\\ntk ,\\n\\ntjOF , ,\\n\\nF\\n\\nSN\\n\\n,\\n\\nt\\n\\nNC\\n\\nNC\\n\\nF\\n\\n, tON\\n\\n)\\n\\nEF 1\\n\\n44 28\\n\\nGWP\\n\\nON 2\\n\\n(33)\\n\\ndirect N2O emission as a result of nitrogen application within the project boundary in year t in the project scenario, t CO2-e;\\n\\nMass of synthetic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nmass of organic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N; emission factor for emissions from N inputs, t N2O-N t-1 N input; ratio of molecular weights of N2O and N, t N2O t-1 N; and\\n\\nglobal warming potential integrated over 100 years for N2O, t CO2-e t-1 N2O.\\n\\nSF\\n\\n,\\n\\nk\\n\\n1(\\n\\nFrac\\n\\nGASF\\n\\n)\\n\\n(34)\\n\\nmass of synthetic fertilizer nitrogen applied in year t in the project scenario adjusted for volatilization as NH3 and NOX, t N;\\n\\nmass of synthetic fertilizer type k applied in year t in the project scenario, t;\\n\\nnitrogen content of synthetic fertilizer type k applied, g N 100g-1 fertilizer;\\n\\nFraction that volatilises as NH3 and NOX for synthetic fertilizers, dimensionless; and\\n\\nsynthetic fertilizer type.\\n\\njOF ,\\n\\n1(\\n\\nFrac\\n\\nGASM\\n\\n)\\n\\n(35)\\n\\nmass of organic fertilizer nitrogen applied in year t in the project scenario adjusted for volatilization as NH3 and NOX, t N;\\n\\nmass of organic fertilizer type j applied in year t in the project scenario, t;\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 43\\n\\nNCOF,j\\n\\nnitrogen content of organic fertilizer type j applied, g N 100g-1 fertilizer; and\\n\\nFracGASM\\n\\nFraction that volatilises as NH3 and NOX for organic fertilizers, dimensionless; and\\n\\nj\\n\\norganic fertilizer type.\\n\\nStep 5.6 Estimate net Greenhouse gas emissions in the ex-ante project scenario\\n\\nThis step calculates GHGNET,t|PRS, the net GHG emissions in year t in the project scenario.\\n\\nProponents shall calculate the net greenhouse gas emissions in year t in the ex-ante project scenario as:\\n\\nGHG\\n\\nNET\\n\\nt |,\\n\\nPRS\\n\\nGHG\\n\\nAWB\\n\\nt |,\\n\\nPRS\\n\\nGHG\\n\\nENTERIC\\n\\nt |,\\n\\nPRS\\n\\nGHG\\n\\ntFF |,\\n\\nPRS\\n\\nGHG\\n\\nFERT\\n\\nt |,\\n\\nPRS\\n\\n(\\n\\nC\\n\\ntS |,\\n\\nPRS\\n\\nC\\n\\nAWB\\n\\nt |,\\n\\nPRS\\n\\n)\\n\\n(36)\\n\\nWhere:\\n\\nGHGNET,t|PRS\\n\\nnet greenhouse gas emissions in year t in the project scenario; t CO2-e;\\n\\nGHGENTERIC,t|PRS\\n\\ngreenhouse gas emissions from enteric fermentation in year t in the project scenario; t CO2-e;\\n\\nGHGFF,t|PRS\\n\\ngreenhouse gas emissions from fossil fuel combustion in year t in the project scenario, tCO2-e; and\\n\\nGHGFERT,t|PRS\\n\\ndirect N2O emission as a result of nitrogen application within the project boundary in year t, t CO2-e;\\n\\nCs,t |PRS\\n\\ncarbon stock change in soil organic carbon in year t in the project scenario, t CO2-e; and\\n\\n∆CAWB,t|PRS\\n\\nthe carbon stock change in above-ground woody biomass within the project boundary in year t in the project scenario; t CO2-e.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 44\\n\\nSTEP 6 – Ex-post Grassland Management Plans and stratification\\n\\nThis step recalibrates the GMP and the IGMP to account for environmental and management conditions that occurred during each verification period, and updates parameter selection for ex-post baseline scenario greenhouse gas emissions and ex post project scenario greenhouse gas emissions.\\n\\nWhere historical data were used to provide parameter input (such as rainfall, temperature, market forces) and management strategy decisions that generated ex-ante estimation of the baseline scenario, these data and management strategy decisions must be updated to use ex post data for the verification period.\\n\\nThe project proponent must, at a minimum, update rainfall and temperature parameters and baseline grassland management parameters in the GMP and IGMP where ex post data for management practices can be obtained or where historical or common practice justification can be made based on economic, rainfall and temperature patterns over the verification period.\\n\\nStep 6.1 Ex-post Grassland Management Plan\\n\\nThe GMP, the grassland management plan which defines the baseline management strategies and input data for ex ante estimates of greenhouse gas emissions in the baseline scenario, shall be updated with parameter values from:\\n\\nlivestock management including stocking rate, livestock type, and grazing days per land parcel;\\n\\ngrassland management including any biomass burning and/or vegetation clearing,\\n\\nand/or pasture improvement;\\n\\nfertilizer use as mass of synthetic fertilizer and/or mass of organic fertilizer; and\\n\\nfossil fuel consumed (as represented by fuel purchased by fuel type).\\n\\nProject proponents must provide credible evidence for updated values to the ex-post GMP for the baseline scenario in the VCS verification report.\\n\\nStratification shall be updated where environmental or market conditions during the verification period would justify a change in the GMP. Evidence for updated stratification must come from recorded common practice for the baseline grassland management scenario. It is not acceptable to update the baseline stratification based on evidence from indictors that arise from project activity.\\n\\nProject proponents must submit evidence for changes to baseline scenario strata in the verification report.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 45\\n\\nStep 6.2 Ex-post Improved Grassland Management Plan\\n\\nThe improved grassland management plan which defines the project management strategies and input data for ex ante estimates of greenhouse gas emissions in the project scenario, must be updated with ex post measured and monitored parameters.\\n\\nIGMP, the\\n\\nWhere management strategies deviated from those in the ex ante IGMP, project proponents must update the ex post IGMP and all changes must be reported in the VCS verification report.\\n\\nStratification shall be updated where environmental or market conditions during the verification period would justify a change in the IGMP. Evidence for updated stratification must come from recorded common practice for the baseline grassland management scenario. It is not acceptable to update the baseline stratification based on evidence from indictors that arise from project activity.\\n\\nProject proponents must submit evidence for changes to project scenario strata in the verification report.\\n\\nStep 6.3 Update carbon pools and greenhouse gas emission sources\\n\\nAs ex post grassland management strategies may have deviated from those in the ex ante GMP and IGMP, this step reselects carbon pools and greenhouse gas emission sources that are required or are material in the ex post GMP and the ex post IGMP.\\n\\nStep 6.3.1 Carbon stock additions from above-ground woody biomass\\n\\nIn the baseline scenario, project proponents shall use the approved A/R CDM Guidance on Conditions under which the Change in Carbon Stocks in Existing Live Woody Vegetation Need not be Accounted, to determine whether the change in carbon stocks in existing live woody vegetation (i.e. in trees and shrubs) are to be accounted in the ex post baseline scenario greenhouse gas accounts.\\n\\nEquations are given in Step 7.2.1\\n\\nIn the project scenario, project proponents may conservatively exclude above-ground woody biomass carbon stock additions from the ex-post project scenario greenhouse accounts.\\n\\nWhere project proponents choose to account above-ground woody biomass carbon stock additions, equations are given in Step 8.3.1\\n\\nStep 6.3.2 Above-ground woody biomass carbon stock losses\\n\\nIn the baseline scenario, where biomass clearing and/or burning is included in the management strategies described in the GMP, project proponents may choose to conservatively exclude carbon stock losses in above-ground woody biomass from the ex- post baseline scenario greenhouse gas accounts.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 46\\n\\nWhere project proponents choose to account above-ground woody biomass carbon stock losses, equations are given in Step 7.2.2\\n\\nIn the baseline scenario, if fire is included in the management strategies described in the GMP, the area burned shall be defined as a stratum, and all biomass in the stratum shall be considered to be burned.\\n\\nIn the project scenario, where biomass clearing and/or burning is an included management strategy in the ex post IGMP, above-ground woody biomass carbon stock losses must be included in ex-post project scenario greenhouse gas accounts.\\n\\nEquations for above-ground woody biomass carbon stock losses in the project scenario are given in Step 8.3.2\\n\\nStep 6.3.3 Enteric emissions from methane production\\n\\nIn the baseline scenario, project proponents may choose to conservatively exclude enteric emissions from the ex-post baseline scenario greenhouse gas accounts.\\n\\nWhere project proponents choose to account enteric emissions, equations are given in Step 7.3\\n\\nIn the project scenario, it is necessary to compare ex post baseline scenario GMP and the ex post project scenario IGMP, and if there is:\\n\\n(d) no change in livestock numbers and livestock composition or type; or\\n\\n(e) a decrease in livestock numbers and no substitution to more emissions\\n\\nintensive livestock type(s) in the IGMP; or\\n\\n(f) a substitution to less emissions intensive livestock type(s) and no increase in\\n\\nlivestock numbers in the IGMP;\\n\\nproject proponents may choose to exclude enteric emissions from the ex-post project scenario greenhouse gas accounts.\\n\\nEnteric emissions must be accounted in the ex-post project scenario greenhouse gas accounts in all other situations using equations given in Step 8.4\\n\\nStep 6.3.4 Emissions from fossil fuel combustion\\n\\nIn the baseline scenario, project proponents may choose to conservatively exclude emissions from fossil fuel combustion from the ex-post baseline scenario greenhouse gas accounts.\\n\\nWhere project proponents choose to account emissions from fossil fuel combustion, equations are given in Step 7.4\\n\\nIn the project scenario, it is necessary to compare ex-post baseline scenario GMP and the ex-post project scenario IGMP, and if there is:\\n\\n(d) no change in fuel consumed and fuel type; or\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 47\\n\\n(e) a decrease in fuel consumed and no substitution to more emissions intensive\\n\\nfuel type(s) in the IGMP; or\\n\\n(f) a substitution to less emissions intensive fuel type(s) and no increase in fuel\\n\\nconsumed in the IGMP;\\n\\nproject proponents may choose to exclude emissions from fossil fuel combustion in the ex- post project scenario greenhouse gas accounts.\\n\\nEmissions from fossil fuel combustion must be accounted in the ex-post project scenario greenhouse gas accounts in all other situations using equations given in Step 8.5\\n\\nStep 6.3.5 Emissions from fertilizer use\\n\\nIn the baseline scenario, where fertilizer use is included in the management strategies described in the GMP, project proponents may choose to conservatively exclude emissions from fertilizer use the ex-post baseline scenario greenhouse gas accounts.\\n\\nWhere project proponents choose to account fertilizer use, equations are given in Step 7.5\\n\\nIn the project scenario, where fertilizer use in an included management strategy in the IGMP, emissions from fertilizer use must be included in ex-post project scenario greenhouse gas accounts using equations given in Step 8.6\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 48\\n\\nSTEP 7 – Ex post Net Greenhouse Gas Emissions in the baseline scenario\\n\\nStep 7.1 Determine SOC stock change in the baseline scenario\\n\\nThe output of this step is ex post estimation of SOC stock change in the baseline scenario for the current verification period.\\n\\nStep 7.1.1 Collate ex post parameter data for spatial co-ordinates\\n\\nProject proponents must update the input parameters for each spatial co-ordinate with actual data for the verification period.\\n\\nStep 7.1.2 Run SOC model for the baseline scenario\\n\\nProponents shall rerun the ex-ante SOC model for the baseline scenario at each of the selected spatial co-ordinates using the updated input parameters.\\n\\nThe output of the modelling will be a matrix of values for the SOC stock at each spatial coordinate for each year of the verification period.\\n\\nStep 7.1.3 Spatial interpolation of SOC stock\\n\\nAt this step, the same spatial interpolation algorithms used for ex-ante estimation of SOC stocks in the baseline scenario shall be applied to the matrix of ex-post SOC stock estimates to generate an ex-post SOC stock profile for the baseline scenario in the preceding verification period.\\n\\nStep 7.2 Determine carbon stock change in above-ground woody biomass in the baseline scenario\\n\\nThis step calculates ∆CAWB,t|BSL , the carbon stock change in above-ground woody biomass within the project boundary in year t in the baseline scenario.\\n\\nStep 7.2.1 Above-ground woody biomass carbon stock additions in the baseline scenario\\n\\nThis step calculates ∆CAWB_AD,t|BSL above-ground woody biomass carbon stock additions in year t in the baseline scenario.\\n\\nIf at Step 6.3.1 above-ground woody biomass carbon stock additions need not be accounted in the ex-post baseline scenario, then:\\n\\n∆CAWB_AD,t|BSL = 0\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 49\\n\\nOtherwise, proponents shall use the approved A/R Methodological Tool Estimation of carbon stocks and change in carbon stocks of trees and shrubs in A/R CDM project, to determine the following parameters23:\\n\\n∆CTREE_BSL,t\\n\\nchange in carbon stock in tree biomass within the project boundary in the baseline scenario in year t; t CO2-e\\n\\n∆CSHRUB_BSL,t change in carbon stock in shrub biomass within the project boundary\\n\\nin the baseline scenario in year t; t CO2-e\\n\\nProponents shall estimate above-ground woody biomass carbon stock additions in year t in the baseline scenario as:\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tAD\\n\\nBSL\\n\\nC\\n\\nTREE\\n\\n_\\n\\nBSL\\n\\n, t\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nBSL\\n\\n, t\\n\\n(37)\\n\\nWhere:\\n\\n∆CAWB_AD,t|BSL above-ground woody biomass carbon stock additions in year t in the\\n\\nbaseline scenario; t CO2-e\\n\\n∆CTREE_BSL,t\\n\\nchange in carbon stock in tree biomass within the project boundary in the baseline scenario in year t; t CO2-e; and\\n\\n∆CSHRUB_BSL,t change in carbon stock in shrub biomass within the project boundary\\n\\nin the baseline scenario in year t; t CO2-e.\\n\\nStep 7.2.2 Above-ground woody biomass carbon stock losses in the baseline scenario\\n\\nThis step calculates ∆CAWB_LS,t|BSL, the change in above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the baseline scenario.\\n\\nIf at Step 6.3.2, above-ground woody biomass carbon stock additions need not be accounted in the ex-post baseline scenario, then:\\n\\n∆CAWB_LS,t|BSL = 0\\n\\nIf fire is used, the area burned shall be defined as a stratum, and all biomass in the stratum is considered to be burned. Burning from unplanned disturbance is dealt with separately under the ex-post project scenario (Step 11.4).\\n\\nProject proponents must use the approved A/R Methodological Tool Estimation of carbon stocks and change in carbon stocks of trees and shrubs in A/R CDM project activities to determine the following parameters:\\n\\n23 ∆CTREE_BSL,t and ∆CSHRUB_BSL,t are parameters in the A/R Methodological Tool and do not use the same nomenclature scenario qualifiers as this methodology.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 50\\n\\nCTREE_BSL,i,t\\n\\ncarbon stock in tree biomass in stratum i in the baseline scenario in year t; t C; and\\n\\nCSHRUB_BSL,i,t\\n\\ncarbon stock in shrub biomass in stratum i in the baseline scenario in year t; t C.\\n\\nProponents shall then estimate the above-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i in year t in the baseline scenario as:\\n\\nC\\n\\nAWB\\n\\n|,, ti\\n\\nBSL\\n\\nC\\n\\nTREE\\n\\n_\\n\\nBSL\\n\\n,, ti\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nBSL\\n\\n,, ti\\n\\n(38)\\n\\nWhere:\\n\\nCAWB,i,t|BSL\\n\\nabove-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i year t in the baseline scenario; t CO2-e\\n\\nCTREE_BSLi,,t\\n\\ncarbon stock in tree biomass within the project boundary in stratum i in the baseline scenario in year t; t CO2-e; and\\n\\nCSHRUB_BSLi,,t\\n\\ncarbon stock in shrub biomass within the project boundary in stratum i in the baseline scenario in year t; t CO2-e.\\n\\nTherefore, ∆CAWB_LS,t|BSL, the change in above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the baseline scenario is calculated as:\\n\\nC\\n\\nAWB\\n\\n_\\n\\ntLS |,\\n\\nBSL\\n\\nC\\n\\nAWB\\n\\nti |,,\\n\\nBSL\\n\\n(39)\\n\\ni\\n\\nWhere:\\n\\n∆CAWB_LS,t|BSL change\\n\\nin above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the baseline scenario; t CO2-e;\\n\\nCAWB i,t|BSL\\n\\nabove-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i year t in the baseline scenario; t CO2-e; and\\n\\ni\\n\\n1,2,3… clearing and/or burning strata.\\n\\nWhere fire is used, it is necessary to also estimate the instantaneous non-CO2 greenhouse gas emissions due to burning of tree and shrub biomass within those strata (Box 3).\\n\\nBox 3. Non-CO2 greenhouse gas emissions due to biomass burning This box calculates the non-CO2 greenhouse gas emissions due to biomass burning. These emissions are treated as an instantaneous greenhouse gas emission and not a carbon stock change.\\n\\nProponents shall estimate non-CO2 emissions from tree biomass due to managed fire in\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 51\\n\\nstratum i in year t in the baseline scenario as:\\n\\nGHG\\n\\nTREE\\n\\nti |,,\\n\\nBSL\\n\\nC\\n\\nTREE\\n\\n_\\n\\nBSL\\n\\nti ,,\\n\\nCOMF\\n\\nTREE\\n\\n,\\n\\ni\\n\\nER\\n\\nCH\\n\\n4\\n\\n16 44\\n\\nGWP\\n\\nCH\\n\\n4\\n\\n(40)\\n\\nWhere:\\n\\nGHGTREE,i,t|BSL non-CO2 greenhouse gas emissions from tree biomass due to\\n\\nCTREE_BSLi,,t\\n\\nmanaged fire in stratum i in year t in the baseline scenario; t CO2-e; carbon stock in tree biomass within the project boundary in stratum i in the baseline scenario in year t; t CO2-e;\\n\\nCOMFTREE,i\\n\\nERCH4\\n\\n16/44\\n\\nGWPCH4\\n\\ncombustion factor for tree biomass in stratum i, dimensionless; emissions factor for CH4, t CH4 t-1 C burnt; ratio of molecular weights of CH4 and CO2; mol mol-1; and global warming potential for CH4; t CO2-e t-1 CH4.\\n\\nProponents shall then estimate non-CO2 emissions from shrub biomass due to managed fire in stratum i in year t in the baseline scenario as:\\n\\nGHG\\n\\nSHRUB\\n\\nti |,,\\n\\nBSL\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nBSL\\n\\nti ,,\\n\\nCOMF\\n\\nSHRUB\\n\\ni\\n\\nER\\n\\nCH\\n\\n4\\n\\n16 44\\n\\nGWP\\n\\nCH\\n\\n4\\n\\n(41)\\n\\nWhere:\\n\\nGHGSHRUB,i,t|BSL non-CO2 greenhouse gas emissions from shrub biomass due to\\n\\nCSHRUB_BSLi,,t\\n\\nmanaged fire in stratum i in year t in the baseline scenario; t CO2-e; carbon stock in shrub biomass within the project boundary in stratum i in the baseline scenario in year t; t CO2-e;\\n\\nCOMFSHRUB,i combustion factor for shrub biomass in stratum i, dimensionless;\\n\\nERCH4\\n\\n16/44\\n\\nGWPCH4\\n\\nemissions factor for CH4, t CH4 t-1 C burnt; ratio of molecular weights of CH4 and CO2; mol mol-1; and global warming potential for CH4; t CO2-e t-1 CH4.\\n\\nTherefore, non-CO2 greenhouse gas emissions due to managed fire in year t in the baseline scenario are calculated as:\\n\\nGHG\\n\\nAWB\\n\\n|, t\\n\\nBSL\\n\\nGHG\\n\\nTREE\\n\\n|,, ti\\n\\nBSL\\n\\nGHG\\n\\nSHRUB\\n\\n|,, ti\\n\\nBSL\\n\\n(42)\\n\\ni\\n\\nGHGAWB,t|BSL non-CO2 greenhouse gas emissions from above-ground woody biomass due to managed fire in year t in the baseline scenario; t CO2- e;\\n\\nGHGTREE,i,t|BSL non-CO2 greenhouse gas emissions from tree biomass due to\\n\\nmanaged fire in stratum i in year t in the baseline scenario; t CO2-e;\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 52\\n\\nGHGSHRUB,i,t|BSL non-CO2 greenhouse gas emissions from shrub biomass due to managed fire in stratum i in year t in the baseline scenario; t CO2-e; and\\n\\ni\\n\\n1,2,3… clearing and/or burning strata.\\n\\nStep 7.2.3 Above-ground woody biomass carbon stock in the baseline scenario\\n\\nTherefore, ∆CAWB,t|BSL , the carbon stock change in above-ground woody biomass within the project boundary in year t in the baseline scenario is calculated as follows:\\n\\nC\\n\\nAWB\\n\\n|, t\\n\\nBSL\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tLS\\n\\nBSL\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tAD\\n\\nBSL\\n\\n(43)\\n\\nWhere:\\n\\n∆CAWB,t|BSL\\n\\nthe carbon stock change in above-ground woody biomass within the project boundary in year t in the baseline scenario; t CO2-e;\\n\\n∆CAWB_AD,t|BSL above-ground woody biomass carbon stock additions in year t in the\\n\\nbaseline scenario; t CO2-e; and\\n\\n∆CAWB_LS,t|BSL change\\n\\nin above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the baseline scenario; t CO2-e.\\n\\nStep 7.3 Determine methane production from enteric emissions in the ex-post baseline scenario\\n\\nIf at Step 6.3.3 methane production from enteric emissions need not be accounted in the ex-post baseline scenario, then\\n\\nGHGENTERIC,t|BSL.= 0\\n\\nOtherwise, the updated ex-post GMP inputs data to the following parameters:\\n\\nNl,t|BSL\\n\\nnumber of livestock of type l in year t in the baseline scenario, head yr-1; and\\n\\nGPl,t|BSL\\n\\ngrazing days for livestock type l in year t in the baseline scenario, days.\\n\\nProponents shall then estimate methane production from enteric emissions in year t in the ex-post baseline scenario as:\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 53\\n\\nEF l\\n\\nGE\\n\\nMCF l\\n\\nl 65.55\\n\\n(44)\\n\\nWhere:\\n\\nEFl\\n\\nGEl\\n\\nemissions factor for livestock type l, kg CH4 head-1 day-1; gross energy intake livestock type l, MJ head-1 day-1;\\n\\nMCFl\\n\\nmethane conversion factor for livestock type l, fraction of gross energy in feed converted to methane;\\n\\n55.65\\n\\nenergy content of methane, MJ/kg CH4; and\\n\\nl\\n\\nspecies/category/type of livestock.\\n\\nE\\n\\nENTERIC\\n\\n|, t\\n\\nBSL\\n\\nEF l\\n\\nN\\n\\n|, tl\\n\\nBSL\\n\\nGP |, tl\\n\\nBSL\\n\\n(45)\\n\\nl\\n\\nWhere:\\n\\nEENTERIC,t|BSL\\n\\nEFl\\n\\nmethane emissions from enteric fermentation in year t in the baseline scenario, kg CH4 yr-1; emissions factor for livestock type l, kg CH4 head-1 day-1;\\n\\nNl,t|BSL\\n\\nnumber of livestock of type l in year t in the baseline scenario, head yr-1;\\n\\nGPl,t|BSL\\n\\ngrazing days for livestock type l in year t in the baseline scenario, days; and\\n\\nl\\n\\nspecies/category/type of livestock.\\n\\nThe conversion of methane production to carbon dioxide equivalents shall be calculated as:\\n\\nGHG\\n\\nENTERIC\\n\\n|, t\\n\\nBSL\\n\\nE\\n\\nENTERIC\\n\\n|, t\\n\\nBSL\\n\\n23\\n\\n10\\n\\n3\\n\\n(46)\\n\\nWhere:\\n\\nGHGENTERIC,t|BSL\\n\\ngreenhouse gas emissions from enteric fermentation in year t in the baseline scenario; t CO2-e yr-1;\\n\\nEENTERIC,t|BSL\\n\\nmethane emissions from enteric fermentation in year t in the baseline scenario, kg CH4 yr-1; and\\n\\n23\\n\\nglobal warming potential integrated over 100 years for CH4, t CO2-e t-1 CH4.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 54\\n\\nStep 7.4 Determine emissions from fossil fuel combustion in the ex-post baseline scenario\\n\\nIf at Step 6.3.4 emissions from fossil fuel combustion need not be accounted in the ex-post baseline scenario, then:\\n\\nGHGFF,t|BSL. = 0\\n\\nOtherwise, the updated ex-post GMP inputs data to the following parameters:\\n\\nFCf,t|BSL\\n\\nfuel consumed (as represented by fuel purchased) for fuel type f in year t in the baseline scenario, kL.\\n\\nf\\n\\nfuel type.\\n\\nGreenhouse gas emissions from fossil fuel combustion in the ex-post baseline scenario in year t shall be calculated as follows:\\n\\n3\\n\\nf\\n\\n\\n\\nGHG\\n\\ntFF ,\\n\\nBSL\\n\\nEC\\n\\ntf |,\\n\\nBSL\\n\\nEF\\n\\nfg ,\\n\\nGWP g\\n\\n10\\n\\n3\\n\\n(47)\\n\\ng\\n\\n1\\n\\nf\\n\\n1\\n\\nWhere:\\n\\nGHGFF,t|BSL\\n\\ngreenhouse gas emissions from fossil fuel combustion in year t in the baseline scenario, tCO2-e yr-1;\\n\\nECf,t|BSL\\n\\nEFg,f\\n\\nenergy consumed for fuel type f in year t in the baseline scenario, TJ; emissions factor for greenhouse gas g for fuel type f; kg TJ-1;\\n\\nGWP100,g\\n\\nglobal warming potential greenhouse gas g, t CO2-e t-1;\\n\\nintegrated over 100 years for\\n\\ng\\n\\nunique identifier for each greenhouse gas; and\\n\\nf\\n\\nfuel type.\\n\\nThe energy consumed for each fuel type in the baseline scenario shall be calculated as follows:\\n\\nEC\\n\\n|, tf\\n\\nBSL\\n\\nFC\\n\\n|, tf\\n\\nBSL\\n\\nNCV\\n\\nf\\n\\nD\\n\\nf\\n\\n(48)\\n\\nWhere:\\n\\nECf,t|BSL\\n\\nenergy consumed for fuel type f in year t in the baseline scenario, TJ;\\n\\nFCf,t|BSL\\n\\nNCVf\\n\\nfuel consumed (as represented by fuel purchased) for fuel type f in year t in the baseline scenario, kL; net calorific value for fuel type f, TJ Gg-1; and\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 55\\n\\nDf\\n\\ndensity of fuel type f, Gg kL-1.\\n\\nStep 7.5 Determine emissions from fertilizer use in the ex-post baseline scenario\\n\\nIf at Step 6.3.3 emissions from fertilizer use need not be accounted in the ex-post baseline scenario, then:\\n\\nGHGFERT,t|BSL. = 0\\n\\nOtherwise, the updated ex-post GMP inputs data to the following parameters:\\n\\nMSF,k,t mass of synthetic fertilizer type k applied in year t, t;\\n\\nMOF,j,t mass of organic fertilizer type j applied in year t, t.\\n\\nIf flooding irrigation or any natural flood has occurred on the project area within a period of 3 months from date of fertilizer application, then GHGFERT,t|BSL for that year t is conservatively estimated as:\\n\\nGHG\\n\\nFERT\\n\\nt |, BSL\\n\\n0\\n\\nFor all other years, the direct nitrous oxide emissions from nitrogen fertilization in year t shall be calculated as:\\n\\nGHG\\n\\nFERT\\n\\n|, t\\n\\nBSL\\n\\n(\\n\\nF\\n\\nSN\\n\\n,\\n\\nt\\n\\nF\\n\\n, tON\\n\\n)\\n\\nEF 1\\n\\n44 28\\n\\nGWP\\n\\nON 2\\n\\n(49)\\n\\nWhere:\\n\\nGHGFERT,t|BSL\\n\\ndirect N2O emission as a result of nitrogen application within the project boundary in year t, t CO2-e;\\n\\nFSN,t\\n\\nMass of synthetic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nFON,t\\n\\nEF1\\n\\n44/28\\n\\nmass of organic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N; emission factor for emissions from N inputs, t N2O-N t-1 N input; ratio of molecular weights of N2O and N, t N2O t-1 N; and\\n\\nONGWP\\n\\n2\\n\\nglobal warming potential integrated over 100 years for N2O, t CO2-e t-1 N2O.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 56\\n\\nF\\n\\nSN\\n\\n,\\n\\nt\\n\\nM\\n\\nSF\\n\\n,\\n\\ntk ,\\n\\nNC\\n\\nSF\\n\\n,\\n\\nk\\n\\n1(\\n\\nFrac\\n\\nGASF\\n\\n)\\n\\n(50)\\n\\nk\\n\\nWhere:\\n\\nFSN,t\\n\\nmass of synthetic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nMSF,k,t\\n\\nmass of synthetic fertilizer type k applied in year t, t;\\n\\nNCSF,k\\n\\nnitrogen content of synthetic fertilizer type k applied, g N 100g-1 fertilizer;\\n\\nFracGASF\\n\\nFraction that volatilises as NH3 and NOX for synthetic fertilizers, dimensionless; and\\n\\nk\\n\\nsynthetic fertilizer type.\\n\\nF\\n\\ntON ,\\n\\nM\\n\\ntjOF , ,\\n\\nNC\\n\\njOF ,\\n\\n1(\\n\\nFrac\\n\\nGASM\\n\\n)\\n\\n(51)\\n\\nj\\n\\nWhere:\\n\\nFON,t\\n\\nmass of organic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nMOF,j,t\\n\\nNCOF,j\\n\\nmass of organic fertilizer type j applied in year t, t; nitrogen content of organic fertilizer type j applied, g N 100g-1 fertilizer; and\\n\\nFracGASM\\n\\nFraction that volatilises as NH3 and NOX for organic fertilizers, dimensionless; and\\n\\nj\\n\\norganic fertilizer type.\\n\\nStep 7.6 Net greenhouse gas emissions in the ex-post baseline scenario\\n\\nThis step calculates GHGNET,t|BSL, the net GHG emissions in year t in the baseline scenario.\\n\\nProponents shall calculate the net greenhouse gas emissions in year t in the ex-post baseline scenario as:\\n\\nGHG\\n\\nNET\\n\\n|, t\\n\\nBSL\\n\\nC\\n\\n|, tS\\n\\nBSL\\n\\nC\\n\\nAWB\\n\\n|, t\\n\\nBSL\\n\\nGHG\\n\\nAWB\\n\\n|, t\\n\\nBSL\\n\\nGHG\\n\\nENTERIC\\n\\n|, t\\n\\nBSL\\n\\nGHG\\n\\n|, tFF\\n\\nBSL\\n\\nGHG\\n\\nFERT\\n\\n|, t\\n\\nBSL\\n\\n(52)\\n\\nWhere:\\n\\nGHGNET,t|BSL\\n\\nnet greenhouse gas emissions in year t in the baseline scenario; t CO2-e;\\n\\nCs,t |BSL\\n\\ncarbon stock change in soil organic carbon in year t in the baseline scenario, t CO2-e;\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 57\\n\\n∆CAWB,t|BSL\\n\\nGHGAWB,t|BSL\\n\\nGHGENTERIC,t|BSL\\n\\nGHGFF,t|BSL\\n\\nGHGFERT,t|BSL\\n\\nIGM Methodology\\n\\nthe carbon stock change in above-ground woody biomass within the project boundary in year t in the baseline scenario; t CO2-e\\n\\nnon-CO2 greenhouse gas emissions from above-ground woody biomass due to managed fire in year t in the baseline scenario; t CO2-e;\\n\\ngreenhouse gas emissions from enteric fermentation in year t in the baseline scenario; t CO2-e;\\n\\ngreenhouse gas emissions from fossil fuel combustion in year t in the baseline scenario, tCO2-e; and\\n\\ndirect N2O emission as a result of nitrogen application within the project boundary in year t, t CO2-e.\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 58\\n\\nSTEP 8 – Ex-post Net Greenhouse Gas Emissions in the Project Scenario\\n\\nThis step calculates ex-post net greenhouse gas emissions, GHGNET|PRS, in the project scenario.\\n\\nStep 8.1 Estimate SOC stock change in the ex-post project scenario from SOC modelling\\n\\nThe output of this step is ex-post estimation of SOC stock change in the project scenario for each verification period.\\n\\nProject proponents shall use a model calibration method to calculate and monitor SOC stock change in the project scenario.\\n\\nStep 8.1.1 Collate ex post parameter data for spatial co-ordinates\\n\\nProject proponents must update the input parameters for each spatial co-ordinate used to determine the ex-ante project scenario with actual data for the verification period under the project scenario.\\n\\nEnvironmental data must be obtained from the same sources as those used to parameterize the project scenario modelling and from records contained in the ex-post IGMP.\\n\\nStep 8.1.2 Run SOC model for the ex-post project scenario\\n\\nProponents shall rerun the SOC model for the ex-post project scenario at each of the spatial co-ordinates generated for the ex-ante project scenario using the updated input parameters.\\n\\nThe output of the modelling will be a matrix of values for the SOC stock at each spatial coordinate for each year of the verification period.\\n\\nStep 8.1.3 Spatial interpolation of SOC stock\\n\\nAt this step, the same spatial interpolation algorithms used for ex-ante estimation of SOC stocks in the project scenario shall be applied to the matrix of ex-post SOC stock estimates to generate an ex-post SOC stock profile for the project scenario in the verification period.\\n\\nStep 8.2 Validate SOC stock change estimate in the ex-post project scenario\\n\\nThis step completes the calibration of the SOC model output by comparison with selective SOC values determined by field sampling in the project area.\\n\\nThis step requires the completion of field sampling of SOC.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 59\\n\\nThe methods applied to field sampling and SOC analysis described below must be applied. However, new technologies can be applied as they become available once scientific peer review and tests on soils equivalent to those in the project scenario have been completed.\\n\\nIt is acceptable for proponents to outsource soil sampling and soil analysis to certified analytical laboratories.\\n\\nStep 8.2.1 Determine stratified sampling design for field measurement of SOC\\n\\nProponents must generate a soil sampling design prior to completing fieldwork.\\n\\nField sampling shall take place at a sub-set of the spatial co-ordinates used to generate output for the chosen SOC model. The sub-set of spatial co-ordinates shall be stratified to cover the project area and include the strata used as parameters in the chosen SOC model for the project scenario.\\n\\nThe sub-set of spatial co-ordinates must include:\\n\\nthe major soil types;\\n\\nsampling from a minimum of three co-ordinates in sufficient strata identified in the\\n\\nproject scenario that cover 80% of the project area; include all areas of the project where variance in model output is 65% greater than the average variance; and\\n\\na minimum of 30 samples across the project area.\\n\\nThe sampling design must be described in the VCS verification report.\\n\\nStep 8.2.2 Field sampling\\n\\nSoil sampling for SOC must follow standard procedures compliant with ISO standards.24\\n\\nThe standard depth of soil sampling shall be 30cm.\\n\\nDepth of soil samples may differ from 30cm where this is necessary for consistency with the parameters and output of the selected SOC model. It is only acceptable to compare model output for soil to a depth that is consistent with the chosen SOC model. Justification for any variance from the 30cm depth of sampling must be provided in the verification report.\\n\\nAt each sampling co-ordinate three soil cores must be taken within a minimum of 1m radius, and no greater than 5m radius, apart, to the determined sampling depth. These samples must be pooled and sub-sampled for analysis following ISO compliant procedures.25\\n\\n24 ISO 10381-2:2003 Soil quality – sampling – Part 2: Guidance on sampling techniques\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 60\\n\\nStep 8.2.3 Sample analysis for SOC determination\\n\\nIt is acceptable to use either dry combustion or wet oxidation methods to determine soil organic carbon content of soil samples where the method chosen is compliant with ISO standards for soil carbon analysis.26\\n\\nIt is also acceptable to apply new technologies as they become available once scientific peer review and tests on soils equivalent to those in the project scenario have been completed.\\n\\nAll SOC estimates must be given as a carbon density. Where the chosen SOC model produces SOC estimates as a percentage (%C) it is necessary to convert %C to carbon density by measurement of soil bulk density for each soil sample. Methods for the determination of bulk density must be ISO compliant27 and be described in the verification report.\\n\\nStep 8.2.4 Comparison of SOC from model output and field sampling\\n\\nThis step compares the SOC estimates from model output with SOC estimates from field sampling.\\n\\nFor the sub-set of spatial co-ordinates proponents shall complete a table comparing the model and sampled SOC values and complete significance tests.\\n\\nStatistical testing shall be applied sequentially to determine:\\n\\nany statistical difference between the model output and field sample estimates of\\n\\nSOC across the sample sub-set that there is no strata effect on the difference between the model output and field sample estimates of SOC that there is no spatial effect on the difference between the model output and field sample estimates of SOC\\n\\nThe project proponent must complete a paired comparison test on data from the sub-set of spatial co-ordinates used in the field sampling to determine if the estimates of SOC from field sampling are significantly different to the SOC values predicted by the SOC model.\\n\\n25 ISO 10381-2:2003 Soil quality – sampling – Part 2: Guidance on sampling techniques\\n\\n26 ISO 10694:1995 Soil quality -- Determination of organic and total carbon after dry combustion (elementary analysis), and ISO 14235:1998 Soil quality -- Determination of organic carbon by sulfochromic oxidation.\\n\\n27 ISO 11272: 1998 Soil quality - Determination of dry bulk density\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 61\\n\\nWhere paired comparison test are significant a sign test shall be completed to determine whether the model output or field samples give consistently higher values. Where this analysis shows that the field samples are consistently higher than estimates from the SOC model, the proponent shall use the model output to calculate the SOC stock change in the project scenario.\\n\\nWhere the paired comparison test is not statistically significant or where the test is significant but a sign test does not confirm that field samples are consistently above SOC model estimates for SOC, project proponents shall compute paired comparison tests on data from the sub-set of spatial co-ordinates used in the field sampling that have been grouped by strata.\\n\\nEach major stratum that accounts for more than 10% of the project area shall form the groupings for analysis. Where the selection of strata fail to cover the project area it is necessary to also include a spatial stratification to the groupings for paired comparison tests.\\n\\nWhere paired comparison test for a stratum is significant a sign test shall be completed to determine whether the model output or field samples give consistently higher values. Where this analysis shows that the field samples are consistently higher than estimates from the SOC model, the proponent shall use the model output to calculate the SOC stock change in the project scenario for that stratum.\\n\\nWhere the overall paired test for a stratum is significant but the sign test shows that SOC model estimates are consistently higher than sample values, then the field sample values for the stratum must be used to compute a spatial interpolation of SOC for the calculation of SOC in the project scenario.\\n\\nComputation of spatial interpolation of SOC for the calculation of SOC in the project scenario shall include SOC model estimates and field sample values for strata where the model predicts higher SOC than was observed. As field sample values will be fewer in number than the original spatial co-ordinates matrix and lower than the model predictions this interpolation is conservative.\\n\\nStep 8.3 Determine carbon stock change in above-ground woody biomass in the ex-post project scenario\\n\\nThis step calculates ∆CAWB,t|PRS, the carbon stock change in above-ground woody biomass within the project boundary in year t in the ex-post project scenario.\\n\\nStep 8.3.1 Above-ground woody biomass carbon stock additions in the ex-post project scenario\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 62\\n\\nThis step calculates ∆CAWB_AD,t|PRS above-ground woody biomass carbon stock additions in year t in the project scenario.\\n\\nIf at Step 6.3.1 above-ground woody biomass carbon stock additions need not be accounted in the ex-post project scenario, then:\\n\\n∆CAWB_AD,t|PRS = 0\\n\\nOtherwise, proponents shall use the approved A/R Methodological Tool Estimation of carbon stocks and change in carbon stocks of trees and shrubs in A/R CDM project, to determine the following parameters:\\n\\n∆CTREE_PROJ,t change in carbon stock in tree biomass within the project boundary in\\n\\nthe project scenario in year t; t CO2-e\\n\\n∆CSHRUB_PROJ,t change in carbon stock in shrub biomass within the project boundary\\n\\nin the project scenario in year t; t CO2-e\\n\\nProponents shall estimate above-ground woody biomass carbon stock additions in year t in the ex-post project scenario as:\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tAD\\n\\nPRS\\n\\nC\\n\\nTREE\\n\\n_\\n\\nPROJ\\n\\n, t\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nPROJ\\n\\n, t\\n\\n(53)\\n\\nWhere:\\n\\n∆CAWB_AD,t|PRS above-ground woody biomass carbon stock additions in year t in the\\n\\nproject scenario; t CO2-e\\n\\n∆CTREE_PRS,t\\n\\nchange in carbon stock in tree biomass within the project boundary in the project scenario in year t; t CO2-e; and\\n\\n∆CSHRUB_PRS,t change in carbon stock in shrub biomass within the project boundary\\n\\nin the project scenario in year t; t CO2-e.\\n\\nStep 8.3.2 Above-ground woody biomass carbon stock losses in the ex-post project scenario\\n\\nThis step calculates ∆CAWB_LS,t|PRS, the change in above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the ex-post project scenario. Where unplanned disturbance to above-ground woody biomass occurs, the equations in this step are used to calculate these carbon stock losses. Guidance on unplanned disturbance and how to include it within these equations is dealt with under project monitoring (Step 12.4).\\n\\nIf at Step 6.3.2, above-ground woody biomass carbon stock losses need not be accounted in the ex-post project scenario and no unplanned disturbance has occurred, then:\\n\\n∆CAWB_LS,t|PRS = 0\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 63\\n\\nIf fire is used, the area burned shall be defined as a stratum, and all biomass in the stratum is considered to be burned.\\n\\nProject proponents must use the approved A/R Methodological Tool Estimation of carbon stocks and change in carbon stocks of trees and shrubs in A/R CDM project activities to determine the following parameters:\\n\\nCTREE_PROJ,i,t\\n\\ncarbon stock in tree biomass in statum i in the ex-post project scenario in year t; t C; and\\n\\nCSHRUB_PROJ,i,t carbon stock in shrub biomass in stratum i in the ex-post project\\n\\nscenario in year t; t C.\\n\\nProponents shall then estimate the above-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i in year t in the ex-post project scenario as:\\n\\nC\\n\\nAWB\\n\\n|,, ti\\n\\nPRS\\n\\nC\\n\\nTREE\\n\\n_\\n\\nPROJ\\n\\n,, ti\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nPROJ\\n\\n,, ti\\n\\n(54)\\n\\nWhere:\\n\\nCAWB,i,t|PRS\\n\\nabove-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i year t in the ex-post project scenario; t CO2-e\\n\\nCTREE_PRSi,,t\\n\\ncarbon stock in tree biomass within the project boundary in stratum i in the ex-post project scenario in year t; t CO2-e; and\\n\\nCSHRUB_PRSi,,t\\n\\ncarbon stock in shrub biomass within the project boundary in stratum i in the ex-post project scenario in year t; t CO2-e.\\n\\nTherefore, ∆CAWB_LS,t|PRS, the change in above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the project scenario is calculated as:\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tLS\\n\\nPRS\\n\\nC\\n\\nAWB\\n\\n|,, ti\\n\\nPRS\\n\\n(55)\\n\\ni\\n\\nWhere:\\n\\n∆CAWB_LS,t|PRS change\\n\\nin above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the project scenario; t CO2-e;\\n\\nCAWB,i,t|PRS\\n\\nabove-ground woody biomass carbon stock impacted by clearing and/or burning in stratum i year t in the project scenario; t CO2-e; and\\n\\ni\\n\\n1,2,3… clearing and/or burning strata.\\n\\nWhere fire is used, it is necessary to also estimate the instantaneous non-CO2 greenhouse gas emissions due to biomass burning of tree and shrub biomass within those strata (Box 4).\\n\\nBox 4. Non-CO2 greenhouse gas emissions due to biomass burning This box calculates the non-CO2 greenhouse gas emissions due to biomass burning. These emissions are treated as an instantaneous greenhouse gas emission and not a carbon stock change.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 64\\n\\nProponents shall estimate non-CO2 emissions from tree biomass due to managed fire in stratum i in year t in the project scenario as:\\n\\nGHG\\n\\nTREE\\n\\nti |,,\\n\\nPRS\\n\\nC\\n\\nTREE\\n\\n_\\n\\nPROJ\\n\\nti ,,\\n\\nCOMF\\n\\nTREE\\n\\n,\\n\\ni\\n\\nER\\n\\nCH\\n\\n4\\n\\n16 44\\n\\nGWP\\n\\nCH\\n\\n4\\n\\n(56)\\n\\nWhere:\\n\\nGHGTREE,i,t|PRS non-CO2 greenhouse gas emissions from tree biomass due to\\n\\nCTREE_PROJi,,t\\n\\nmanaged fire in stratum i in year t in the project scenario; t CO2-e; carbon stock in tree biomass within the project boundary in stratum i in the project scenario in year t; t CO2-e;\\n\\nCOMFTREE,i\\n\\nERCH4\\n\\n16/44\\n\\nGWPCH4\\n\\ncombustion factor for tree biomass in stratum i, dimensionless; emissions factor for CH4, t CH4 t-1 C burnt; ratio of molecular weights of CH4 and CO2; mol mol-1; and global warming potential for CH4; t CO2-e t-1 CH4.\\n\\nProponents shall then estimate non-CO2 emissions from shrub biomass due to managed fire in stratum i in year t in the project scenario as:\\n\\nGHG\\n\\nSHRUB\\n\\nti |,,\\n\\nPRS\\n\\nC\\n\\nSHRUB\\n\\n_\\n\\nPROJ\\n\\nti ,,\\n\\nCOMF\\n\\nSHRUB\\n\\n,\\n\\ni\\n\\nER\\n\\nCH\\n\\n4\\n\\n16 44\\n\\nGWP\\n\\nCH\\n\\n4\\n\\n(57)\\n\\nWhere:\\n\\nGHGSHRUB,i,t|PRS non-CO2 greenhouse gas emissions from shrub biomass due to\\n\\nmanaged fire in stratum i in year t in the project scenario; t CO2-e;\\n\\nCSHRUB_PROJi,,t carbon stock in shrub biomass within the project boundary in stratum\\n\\ni in the project scenario in year t; t CO2-e;\\n\\nCOMFSHRUB,i combustion factor for shrub biomass in stratum i, dimensionless;\\n\\nERCH4\\n\\n16/44\\n\\nGWPCH4\\n\\nemissions factor for CH4, t CH4 t-1 C burnt; ratio of molecular weights of CH4 and CO2; mol mol-1; and global warming potential for CH4; t CO2-e t-1 CH4.\\n\\nTherefore, non-CO2 greenhouse gas emissions due to managed fire in year t in the project scenario are calculated as:\\n\\nGHG\\n\\nAWB\\n\\n|, t\\n\\nPRS\\n\\nGHG\\n\\nTREE\\n\\n|,, ti\\n\\nPRS\\n\\nGHG\\n\\nSHRUB\\n\\n|,, ti\\n\\nPRS\\n\\n(58)\\n\\ni\\n\\nGHGAWB,t|PRS non-CO2 greenhouse gas emissions from above-ground woody biomass due to managed fire in year t in the project scenario; t CO2-e; GHGTREE,i,t|PRS non-CO2 greenhouse gas emissions from tree biomass due to\\n\\nmanaged fire in stratum i in year t in the project scenario; t CO2-e;\\n\\nGHGSHRUB,i,t|PRS non-CO2 greenhouse gas emissions from shrub biomass due to managed fire in stratum i in year t in the project scenario; t CO2-e; and\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 65\\n\\ni\\n\\n1,2,3… clearing and/or burning strata.\\n\\nStep 8.3.3 Above-ground woody biomass carbon stock in the project scenario\\n\\nTherefore, ∆CAWB,t|PRS , the carbon stock change in above-ground woody biomass within the project boundary in year t in the project scenario is calculated as follows:\\n\\nC\\n\\nAWB\\n\\n|, t\\n\\nPRS\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tAD\\n\\nPRS\\n\\nC\\n\\nAWB\\n\\n_\\n\\n|, tLS\\n\\nPRS\\n\\n(59)\\n\\nWhere:\\n\\n∆CAWB,t|PRS\\n\\nthe carbon stock change in above-ground woody biomass within the project boundary in year t in the project scenario; t CO2-e;\\n\\n∆CAWB_AD,t|PRS above-ground woody biomass carbon stock additions in year t in the\\n\\nproject scenario; t CO2-e; and\\n\\n∆CAWB_LS,t|PRS change\\n\\nin above-ground woody biomass carbon stock due to managed biomass clearing and/or burning in year t in the project scenario; t CO2-e.\\n\\nStep 8.4 Determine emissions from enteric methane production in the ex-post project scenario\\n\\nIf at Step 6.3.3 methane production from enteric emissions need not be accounted in the ex-post project scenario, then\\n\\nGHGENTERIC,t|PRS.= 0\\n\\nOtherwise, the updated ex-post IGMP inputs data to the following parameters:\\n\\nNl,t|PRS\\n\\nnumber of livestock of type l in year t in the project scenario, head yr-1; and\\n\\nGPl,t|PRS\\n\\ngrazing days for livestock type l in year t in the project scenario, days.\\n\\nProponents shall then estimate methane production from enteric emissions in year t in the ex-post project scenario as:\\n\\nEF l\\n\\nGE\\n\\nMCF l\\n\\nl 65.55\\n\\n(60)\\n\\nWhere:\\n\\nEFl\\n\\nGEl\\n\\nemissions factor for livestock type l, kg CH4 head-1 day-1; gross energy intake livestock type l, MJ head-1 day-1;\\n\\nMCFl\\n\\nmethane conversion factor for livestock type l, fraction of gross energy in feed converted to methane;\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 66\\n\\n55.65\\n\\nenergy content of methane, MJ/kg CH4; and\\n\\nl\\n\\nspecies/category/type of livestock.\\n\\nE\\n\\nENTERIC\\n\\nt |,\\n\\nPRC\\n\\nEF l\\n\\nN\\n\\ntl |,\\n\\nPRS\\n\\nGD tl |,\\n\\nPRC\\n\\n(61)\\n\\nl\\n\\nWhere:\\n\\nEENTERIC,t|PRS\\n\\nEFl\\n\\nmethane emissions from enteric fermentation in year t in the project scenario, kg CH4 yr-1; emissions factor for livestock type l, kg CH4 head-1 day-1;\\n\\nNl,t|PRS\\n\\nnumber of livestock of type l in year t in the project scenario, head yr-1;\\n\\nGDl,t|PRS\\n\\ngrazing days for livestock type l in year t in the project scenario, days; and\\n\\nl\\n\\nspecies/category/type of livestock.\\n\\nThe conversion of methane production to carbon dioxide equivalents shall be calculated as:\\n\\nGHG\\n\\nENTERIC\\n\\n|, t\\n\\nPRC\\n\\nE\\n\\nENTERIC\\n\\n|, t\\n\\nPRC\\n\\n23\\n\\n10\\n\\n3\\n\\n(62)\\n\\nWhere:\\n\\nGHGENTERIC,t|PRS\\n\\ngreenhouse gas emissions from enteric fermentation in year t in the project scenario; t CO2-e yr-1;\\n\\nEENTERIC,t|PRS\\n\\nmethane emissions from enteric fermentation in year t in the project scenario, kg CH4 yr-1; and\\n\\n23\\n\\nglobal warming potential integrated over 100 years for CH4, t CO2-e t-1 CH4.\\n\\nStep 8.5 Determine emissions from fossil fuel combustion in the ex-post project scenario\\n\\nIf at Step 6.3.4 emissions from fossil fuel combustion need not be accounted in the ex-post baseline scenario, then:\\n\\nGHGFF,t|PRS. = 0\\n\\nOtherwise, the updated ex-post IGMP inputs data to the following parameters:\\n\\nFCf,t|PRS\\n\\nfuel consumed (as represented by fuel purchased) for fuel type f in year t in the project scenario, kL.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 67\\n\\nf\\n\\nfuel type\\n\\nGreenhouse gas emissions from fossil fuel combustion in the project scenario shall be estimated as follows:\\n\\n3\\n\\nf\\n\\n\\n\\nGHG\\n\\ntFF ,\\n\\nPRC\\n\\nEC\\n\\ntf |,\\n\\nPRC\\n\\nEF\\n\\nfg ,\\n\\nGWP g\\n\\n10\\n\\n3\\n\\n(63)\\n\\ng\\n\\n1\\n\\nf\\n\\n1\\n\\nWhere:\\n\\nGHGFF,t|PRS\\n\\ngreenhouse gas emissions from fossil fuel combustion in year t in the project scenario, tCO2-e yr-1;\\n\\nECf,t|PRS\\n\\nEFg,f\\n\\nenergy consumed for fuel type f in year t in the project scenario, TJ; emissions factor for greenhouse gas g for fuel type f; kg TJ-1;\\n\\nGWP100,g\\n\\nglobal warming potential greenhouse gas g, t CO2-e t-1;\\n\\nintegrated over 100 years for\\n\\ng\\n\\nunique identifier for each greenhouse gas; and\\n\\nf\\n\\nfuel type.\\n\\nThe energy consumed for each fuel type in the project scenario shall be calculated as follows:\\n\\nEC\\n\\n|, tf\\n\\nPRC\\n\\nFC\\n\\n|, tf\\n\\nPRC\\n\\nNCV\\n\\nf\\n\\nD\\n\\nf\\n\\n(64)\\n\\nWhere:\\n\\nECf,t|PRS\\n\\nenergy consumed for fuel type f in year t in the project scenario, TJ;\\n\\nFCf,t|PRS\\n\\nNCVf\\n\\nDf\\n\\nfuel consumed (as represented by fuel purchased) for fuel type f in year t in the project scenario, kL; net calorific value for fuel type f, TJ Gg-1; and density of fuel type f, Gg kL-1.\\n\\nStep 8.6 Determine emissions from fertilizer use in the ex-post project scenario\\n\\nIn the ex-post project scenario direct nitrous oxide emissions from nitrogen fertilization is measured even when flood irrigation or flooding has occurred on the project area within a period of 3 months from date of fertilizer application, as this is conservative.\\n\\nFor ex-post estimation of GHGFERT,t|PRS, the updated ex-post IGMP inputs data to the following parameters:\\n\\nMSF,k,t mass of synthetic fertilizer type k applied in year t, t;\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 68\\n\\nMOF,j,t mass of organic fertilizer type j applied in year t, t.\\n\\nThe direct nitrous oxide emissions from nitrogen fertilization in year t can be estimated using equations as follows:\\n\\nGHG\\n\\nFERT\\n\\n|, t\\n\\nPRS\\n\\n(\\n\\nF\\n\\nSN\\n\\n,\\n\\nt\\n\\nF\\n\\n, tON\\n\\n)\\n\\nEF 1\\n\\n44 28\\n\\nGWP\\n\\nON 2\\n\\n(65)\\n\\nWhere:\\n\\nGHGFERT,t|PRS\\n\\ndirect N2O emission as a result of nitrogen application within the project boundary in year t in the ex-post project scenario, t CO2-e;\\n\\nFSN,t\\n\\nMass of synthetic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nFON,t\\n\\nEF1\\n\\n44/28\\n\\nmass of organic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N; emission factor for emissions from N inputs, t N2O-N t-1 N input; ratio of molecular weights of N2O and N, t N2O t-1 N; and\\n\\nONGWP\\n\\n2\\n\\nglobal warming potential integrated over 100 years for N2O, t CO2-e t-1 N2O.\\n\\nF\\n\\nSN\\n\\n,\\n\\nt\\n\\nM\\n\\nSF\\n\\ntk ,\\n\\nNC\\n\\nSF\\n\\n,\\n\\nk\\n\\n1(\\n\\nFrac\\n\\nGASF\\n\\n)\\n\\n(66)\\n\\nk\\n\\nWhere:\\n\\nFSN,t\\n\\nmass of synthetic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nMSF,k,t\\n\\nmass of synthetic fertilizer type k applied in year t, t;\\n\\nNCSF,k\\n\\nnitrogen content of synthetic fertilizer type k applied, g N 100g-1 fertilizer;\\n\\nFracGASF\\n\\nFraction that volatilises as NH3 and NOX for synthetic fertilizers, dimensionless; and\\n\\nk\\n\\nsynthetic fertilizer type.\\n\\nF\\n\\ntON ,\\n\\nM\\n\\ntjOF , ,\\n\\nNC\\n\\njOF ,\\n\\n1(\\n\\nFrac\\n\\nGASM\\n\\n)\\n\\n(67)\\n\\nj\\n\\nWhere:\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 69\\n\\nFON,t\\n\\nmass of organic fertilizer nitrogen applied in year t adjusted for volatilization as NH3 and NOX, t N;\\n\\nMOF,j,t\\n\\nNCOF,j\\n\\nmass of organic fertilizer type j applied in year t, t; nitrogen content of organic fertilizer type j applied, g N 100g-1 fertilizer; and\\n\\nFracGASM\\n\\nFraction that volatilises as NH3 and NOX for organic fertilizers, dimensionless; and\\n\\nj\\n\\norganic fertilizer type.\\n\\nStep 8.7 Net GHG emissions in the ex-post project scenario\\n\\nThis step calculates GHGNET,t|PRS, the net GHG emissions in year t in the project scenario.\\n\\nProponents shall calculate the net greenhouse gas emissions in year t in the ex-post project scenario as:\\n\\nGHG\\n\\nNET\\n\\nt |,\\n\\nPRS\\n\\nGHG\\n\\nAWB\\n\\nt |,\\n\\nPRS\\n\\nGHG\\n\\nENTERIC\\n\\nt |,\\n\\nPRS\\n\\nGHG\\n\\ntFF |,\\n\\nPRS\\n\\nGHG\\n\\nFERT\\n\\nt |,\\n\\nPRS\\n\\n(\\n\\nC\\n\\ntS |,\\n\\nPRS\\n\\nC\\n\\nAWB\\n\\nt |,\\n\\nPRS\\n\\n)\\n\\n(68)\\n\\nWhere:\\n\\nGHGNET,t|PRS\\n\\nnet greenhouse gas emissions in year t in the project scenario; t CO2-e;\\n\\nGHGAWB,t|PRS\\n\\ngreenhouse gas emissions from above-ground woody biomass in year t in the project scenario; t CO2-e;\\n\\nGHGENTERIC,t|PRS\\n\\ngreenhouse gas emissions from enteric fermentation in year t in the project scenario; t CO2-e;\\n\\nGHGFF,t|PRS\\n\\ngreenhouse gas emissions from fossil fuel combustion in year t in the project scenario, tCO2-e; and\\n\\nGHGFERT,t|PRS\\n\\ndirect N2O emission as a result of nitrogen application within the project boundary in year t, t CO2-e;\\n\\nCs,t |PRS\\n\\ncarbon stock change in soil organic carbon in year t in the project scenario, t CO2-e; and\\n\\n∆CAWB,t|PRS\\n\\nthe carbon stock change in above-ground woody biomass within the project boundary in year t in the project scenario; t CO2-e.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 70\\n\\nSTEP 9 – Project Leakage Leakage is defined as any increase in greenhouse gas emissions that occur outside a project’s boundary, but within the same country, that is measurable and attributable to the project activity.\\n\\nStep 9.1 Activity shifting leakage\\n\\nThere may be no leakage due to activity shifting.\\n\\nAt each verification documentation must be provided covering any other grasslands controlled by the project proponent where leakage could occur, including, at a minimum, their location(s), area and type of existing land use(s), and grazing management plans.\\n\\nland under grassland Where the project proponent controls multiple parcels of management within the country, the project proponent must demonstrate that the grassland management plans and/or land-use designations of the land parcels they control have not materially changed as a result of the planned improved grazing management project.\\n\\nThis must be demonstrated through:\\n\\nhistorical records showing grassland management and livestock production do not\\n\\ndeviate from historical trends; and/or\\n\\ngrassland management on all land parcels controlled by the project proponent show no deviation from grassland management plans prepared greater than 24 months prior to the start of the improved grassland management project.\\n\\nWhere activity shifting occurs or a project proponent is unable to provide the necessary documentation at first and subsequent verification, the project shall not meet the requirements for verification.\\n\\nTherefore, the project shall be subject to the VCS conditions on projects which fail to submit periodic verification after the commencement of the project. Project proponents may optionally choose to submit a methodology deviation with their future verifications to address activity shifting leakage.\\n\\nWhere the project proponent has control only over resource use in the project area and has no access to other forest resource, then the only type of leakage emissions calculated is GHG emissions due to market effects that result from project activity.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 71\\n\\nStep 9.2 Market leakage\\n\\nLeakage due to market effects results from the displacement of baseline scenario livestock production to commercial producers operating outside the project boundary which is measureable and attributable to the improved grazing management project activity.28\\n\\nStep 9.2.1 Direct substitution\\n\\nWhere there is direct substitution in livestock production there shall be no market leakage.\\n\\nDirect substitution occurs where a demand for production is met by an alternative production source with equivalent or lower greenhouse gas emissions than livestock production in the ex-post project scenario.\\n\\nDirect substitution shall apply where a decrease in livestock production in the project scenario is met by alternative livestock production outside the project area and/or where direct product substitution occurs within the project boundary.\\n\\nProject proponents shall provide evidence in the VCS verification report for direct substitution.\\n\\nStep 9.2.2 Livestock production\\n\\nLeakage due to market effects is equal to the net emissions in the baseline scenario multiplied by an appropriate leakage factor:\\n\\nGHG\\n\\nIGMtLK\\n\\n,\\n\\nLF\\n\\nme\\n\\n\\n\\nGHG\\n\\nNET\\n\\n,\\n\\nt\\n\\nBSL\\n\\n(69)\\n\\nWhere:\\n\\nGHGLK|LtPF\\n\\nis market leakage in year t as a result of IGM activities, tCO2e;\\n\\nLFME\\n\\nis the dimensionless leakage factor for market-effects calculations;\\n\\nGHGNET|BSL\\n\\nnet greenhouse gas emissions in year t in the baseline scenario, tCO2e.\\n\\nWhere livestock production is lower in the ex-post baseline scenario than the ex-post project scenario or where livestock production in the ex-post baseline scenario is not significantly different to livestock production in the ex-post project scenario there shall be no market leakage.\\n\\nTherefore,\\n\\nLFME = 0\\n\\nLivestock production shall be compared in standard livestock units from data provided to recalibrate the GMP and the IGMP to account for environmental and management conditions that occurred during each verification period (Step 6).\\n\\n28 CDM 5/CMP.1, Annex, paragraph 1(e)\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 72\\n\\nStep 9.2.3 Livestock production trigger\\n\\nWhere livestock production in the ex-post project scenario is greater than or equal to 20% lower than the average livestock production in the ex-post baseline scenario over the verification period, project proponents shall determine whether a displacement of production and subsequent emissions are measureable and attributable to the project activity.\\n\\nDisplacement of the sum of removed production shall be determined to have occurred when the amount of livestock production foregone in the project area is greater than 5% of the variance of average national production in units of production for the same product during the period of 10 years preceding project implementation on the relevant national livestock market.\\n\\nWhere livestock production in the ex-post project scenario is greater than or equal to 20% lower than the average livestock production in the ex-post baseline scenario over the verification period but the detection trigger is not met, there shall be no market leakage.\\n\\nTherefore,\\n\\nLFME = 0\\n\\nWhere livestock production in the ex-post project scenario is greater than or equal to 20% lower than the average livestock production in the ex-post baseline scenario over the verification period and the detection trigger is met, market leakage shall be:\\n\\nLFME = 0.5\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 73\\n\\nSTEP 10 – Net Project Greenhouse Gas Emission Reductions This step calculates GHGCREDITS|IGM, the net project greenhouse gas emission credits associated with the implementation of improved grazing management (IGM) activities in the project scenario.\\n\\nAt validation the following equation shall be applied using the ex-ante greenhouse gas emission calculations at Step 4 for ex-ante baseline scenario and at Step 5 for ex-ante project scenario greenhouse gas emissions assuming that in the ex-ante case leakage is zero:\\n\\nGHG\\n\\nCREDITS\\n\\n|, IGMt\\n\\nGHG\\n\\nNET\\n\\n|, t\\n\\nPRS\\n\\nGHG\\n\\nNET\\n\\n|, t\\n\\nPRS\\n\\n(70)\\n\\nWhere:\\n\\nGHGCREDITS|IGM project greenhouse gas emission credits in year t associated with the implementation of Improved Grazing Management (IGM) project, tCO2e;\\n\\nGHGNET,t|BSL\\n\\nnet greenhouse gas emissions in year t in the baseline scenario since the start of the project activity, tCO2e; and\\n\\nGHGNET,t|PRS\\n\\nnet greenhouse gas emissions in year t in the project scenario since the start of the project activity, tCO2e.\\n\\nAt verification the following equation shall also be applied using the ex-post greenhouse gas emission calculations at Step 7 for ex-post baseline scenario and at Step 8 for ex-post project scenario greenhouse gas emissions and the calculation of project leakage at Step 9.\\n\\nGHG\\n\\nCREDITS\\n\\n|, IGMt\\n\\nGHG\\n\\nNET\\n\\n|, t\\n\\nPRS\\n\\nGHG\\n\\nNET\\n\\n|, t\\n\\nPRS\\n\\nGHG\\n\\n|, IGMtLK\\n\\n(71)\\n\\nWhere:\\n\\nGHGCREDITS|IGM project greenhouse gas emission credits in year t associated with the implementation of Improved Grazing Management (IGM) project, tCO2e;\\n\\nGHGNET,t|BSL\\n\\nnet greenhouse gas emissions in year t in the baseline scenario since the start of the project activity, tCO2e;\\n\\nGHGNET,t|PRS\\n\\nnet greenhouse gas emissions in year t in the project scenario since the start of the project activity, tCO2e; and\\n\\nGHGLK,t|IGM\\n\\ntotal greenhouse gas emissions due to leakage arising outside the project boundary as a result of the implementation of improved grazing management (IGM) project, tCO2e.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 74\\n\\nSTEP 11 – Project Voluntary Carbon Units The number of Voluntary Carbon Units (VCUs) for each year t in the crediting period is the greenhouse gas emission credits adjusted for uncertainty and risk.\\n\\nStep 11.1 Adjustment for uncertainty\\n\\nEstimated greenhouse gas emissions and emission reductions from IGM activities have uncertainties associated with parameters and coefficients including estimates of area, carbon stocks, stratification and greenhouse gas emissions. is assumed that the uncertainties associated with input data are available, either as default uncertainty values given in most recent IPCC guidelines, or as statistical estimates based on sampling.\\n\\nIt\\n\\nUncertainty at all times is defined as the 95% confidence interval as a percentage of the mean.\\n\\nProcedures including stratification and the allocation of sufficient measurement plots will help ensure that low uncertainty results and ultimately full crediting can result.\\n\\nIt is good practice to consider uncertainty at an early stage to identify the data sources with the highest uncertainty to allow the opportunity to conduct further work to diminish uncertainty.\\n\\nUncertainties arising from the measurement and monitoring of carbon pools and greenhouse gases shall always be quantified. Errors in each pool shall be weighted by the size of the pool so that projects may reasonably target a lower precision level in pools that only form a small proportion of the total stock.\\n\\nFor both the baseline and the with-project scenario the total uncertainty is equal to the square root of the sum of the squares of each component uncertainty and is calculated at the time of reporting through propagating the error in the baseline stocks and the error in the project stocks.\\n\\nTherefore, total uncertainty for IGM project is calculated as:\\n\\nU\\n\\nTOTAL\\n\\nIGMt |,\\n\\nU\\n\\n2 t PRJ |\\n\\nU\\n\\n2 t BSL |\\n\\n(72)\\n\\nWhere:\\n\\nUTOTAL|IGM\\n\\ntotal uncertainty in year t for IGM Project, dimensionless;\\n\\nU|PRS\\n\\ntotal uncertainty improved grassland t management activities in the project scenario, dimensionless; and\\n\\nin year\\n\\nfor\\n\\nthe\\n\\nU|BSL\\n\\ntotal uncertainty in year tfor the baseline scenario, dimensionless.\\n\\nProject proponents must justify the selection of uncertainty propagation in the VCS-PD.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 75\\n\\nIf Utotal|IGM ≤ 0.1 then no deduction will result for uncertainty.\\n\\nIf Utotal|IGM>0.1 then the amount of greenhouse gas emission credits associated with IFM activites will be deducted as follows:\\n\\nCredits\\n\\nTOTAL\\n\\n|, IGMt\\n\\nGHG\\n\\nCREDITS\\n\\n|, IGMt\\n\\n1\\n\\nU\\n\\nTOTAL\\n\\n|, IGMt\\n\\n(73)\\n\\nWhere:\\n\\nCreditstotal│IGM\\n\\ntotal greenhouse gas emission credits adjusted for uncertainty in year t in the crediting period;\\n\\nGHGcredits|IGM\\n\\nproject greenhouse gas emission credits in year t associated with the implementation of improved forest management (IFM) activities in the project scenario, tCO2e•year-1; and\\n\\nUtotal|IGM\\n\\ntotal uncertainty in year t for IGM Project, dimensionless.\\n\\nStep 11.2 Calculation of voluntary carbon units\\n\\nThe amount of greenhouse gas emission credits estimated at Step 7.1 above shall be adjusted to account for risk.\\n\\nThey shall be subject to deductions based on application of the VCS Tool for AFOLU Non- Permanence Risk Analysis and Buffer Determination29.\\n\\nTherefore, the amount of VCU’s that can be issued in year t is calculated as:\\n\\nVCU\\n\\n|, IGMtnet\\n\\nCredits\\n\\ntotal\\n\\n|, IGMt\\n\\n1\\n\\nBu |\\n\\nIGM\\n\\n(74)\\n\\nWhere:\\n\\nVCUnet,t│IGM\\n\\nnumber of voluntary carbon units in year t for the IGM project; dimensionless;\\n\\nCreditsTOTAL.t│IGM total greenhouse gas emission credits adjusted for uncertainty in year t in\\n\\nthe crediting period;\\n\\nBu|IFM-VCS\\n\\ntotal buffer proportion withheld in VCS buffer account.\\n\\n29http://www.v-c-s.org/docs/Tool%20for%20AFOLU%20Non- Permanence%20Risk%20Analysis%20and%20Buffer%20Determination.pdf\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 76\\n\\nSTEP 12 – Project Monitoring\\n\\nStep 12.1 Scope of monitoring and the monitoring plan\\n\\nMonitoring is required to:\\n\\na) confirm project activity;\\n\\nb) record environmental parameters such as rainfall and temperature necessary for\\n\\nSOC modelling and determination of ex-post GMP and IGMP\\n\\nc) record parameter values under the IGMP;\\n\\nd) determine soil carbon stock change and GHG emissions from project activity;\\n\\ne) record fertilizer use in the project scenario; and\\n\\nf) determine GHG emissions from disturbance due to unplanned fire, erosion, pests\\n\\nand disease;\\n\\nIn some project scenarios monitoring may also be implemented to update stratification.\\n\\nIt is a requirement that the monitoring plan presented in the VCS-PD shall address the monitoring of project implementation, the monitoring of actual carbon stock changes from project activity, and estimation of ex-post net carbon stock changes from disturbance.\\n\\nThe description of the monitoring plan in the VCS-PD will include the following for each of these monitoring tasks:\\n\\na) technical description of the monitoring task;\\n\\nb) a list of data and parameters to be collected;\\n\\nc) overview of data collection procedures;\\n\\nd) quality control and quality assurance procedure;\\n\\ne) data archiving; and\\n\\nf) organisation and responsibilities of the parties involved in all the above.\\n\\nStep 12.2 Monitoring of project implementation\\n\\nStep 12.2.1 Monitoring of project boundaries and stratification\\n\\nInformation shall be provided, and recorded in the VCS-PD, to establish that:\\n\\nthe geographic position of the project boundary is recorded for all areas of land;\\n\\nthe geographic coordinates of the project boundary (and any stratification inside the boundary) are established, recorded and archived. This will be achieved by field survey (e.g.. using GPS) or by using georeferenced spatial data (e.g. maps, GIS datasets, aerial photography, or georeferenced remote sensing images);\\n\\nstandard operating procedures (SOPs) and quality control/quality assurance (QA/QC)\\n\\nprocedures for any field data measurements are applied; and\\n\\nthe ex-ante and ex-post GMP and ex-ante and ex-post IGMP, shall be available for\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 77\\n\\nvalidation or verification as appropriate.\\n\\nStep 12.2.2 Grassland management activity records\\n\\nInformation shall be provided, and recorded in the VCS-PD, to establish that:\\n\\ncommonly accepted principles of grassland management are implemented;\\n\\nlivestock management parameters relevant to the grassland management implemented including stocking rate, livestock adjistment, production and changes in livestock type or composition are recorded. It is acceptable to use grassland management records and farm management records to provide these data;\\n\\nfossil fuel use in implementing the grassland management are recorded. It is acceptable to provide fuel purchase records as evidence of fossil fuel use;\\n\\nall applications of fertilizer are recorded to include the type of fertilizer, together\\n\\nwith the rate, timing and location of fertilizer application(s).\\n\\nStep 12.2.3 Monitoring of vegetation\\n\\nInformation shall be provided, and recorded in the VCS-PD, to establish that vegetation cover has been maintained or increased as a result of project implementation.\\n\\nProject proponents shall establish a minimum of three photopoints in each strata (the combination of soil type and management practice used to calibrate the SOC model) that each cover greater than 10% of the project area.\\n\\nAt each photopoint images shall be captured biannually in the same month and corresponding to the average annual biomass peak and trough for the district.\\n\\nProtocols for image capture shall follow common practice for photopoint interpretation.\\n\\nStep 12.3 Data inputs to SOC model calibration\\n\\nMonitoring of parameters is required to recalibrate the GMP and the IGMP to account for environmental and management conditions that occurred during each verification period, and to update parameter selection for ex-post baseline scenario greenhouse gas emissions and ex post project scenario greenhouse gas emissions.\\n\\nRainfall and temperature data must be obtained from the nearest weather station certified to provide data to the national weather recording system. Where project locations are more than 100km from a certified weather station it is acceptable to obtain data from an independent recording station.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 78\\n\\nCalibration parameters related to grassland management are specific to the chosen SOC model and must be recorded in a format acceptable to the selected SOC model.\\n\\nAppropriate QA/QC procedures shall be applied to data collection.\\n\\nWhere historical data were used to provide parameter input (such as rainfall, temperature, market forces) and management strategy decisions that generated ex-ante estimation of the baseline scenario, these data and management strategy decisions must be updated to use ex post data for the verification period.\\n\\nThe project proponent must, at a minimum, update rainfall and temperature parameters and baseline grassland management parameters in the GMP and IGMP where ex post data for management practices can be obtained or where historical or common practice justification can be made based on economic, rainfall and temperature patterns over the verification period.\\n\\nStep 12.4 Disturbance\\n\\nIt is a requirement that any greenhouse gas emissions from natural disturbance above de minimis that may occur in the project area are monitored.\\n\\nFor fire damage it is assumed that a fire burning in the project scenario would also have burned in the baseline. Project emissions are therefore equal to the fire damage to biomass absent in the baseline scenario but present in the project scenario.\\n\\nWhere fires occur ex post in the project area, the area burned shall be delineated. Any above-ground biomass stock present in the delineated area shall be included as a stratum in the calculation of above-ground woody biomass carbon stock losses in the ex-post project scenario (Step 8.3.2)\\n\\nIn the case of erosion and/or pests and disease it is assumed that disturbance in the project scenario would also have occurred in the baseline scenario. Where erosion and/or pests and disease occur ex post in the project area, the area of erosion and/or pests and disease shall be delineated.\\n\\nThe SOC stock change that was present in the delineated area shall be removed from the ex- post project scenario net greenhouse gas emissions.\\n\\nStep 12.5 National livestock production\\n\\nData shall be obtained on the national livestock production to inform the leakage calculation at Step 9.\\n\\nIt is acceptable to obtain livestock production data from published national agricultural records.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 79\\n\\nStep 12.6 General requirements for monitoring\\n\\nAll data collected as part of monitoring will be archived electronically and be kept at least for 2 years after the end of the crediting period. All measurements will be conducted according to relevant standards.\\n\\nData archiving shall take both electronic and paper forms, and copies of all data shall be provided to each project participant.\\n\\nAll electronic data and reports shall also be copied on durable media such as CDs and copies of the CDs are to be stored in multiple locations.\\n\\nThe archives shall include:\\n\\ncopies of all original field measurement data, laboratory data, photopoint images,\\n\\ndata analysis spreadsheets;\\n\\nestimates of the carbon stock changes in all pools and non-CO2 GHG and\\n\\ncorresponding calculation spreadsheets;\\n\\nGIS products; and\\n\\ncopies of the measuring and monitoring reports.\\n\\nStep 12.7 Conservative approach and uncertainty\\n\\nProject proponents shall apply all relevant equations for the ex-ante calculation of net anthropogenic GHG removals by sinks with care and provide transparent estimations for the parameters that are monitored during the crediting period. These estimates shall be based on measured or existing published data where possible and project proponents should retain a conservative approach: that is, if different values for a parameter are equally plausible, a value that does not lead to over-estimation of net anthropogenic GHG removals by sinks must be selected.\\n\\nAn uncertainty analysis is required for all estimates from monitoring related to change in area, change in carbon stocks and emissions for both the baseline and project scenario.\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 80\\n\\nData and parameters not monitored (default or possibly measured one time)\\n\\nIn addition to the parameters listed in the tables presented in the following pages, the provisions on data and parameters not monitored in the tools referred to in this methodology apply. In choosing key parameters or making important assumptions based on information that is not specific to the project circumstances, such as in use of existing published data, project participants must retain a conservative approach: that is, if different values for a parameter are equally plausible, a value that does not lead to over-estimation of net anthropogenic GHG removals by sinks must be selected.\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data: Measurement procedures (if any): Any comment:\\n\\nGEl\\n\\nMJ head-1 day-1\\n\\nGross energy intake by livestock type l\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data: Measurement procedures (if any): Any comment:\\n\\nMCFl\\n\\nfraction of gross energy in feed converted to methane\\n\\nmethane conversion factor for livestock type l\\n\\nData parameter: Data unit: Used equations: Description: Source of data:\\n\\n/\\n\\nin\\n\\nCOMFTREE,i\\n\\nDimensionless\\n\\nCombustion factor of tree for stratum i(vegetation type) Default values in Table 2.6 of IPCC, 2006\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 81\\n\\nMeasurement procedures any): Any comment:\\n\\nData parameter: Data unit: Used equations: Description: Source of data: Measurement procedures any): Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data: Measurement procedures (if\\n\\nIGM Methodology\\n\\n(if\\n\\n/\\n\\nin\\n\\n(if\\n\\nN/A\\n\\nThe combustion factor is a measure of the proportion of the fuel that is actually combusted, which varies as a function of the size and architecture of the fuel load (i.e., a smaller proportion of large, coarse fuel such as tree stems will be burnt compared to fine fuels, such as grass leaves), the moisture content of the fuel and the type of fire (i.e., intensity and rate of spread).\\n\\nDefault values shall be updated whenever new guidelines are produced by the IPCC\\n\\nCOMFSHRUB,i\\n\\nDimensionless\\n\\nCombustion factor of shrub for stratum i(vegetation type) Default values in Table 2.6 of IPCC, 2006 N/A\\n\\nThe combustion factor is a measure of the proportion of the fuel that is actually combusted, which varies as a function of the size and architecture of the fuel load (i.e., a smaller proportion of large, coarse fuel such as tree stems will be burnt compared to fine fuels, such as grass leaves), the moisture content of the fuel and the type of fire (i.e., intensity and rate of spread).\\n\\nDefault values shall be updated whenever new guidelines are produced by the IPCC\\n\\nNCVf\\n\\nTJ Gg-1 (Terajoules per Gigagram)\\n\\nnet calorific value for fuel type f\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 82\\n\\nany): Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data: Measurement procedures (if any): Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data:\\n\\nMeasurement procedures (if any): Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data: Measurement procedures (if any): Any comment:\\n\\nIGM Methodology\\n\\nDf\\n\\nGg kL-1 (Gigagrams per kilolitre)\\n\\ndensity of fuel type f\\n\\nEF1\\n\\nt N2O t-1 N input\\n\\nemission factor for emissions from N inputs Country-specific data, IPCC\\n\\nNCSF,k\\n\\ng N 100g-1 fertilizer\\n\\nnitrogen content of synthetic fertilizer type k applied Producers of synthetic fertilizer purchased and used Keep record of nitrogen content from producers\\n\\nIF producers do not provide data on nitrogen content, the nitrogen content must be determined by qualified lab\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 83\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data:\\n\\nMeasurement procedures (if any): Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data: Measurement procedures (if any): Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data:\\n\\nMeasurement procedures (if any): Any comment:\\n\\nIGM Methodology\\n\\nFracGASF\\n\\ndimensionless\\n\\nFraction that volatilises as NH3 and NOX for synthetic fertilizers Country-specific data, IPCC\\n\\nNCOF,j\\n\\ng N 100g-1 fertilizer\\n\\nnitrogen content of organic fertilizer type j applied Producers of synthetic fertilizer purchased and used Keep record of nitrogen content from producers\\n\\nIF producers do not provide data on nitrogen content, the nitrogen content must be determined by qualified lab\\n\\nFracGASM\\n\\ndimensionless\\n\\nFraction that volatilises as NH3 and NOX for organic fertilizers Country-specific data, IPCC\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 84\\n\\nData and parameters used in monitoring\\n\\nIn addition to the parameters listed in the tables below, the provisions on data and parameters not monitored in the tools referred to in this methodology apply. In choosing key parameters or making important assumptions based on information that is not specific to the project circumstances, such as in use of existing published data, project participants must retain a conservative approach: that is, if different values for a parameter are equally plausible, a value that does not lead to over-estimation of net anthropogenic GHG removals by sinks must be selected.\\n\\nData / parameter: Data unit: Used in equations: Description:\\n\\nNl,t|BSL\\n\\nhead yr-1\\n\\nnumber of livestock of type l in year t in the baseline scenario\\n\\nSource of data:\\n\\nshall be reported in the baseline Grassland Management Plan Ex-ante proponents are to use in descending order of preference:\\n\\n(I) (II)\\n\\nhistorical data common practice for the region\\n\\nto determine amount applied in each year of the project crediting period. Ex-post proponents are to use in descending order of preference:\\n\\n(I) (II)\\n\\nhistorical data common practice for the region\\n\\nto determine amount applied in each year of the project crediting period, based on the environmental and economic data.\\n\\nMeasurement procedures (if any): Measurement Frequency QA/QC Procedures Any comment:\\n\\nAnnual\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data:\\n\\nGPl,t|BSL\\n\\ndays\\n\\ngrazing days for livestock type l in year t in the baseline scenario shall be reported in the baseline Grassland Management Plan Ex-ante proponents are to use in descending order of preference:\\n\\nIGM Methodology\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 85\\n\\nMeasurement procedures (if any): Measurement Frequency QA/QC Procedures Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description:\\n\\nSource of data:\\n\\nMeasurement procedures (if any): Measurement\\n\\nIGM Methodology\\n\\n(III) (IV)\\n\\nhistorical data common practice for the region\\n\\nto determine amount applied in each year of the project crediting period. Ex-post proponents are to use in descending order of preference:\\n\\n(III) (IV)\\n\\nhistorical data common practice for the region\\n\\nto determine amount applied in each year of the project crediting period, based on the environmental and economic data.\\n\\nFCf,t|BSL\\n\\nkL\\n\\nfuel consumed (as represented by fuel purchased) for fuel type f in year t in the baseline scenario shall be reported in the baseline Grassland Management Plan Ex-ante proponents are to use in descending order of preference:\\n\\n(V) (VI)\\n\\nhistorical data common practice for the region\\n\\nto determine amount applied in each year of the project crediting period. Ex-post proponents are to use in descending order of preference:\\n\\n(V) (VI)\\n\\nhistorical data common practice for the region\\n\\nto determine amount applied in each year of the project crediting period, based on the environmental and economic data.\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 86\\n\\nFrequency QA/QC Procedures Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description:\\n\\nSource of data:\\n\\nMeasurement procedures (if any): Measurement Frequency QA/QC Procedures Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description:\\n\\nSource of data:\\n\\nIGM Methodology\\n\\nMSF,k,t|BSL\\n\\nt\\n\\nmass of synthetic fertilizer type k applied in year t in the baseline scenario Record of synthetic fertilizer purchased and used shall be reported in the baseline Grassland Management Plan Ex-ante proponents are to use in descending order of preference:\\n\\n(VII) historical data (VIII) common practice for the region\\n\\nto determine amount applied in each year of the project crediting period. Ex-post proponents are to use in descending order of preference:\\n\\n(VII) historical data (VIII) common practice for the region\\n\\nto determine amount applied in each year of the project crediting period, based on the environmental and economic data.\\n\\nAnnually\\n\\nMOF,j,t|BSL\\n\\nt\\n\\nmass of organic fertilizer type j applied in year t in the baseline scenario Record organic fertilizer purchased and used shall be reported in the baseline Grassland Management Plan Ex-ante proponents are to use in descending order of preference:\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 87\\n\\nMeasurement procedures (if any): Measurement Frequency QA/QC Procedures Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data:\\n\\nMeasurement procedures (if any): Measurement Frequency QA/QC Procedures Any comment:\\n\\nData /\\n\\nIGM Methodology\\n\\n(IX) (X)\\n\\nhistorical data common practice for the region\\n\\nto determine amount applied in each year of the project crediting period. Ex-post proponents are to use in descending order of preference:\\n\\n(IX) (X)\\n\\nhistorical data common practice for the region\\n\\nto determine amount applied in each year of the project crediting period, based on the environmental and economic data.\\n\\nNl,t|PRS\\n\\nhead yr-1\\n\\nnumber of livestock of type l in year t in the project scenario Predicted and reported in the Improved Grassland Management Plan Ex-ante, project proponents are to use in descending order of preference:\\n\\n(I) (II)\\n\\nhistorical data common practice for the region/management strategy\\n\\nto determine amount applied in each year of the project crediting period. Ex-post livestock type shall be reported in the project scenario Improved Grassland Management Plan Record of livestock type shall be reported in the project scenario Improved Grassland Management Plan\\n\\nAnnually\\n\\nGDl,t|PRS\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 88\\n\\nparameter: Data unit: Used in equations: Description: Source of data:\\n\\nMeasurement procedures (if any): Measurement Frequency QA/QC Procedures Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description:\\n\\nSource of data:\\n\\nMeasurement procedures (if any): Measurement\\n\\nIGM Methodology\\n\\ndays\\n\\ngrazing days for livestock type l in year t in the project scenario, Predicted and reported in the Improved Grassland Management Plan Ex-ante, project proponents are to use in descending order of preference:\\n\\n(III) (IV)\\n\\nhistorical data common practice for the region/management strategy\\n\\nto determine amount applied in each year of the project crediting period. Ex-post grazing days shall be reported in the project scenario Improved Grassland Management Plan Record of grazing days shall be reported in the project scenario Improved Grassland Management Plan\\n\\nAnnually\\n\\nFCf,t|PRS\\n\\nkL\\n\\nfuel consumed (as represented by fuel purchased) for fuel type f in year t in the project scenario Use Management Plan Ex-ante, project proponents are to use in descending order of preference:\\n\\nis predicted and reported\\n\\nin\\n\\nthe\\n\\nImproved Grassland\\n\\n(V) (VI)\\n\\nhistorical data common practice for the region/management strategy\\n\\nto determine amount applied in each year of the project crediting period. Ex-post fuel purchased and used shall be reported in the project scenario Improved Grassland Management Plan.\\n\\nRecord of synthetic fertilizer purchased and used shall be reported in the project scenario Improved Grassland Management Plan\\n\\nAnnually\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 89\\n\\nFrequency QA/QC Procedures Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description:\\n\\nSource of data:\\n\\nMeasurement procedures (if any): Measurement Frequency QA/QC Procedures Any comment:\\n\\nData / parameter: Data unit: Used in equations: Description: Source of data:\\n\\nIGM Methodology\\n\\nMSF,k,t|PRJ\\n\\nt\\n\\nmass of synthetic fertilizer type k applied in year t in the project scenario Synthetic fertilizer use is predicted and reported in the Improved Grassland Management Plan Ex-ante, project proponents are to use in descending order of preference:\\n\\n(VII) historical data (VIII) common practice for the region/management strategy\\n\\nto determine amount applied in each year of the project crediting period. Ex-post synthetic fertilizer purchased and used shall be reported in the project scenario Improved Grassland Management Plan.\\n\\nRecord of synthetic fertilizer purchased and used shall be reported in the project scenario Improved Grassland Management Plan\\n\\nAnnually\\n\\nMOF,j,t|PRJ\\n\\nt\\n\\nmass of organic fertilizer type j applied in year t in the project scenario Organic fertilizer use is predicted and reported in the Improved Grassland Management Plan Ex-ante, project proponents are to use in descending order of preference:\\n\\n(IX) (X)\\n\\nhistorical data common practice for the region/management strategy\\n\\nto determine amount applied in each year of the project crediting\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 90\\n\\nMeasurement procedures (if any): Measurement Frequency QA/QC Procedures Any comment:\\n\\nIGM Methodology\\n\\nperiod. Ex-post synthetic fertilizer purchased and used shall be reported in the project scenario Improved Grassland Management Plan.\\n\\nRecord of synthetic fertilizer purchased and used shall be reported in the project scenario Improved Grassland Management Plan\\n\\nAnnually\\n\\n' GreenCollar Pty Ltd\\n\\nP a g e | 91\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#key = \"verra/program_notices/txt/Verra Extends Validation Deadline for Plastic Projects.txt\"\n",
    "key = \"verra/methodology/pdf/Improved-Grazing-Management-Methodology-v2-4.pdf\"\n",
    "S3FileLoader(bucket=bucket_name, key=key).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[pdf] in /Users/khoa/py39/lib/python3.9/site-packages (0.16.4)\n",
      "Requirement already satisfied: chardet in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (5.2.0)\n",
      "Requirement already satisfied: filetype in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (0.4.27)\n",
      "Requirement already satisfied: lxml in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (5.3.0)\n",
      "Requirement already satisfied: nltk in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (3.9.1)\n",
      "Requirement already satisfied: requests in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (2.32.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (4.12.3)\n",
      "Requirement already satisfied: emoji in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (2.14.0)\n",
      "Requirement already satisfied: dataclasses-json in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (2024.10.22)\n",
      "Requirement already satisfied: langdetect in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (3.10.1)\n",
      "Requirement already satisfied: backoff in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (4.12.0)\n",
      "Requirement already satisfied: unstructured-client in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (0.26.2)\n",
      "Requirement already satisfied: wrapt in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (4.66.4)\n",
      "Requirement already satisfied: psutil in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (5.9.8)\n",
      "Requirement already satisfied: python-oxmsg in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (0.0.1)\n",
      "Requirement already satisfied: html5lib in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (1.1)\n",
      "Collecting onnx (from unstructured[pdf])\n",
      "  Downloading onnx-1.17.0-cp39-cp39-macosx_12_0_universal2.whl.metadata (16 kB)\n",
      "Collecting pdf2image (from unstructured[pdf])\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six (from unstructured[pdf])\n",
      "  Using cached pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting pikepdf (from unstructured[pdf])\n",
      "  Downloading pikepdf-9.4.0-cp39-cp39-macosx_14_0_arm64.whl.metadata (8.2 kB)\n",
      "Collecting pi-heif (from unstructured[pdf])\n",
      "  Downloading pi_heif-0.20.0-cp39-cp39-macosx_14_0_arm64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pypdf in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured[pdf]) (5.0.1)\n",
      "Collecting google-cloud-vision (from unstructured[pdf])\n",
      "  Using cached google_cloud_vision-3.8.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting effdet (from unstructured[pdf])\n",
      "  Using cached effdet-0.4.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting unstructured-inference==0.8.1 (from unstructured[pdf])\n",
      "  Using cached unstructured_inference-0.8.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting unstructured.pytesseract>=0.3.12 (from unstructured[pdf])\n",
      "  Using cached unstructured.pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting layoutparser (from unstructured-inference==0.8.1->unstructured[pdf])\n",
      "  Using cached layoutparser-0.3.4-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting python-multipart (from unstructured-inference==0.8.1->unstructured[pdf])\n",
      "  Downloading python_multipart-0.0.17-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: huggingface-hub in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (0.23.2)\n",
      "Collecting opencv-python!=4.7.0.68 (from unstructured-inference==0.8.1->unstructured[pdf])\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (1.19.2)\n",
      "Requirement already satisfied: matplotlib in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (3.8.4)\n",
      "Requirement already satisfied: torch in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (2.3.1)\n",
      "Collecting timm (from unstructured-inference==0.8.1->unstructured[pdf])\n",
      "  Using cached timm-1.0.11-py3-none-any.whl.metadata (48 kB)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-inference==0.8.1->unstructured[pdf]) (4.41.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (24.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (10.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/khoa/py39/lib/python3.9/site-packages (from beautifulsoup4->unstructured[pdf]) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/khoa/py39/lib/python3.9/site-packages (from dataclasses-json->unstructured[pdf]) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/khoa/py39/lib/python3.9/site-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: torchvision in /Users/khoa/py39/lib/python3.9/site-packages (from effdet->unstructured[pdf]) (0.18.1)\n",
      "Collecting pycocotools>=2.0.2 (from effdet->unstructured[pdf])\n",
      "  Downloading pycocotools-2.0.8-cp39-cp39-macosx_10_9_universal2.whl.metadata (1.1 kB)\n",
      "Collecting omegaconf>=2.0 (from effdet->unstructured[pdf])\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf])\n",
      "  Downloading google_api_core-2.22.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /Users/khoa/py39/lib/python3.9/site-packages (from google-cloud-vision->unstructured[pdf]) (2.35.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-cloud-vision->unstructured[pdf])\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /Users/khoa/py39/lib/python3.9/site-packages (from google-cloud-vision->unstructured[pdf]) (4.25.5)\n",
      "Requirement already satisfied: six>=1.9 in /Users/khoa/py39/lib/python3.9/site-packages (from html5lib->unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Users/khoa/py39/lib/python3.9/site-packages (from html5lib->unstructured[pdf]) (0.5.1)\n",
      "Requirement already satisfied: click in /Users/khoa/py39/lib/python3.9/site-packages (from nltk->unstructured[pdf]) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/khoa/py39/lib/python3.9/site-packages (from nltk->unstructured[pdf]) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/khoa/py39/lib/python3.9/site-packages (from nltk->unstructured[pdf]) (2024.5.15)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/khoa/py39/lib/python3.9/site-packages (from pdfminer.six->unstructured[pdf]) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/khoa/py39/lib/python3.9/site-packages (from pdfminer.six->unstructured[pdf]) (43.0.3)\n",
      "Requirement already satisfied: Deprecated in /Users/khoa/py39/lib/python3.9/site-packages (from pikepdf->unstructured[pdf]) (1.2.14)\n",
      "Requirement already satisfied: olefile in /Users/khoa/py39/lib/python3.9/site-packages (from python-oxmsg->unstructured[pdf]) (0.47)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/khoa/py39/lib/python3.9/site-packages (from requests->unstructured[pdf]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/khoa/py39/lib/python3.9/site-packages (from requests->unstructured[pdf]) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/khoa/py39/lib/python3.9/site-packages (from requests->unstructured[pdf]) (2024.2.2)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (0.2.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (0.27.0)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (1.0.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (1.6.0)\n",
      "Requirement already satisfied: pydantic<2.10.0,>=2.9.0 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (2.9.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (2.8.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/khoa/py39/lib/python3.9/site-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/khoa/py39/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /Users/khoa/py39/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.65.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/khoa/py39/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf]) (1.67.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf])\n",
      "  Using cached grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/khoa/py39/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/khoa/py39/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/khoa/py39/lib/python3.9/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (4.9)\n",
      "Requirement already satisfied: anyio in /Users/khoa/py39/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/khoa/py39/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/khoa/py39/lib/python3.9/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/khoa/py39/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (0.14.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf>=2.0->effdet->unstructured[pdf])\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /Users/khoa/py39/lib/python3.9/site-packages (from omegaconf>=2.0->effdet->unstructured[pdf]) (6.0.1)\n",
      "Requirement already satisfied: coloredlogs in /Users/khoa/py39/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/khoa/py39/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf]) (24.3.25)\n",
      "Requirement already satisfied: sympy in /Users/khoa/py39/lib/python3.9/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf]) (1.12)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/khoa/py39/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/khoa/py39/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/khoa/py39/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/khoa/py39/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/khoa/py39/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/khoa/py39/lib/python3.9/site-packages (from matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (6.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/khoa/py39/lib/python3.9/site-packages (from pydantic<2.10.0,>=2.9.0->unstructured-client->unstructured[pdf]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/khoa/py39/lib/python3.9/site-packages (from pydantic<2.10.0,>=2.9.0->unstructured-client->unstructured[pdf]) (2.23.4)\n",
      "Requirement already satisfied: safetensors in /Users/khoa/py39/lib/python3.9/site-packages (from timm->unstructured-inference==0.8.1->unstructured[pdf]) (0.4.3)\n",
      "Requirement already satisfied: filelock in /Users/khoa/py39/lib/python3.9/site-packages (from torch->unstructured-inference==0.8.1->unstructured[pdf]) (3.14.0)\n",
      "Requirement already satisfied: networkx in /Users/khoa/py39/lib/python3.9/site-packages (from torch->unstructured-inference==0.8.1->unstructured[pdf]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/khoa/py39/lib/python3.9/site-packages (from torch->unstructured-inference==0.8.1->unstructured[pdf]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/khoa/py39/lib/python3.9/site-packages (from torch->unstructured-inference==0.8.1->unstructured[pdf]) (2024.5.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/khoa/py39/lib/python3.9/site-packages (from transformers>=4.25.1->unstructured-inference==0.8.1->unstructured[pdf]) (0.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/khoa/py39/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: scipy in /Users/khoa/py39/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.8.1->unstructured[pdf]) (1.13.1)\n",
      "Requirement already satisfied: pandas in /Users/khoa/py39/lib/python3.9/site-packages (from layoutparser->unstructured-inference==0.8.1->unstructured[pdf]) (2.2.2)\n",
      "Collecting iopath (from layoutparser->unstructured-inference==0.8.1->unstructured[pdf])\n",
      "  Using cached iopath-0.1.10.tar.gz (42 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pdfplumber (from layoutparser->unstructured-inference==0.8.1->unstructured[pdf])\n",
      "  Using cached pdfplumber-0.11.4-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: pycparser in /Users/khoa/py39/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.22)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-vision->unstructured[pdf])\n",
      "  Using cached protobuf-5.28.3-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-vision->unstructured[pdf])\n",
      "  Downloading grpcio-1.67.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/khoa/py39/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->unstructured-inference==0.8.1->unstructured[pdf]) (3.19.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/khoa/py39/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-vision->unstructured[pdf]) (0.6.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/khoa/py39/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[pdf]) (1.2.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/khoa/py39/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf]) (10.0)\n",
      "Collecting portalocker (from iopath->layoutparser->unstructured-inference==0.8.1->unstructured[pdf])\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/khoa/py39/lib/python3.9/site-packages (from jinja2->torch->unstructured-inference==0.8.1->unstructured[pdf]) (2.1.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/khoa/py39/lib/python3.9/site-packages (from pandas->layoutparser->unstructured-inference==0.8.1->unstructured[pdf]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/khoa/py39/lib/python3.9/site-packages (from pandas->layoutparser->unstructured-inference==0.8.1->unstructured[pdf]) (2024.1)\n",
      "Collecting pdfminer.six (from unstructured[pdf])\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber->layoutparser->unstructured-inference==0.8.1->unstructured[pdf])\n",
      "  Using cached pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/khoa/py39/lib/python3.9/site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.8.1->unstructured[pdf]) (1.3.0)\n",
      "Using cached unstructured_inference-0.8.1-py3-none-any.whl (48 kB)\n",
      "Using cached unstructured.pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Using cached effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "Using cached google_cloud_vision-3.8.0-py2.py3-none-any.whl (488 kB)\n",
      "Downloading onnx-1.17.0-cp39-cp39-macosx_12_0_universal2.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pi_heif-0.20.0-cp39-cp39-macosx_14_0_arm64.whl (489 kB)\n",
      "Downloading pikepdf-9.4.0-cp39-cp39-macosx_14_0_arm64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.22.0-py3-none-any.whl (156 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-macosx_11_0_arm64.whl (54.8 MB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Downloading pycocotools-2.0.8-cp39-cp39-macosx_10_9_universal2.whl (163 kB)\n",
      "Using cached timm-1.0.11-py3-none-any.whl (2.3 MB)\n",
      "Using cached layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "Downloading python_multipart-0.0.17-py3-none-any.whl (24 kB)\n",
      "Downloading grpcio_status-1.67.1-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.28.3-cp38-abi3-macosx_10_9_universal2.whl (414 kB)\n",
      "Downloading grpcio-1.67.1-cp39-cp39-macosx_10_9_universal2.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pdfplumber-0.11.4-py3-none-any.whl (59 kB)\n",
      "Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Using cached pypdfium2-4.30.0-py3-none-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime, iopath\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=c8db93bdcc2885347943b1429f8038000ca57dba9b623d5c783e9d9cd2b62f22\n",
      "  Stored in directory: /Users/khoa/Library/Caches/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
      "  Building wheel for iopath (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31532 sha256=3df622ca10db646d5adabfbbd1b492ce0cbd62ddb9ae103ed402549437e6dca1\n",
      "  Stored in directory: /Users/khoa/Library/Caches/pip/wheels/c1/13/6d/441d8f2af76ee6d2a3e67eebb1d0c556fefcee0a8b32266a8e\n",
      "Successfully built antlr4-python3-runtime iopath\n",
      "Installing collected packages: antlr4-python3-runtime, unstructured.pytesseract, python-multipart, pypdfium2, protobuf, portalocker, pi-heif, pdf2image, opencv-python, omegaconf, grpcio, proto-plus, pikepdf, onnx, iopath, pycocotools, pdfminer.six, grpcio-status, google-api-core, timm, pdfplumber, layoutparser, google-cloud-vision, effdet, unstructured-inference\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.67.0\n",
      "    Uninstalling grpcio-1.67.0:\n",
      "      Successfully uninstalled grpcio-1.67.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-proto 1.27.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 effdet-0.4.1 google-api-core-2.22.0 google-cloud-vision-3.8.0 grpcio-1.67.1 grpcio-status-1.67.1 iopath-0.1.10 layoutparser-0.3.4 omegaconf-2.3.0 onnx-1.17.0 opencv-python-4.10.0.84 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.4 pi-heif-0.20.0 pikepdf-9.4.0 portalocker-2.10.1 proto-plus-1.25.0 protobuf-5.28.3 pycocotools-2.0.8 pypdfium2-4.30.0 python-multipart-0.0.17 timm-1.0.11 unstructured-inference-0.8.1 unstructured.pytesseract-0.3.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/khoa/py39/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install \"unstructured[pdf]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: unstructured\n",
      "Version: 0.16.4\n",
      "Summary: A library that prepares raw documents for downstream ML tasks.\n",
      "Home-page: https://github.com/Unstructured-IO/unstructured\n",
      "Author: Unstructured Technologies\n",
      "Author-email: devops@unstructuredai.io\n",
      "License: Apache-2.0\n",
      "Location: /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages\n",
      "Requires: backoff, beautifulsoup4, chardet, dataclasses-json, emoji, filetype, html5lib, langdetect, lxml, nltk, numpy, psutil, python-iso639, python-magic, python-oxmsg, rapidfuzz, requests, tqdm, typing-extensions, unstructured-client, wrapt\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password:\n",
      "sudo: a password is required\n"
     ]
    }
   ],
   "source": [
    "!sudo yum install -y file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting libmagic\n",
      "  Using cached libmagic-1.0.tar.gz (3.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: libmagic\n",
      "  Building wheel for libmagic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for libmagic: filename=libmagic-1.0-py3-none-any.whl size=4270 sha256=dc657f9fae19f0ecddd5045f5398c8e643fdec9f00cdebcf8c88c082b9685cc4\n",
      "  Stored in directory: /Users/khoa/Library/Caches/pip/wheels/3e/35/13/53c696ff5f3523479505ec5ed4156198671fb598fe678178bf\n",
      "Successfully built libmagic\n",
      "Installing collected packages: libmagic\n",
      "Successfully installed libmagic-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install libmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
